{
  "version": 3,
  "sources": ["../../../../tfjs-converter/src/operations/custom_op/register.ts", "../../../../tfjs-converter/src/data/compiled_api.ts", "../../../../tfjs-converter/src/operations/executors/utils.ts", "../../../../tfjs-converter/src/operations/op_list/arithmetic.ts", "../../../../tfjs-converter/src/operations/op_list/basic_math.ts", "../../../../tfjs-converter/src/operations/op_list/control.ts", "../../../../tfjs-converter/src/operations/op_list/convolution.ts", "../../../../tfjs-converter/src/operations/op_list/creation.ts", "../../../../tfjs-converter/src/operations/op_list/dynamic.ts", "../../../../tfjs-converter/src/operations/op_list/evaluation.ts", "../../../../tfjs-converter/src/operations/op_list/graph.ts", "../../../../tfjs-converter/src/operations/op_list/hash_table.ts", "../../../../tfjs-converter/src/operations/op_list/image.ts", "../../../../tfjs-converter/src/operations/op_list/logical.ts", "../../../../tfjs-converter/src/operations/op_list/matrices.ts", "../../../../tfjs-converter/src/operations/op_list/normalization.ts", "../../../../tfjs-converter/src/operations/op_list/reduction.ts", "../../../../tfjs-converter/src/operations/op_list/slice_join.ts", "../../../../tfjs-converter/src/operations/op_list/sparse.ts", "../../../../tfjs-converter/src/operations/op_list/spectral.ts", "../../../../tfjs-converter/src/operations/op_list/string.ts", "../../../../tfjs-converter/src/operations/op_list/transformation.ts", "../../../../tfjs-converter/src/operations/operation_mapper.ts", "../../../../tfjs-converter/src/operations/custom_op/node_value_impl.ts", "../../../../tfjs-core/src/ops/ops_for_converter.ts", "../../../../tfjs-converter/src/operations/executors/arithmetic_executor.ts", "../../../../tfjs-converter/src/operations/executors/basic_math_executor.ts", "../../../../tfjs-converter/src/executor/tensor_utils.ts", "../../../../tfjs-converter/src/executor/tensor_array.ts", "../../../../tfjs-converter/src/executor/tensor_list.ts", "../../../../tfjs-converter/src/operations/executors/control_executor.ts", "../../../../tfjs-converter/src/operations/executors/convolution_executor.ts", "../../../../tfjs-converter/src/operations/executors/creation_executor.ts", "../../../../tfjs-converter/src/operations/executors/dynamic_executor.ts", "../../../../tfjs-converter/src/operations/executors/evaluation_executor.ts", "../../../../tfjs-converter/src/operations/executors/graph_executor.ts", "../../../../tfjs-converter/src/executor/hash_table.ts", "../../../../tfjs-converter/src/operations/executors/hash_table_executor.ts", "../../../../tfjs-converter/src/operations/executors/image_executor.ts", "../../../../tfjs-converter/src/operations/executors/logical_executor.ts", "../../../../tfjs-converter/src/operations/executors/matrices_executor.ts", "../../../../tfjs-converter/src/operations/executors/normalization_executor.ts", "../../../../tfjs-converter/src/operations/executors/ragged_executor.ts", "../../../../tfjs-converter/src/operations/executors/reduction_executor.ts", "../../../../tfjs-converter/src/operations/executors/slice_join_executor.ts", "../../../../tfjs-converter/src/operations/executors/sparse_executor.ts", "../../../../tfjs-converter/src/operations/executors/spectral_executor.ts", "../../../../tfjs-converter/src/operations/executors/string_executor.ts", "../../../../tfjs-converter/src/operations/executors/transformation_executor.ts", "../../../../tfjs-converter/src/operations/operation_executor.ts", "../../../../tfjs-converter/src/executor/execution_context.ts", "../../../../tfjs-converter/src/executor/model_analysis.ts", "../../../../tfjs-converter/src/executor/graph_executor.ts", "../../../../tfjs-converter/src/executor/resource_manager.ts", "../../../../tfjs-converter/src/executor/graph_model.ts", "../../../../tfjs-converter/src/version.ts", "../../../../tfjs-converter/src/flags.ts", "../../../../tfjs-converter/src/index.ts"],
  "sourcesContent": ["\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpExecutor, OpMapper} from '../types';\n\nconst CUSTOM_OPS: {[key: string]: OpMapper} = {};\n\n/**\n * Register an Op for graph model executor. This allows you to register\n * TensorFlow custom op or override existing op.\n *\n * Here is an example of registering a new MatMul Op.\n * ```js\n * const customMatmul = (node) =>\n *    tf.matMul(\n *        node.inputs[0], node.inputs[1],\n *        node.attrs['transpose_a'], node.attrs['transpose_b']);\n *\n * tf.registerOp('MatMul', customMatmul);\n * ```\n * The inputs and attrs of the node object are based on the TensorFlow op\n * registry.\n *\n * @param name The Tensorflow Op name.\n * @param opFunc An op function which is called with the current graph node\n * during execution and needs to return a tensor or a list of tensors. The node\n * has the following attributes:\n *    - attr: A map from attribute name to its value\n *    - inputs: A list of input tensors\n *\n * @doc {heading: 'Models', subheading: 'Op Registry'}\n */\nexport function registerOp(name: string, opFunc: OpExecutor) {\n  const opMapper: OpMapper = {\n    tfOpName: name,\n    category: 'custom',\n    inputs: [],\n    attrs: [],\n    customExecutor: opFunc\n  };\n\n  CUSTOM_OPS[name] = opMapper;\n}\n\n/**\n * Retrieve the OpMapper object for the registered op.\n *\n * @param name The Tensorflow Op name.\n *\n * @doc {heading: 'Models', subheading: 'Op Registry'}\n */\nexport function getRegisteredOp(name: string): OpMapper {\n  return CUSTOM_OPS[name];\n}\n\n/**\n * Deregister the Op for graph model executor.\n *\n * @param name The Tensorflow Op name.\n *\n * @doc {heading: 'Models', subheading: 'Op Registry'}\n */\nexport function deregisterOp(name: string) {\n  delete CUSTOM_OPS[name];\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\n/* tslint:disable */\n\n/** Properties of an Any. */\nexport declare interface IAny {\n  /** Any typeUrl */\n  typeUrl?: (string|null);\n\n  /** Any value */\n  value?: (Uint8Array|null);\n}\n\n/** DataType enum. */\nexport enum DataType {\n  // These properties must be quoted since they are used by parseDtypeParam\n  // in tfjs-converter/src/operations/operation_mapper.ts to look up dtypes\n  // by string name. If they are not quoted, Closure will mangle their names.\n\n  // Not a legal value for DataType.  Used to indicate a DataType field\n  // has not been set.\n  'DT_INVALID' = 0,\n\n  // Data types that all computation devices are expected to be\n  // capable to support.\n  'DT_FLOAT' = 1,\n  'DT_DOUBLE' = 2,\n  'DT_INT32' = 3,\n  'DT_UINT8' = 4,\n  'DT_INT16' = 5,\n  'DT_INT8' = 6,\n  'DT_STRING' = 7,\n  'DT_COMPLEX64' = 8,  // Single-precision complex\n  'DT_INT64' = 9,\n  'DT_BOOL' = 10,\n  'DT_QINT8' = 11,     // Quantized int8\n  'DT_QUINT8' = 12,    // Quantized uint8\n  'DT_QINT32' = 13,    // Quantized int32\n  'DT_BFLOAT16' = 14,  // Float32 truncated to 16 bits.  Only for cast ops.\n  'DT_QINT16' = 15,    // Quantized int16\n  'DT_QUINT16' = 16,   // Quantized uint16\n  'DT_UINT16' = 17,\n  'DT_COMPLEX128' = 18,  // Double-precision complex\n  'DT_HALF' = 19,\n  'DT_RESOURCE' = 20,\n  'DT_VARIANT' = 21,  // Arbitrary C++ data types\n  'DT_UINT32' = 22,\n  'DT_UINT64' = 23,\n\n  // Do not use!  These are only for parameters.  Every enum above\n  // should have a corresponding value below (verified by types_test).\n  'DT_FLOAT_REF' = 101,\n  'DT_DOUBLE_REF' = 102,\n  'DT_INT32_REF' = 103,\n  'DT_UINT8_REF' = 104,\n  'DT_INT16_REF' = 105,\n  'DT_INT8_REF' = 106,\n  'DT_STRING_REF' = 107,\n  'DT_COMPLEX64_REF' = 108,\n  'DT_INT64_REF' = 109,\n  'DT_BOOL_REF' = 110,\n  'DT_QINT8_REF' = 111,\n  'DT_QUINT8_REF' = 112,\n  'DT_QINT32_REF' = 113,\n  'DT_BFLOAT16_REF' = 114,\n  'DT_QINT16_REF' = 115,\n  'DT_QUINT16_REF' = 116,\n  'DT_UINT16_REF' = 117,\n  'DT_COMPLEX128_REF' = 118,\n  'DT_HALF_REF' = 119,\n  'DT_RESOURCE_REF' = 120,\n  'DT_VARIANT_REF' = 121,\n  'DT_UINT32_REF' = 122,\n  'DT_UINT64_REF' = 123,\n}\n\n/** Properties of a TensorShape. */\nexport declare interface ITensorShape {\n  /** TensorShape dim */\n  dim?: (TensorShape.IDim[]|null);\n\n  /** TensorShape unknownRank */\n  unknownRank?: (boolean|null);\n}\n\nexport namespace TensorShape {\n  /** Properties of a Dim. */\n  export declare interface IDim {\n    /** Dim size */\n    size?: (number|string|null);\n\n    /** Dim name */\n    name?: (string|null);\n  }\n}\n\n/** Properties of a Tensor. */\nexport declare interface ITensor {\n  /** Tensor dtype */\n  dtype?: (DataType|null);\n\n  /** Tensor tensorShape */\n  tensorShape?: (ITensorShape|null);\n\n  /** Tensor versionNumber */\n  versionNumber?: (number|null);\n\n  /** Tensor tensorContent */\n  tensorContent?: (Uint8Array|null);\n\n  /** Tensor floatVal */\n  floatVal?: (number[]|null);\n\n  /** Tensor doubleVal */\n  doubleVal?: (number[]|null);\n\n  /** Tensor intVal */\n  intVal?: (number[]|null);\n\n  /** Tensor stringVal */\n  stringVal?: (Uint8Array[]|null);\n\n  /** Tensor scomplexVal */\n  scomplexVal?: (number[]|null);\n\n  /** Tensor int64Val */\n  int64Val?: ((number | string)[]|null);\n\n  /** Tensor boolVal */\n  boolVal?: (boolean[]|null);\n\n  /** Tensor uint32Val */\n  uint32Val?: (number[]|null);\n\n  /** Tensor uint64Val */\n  uint64Val?: ((number | string)[]|null);\n}\n\n/** Properties of an AttrValue. */\nexport declare interface IAttrValue {\n  /** AttrValue list */\n  list?: (AttrValue.IListValue|null);\n\n  /** AttrValue s */\n  s?: (string|null);\n\n  /** AttrValue i */\n  i?: (number|string|null);\n\n  /** AttrValue f */\n  f?: (number|null);\n\n  /** AttrValue b */\n  b?: (boolean|null);\n\n  /** AttrValue type */\n  type?: (DataType|null);\n\n  /** AttrValue shape */\n  shape?: (ITensorShape|null);\n\n  /** AttrValue tensor */\n  tensor?: (ITensor|null);\n\n  /** AttrValue placeholder */\n  placeholder?: (string|null);\n\n  /** AttrValue func */\n  func?: (INameAttrList|null);\n}\n\nexport namespace AttrValue {\n  /** Properties of a ListValue. */\n  export declare interface IListValue {\n    /** ListValue s */\n    s?: (string[]|null);\n\n    /** ListValue i */\n    i?: ((number | string)[]|null);\n\n    /** ListValue f */\n    f?: (number[]|null);\n\n    /** ListValue b */\n    b?: (boolean[]|null);\n\n    /** ListValue type */\n    type?: (DataType[]|null);\n\n    /** ListValue shape */\n    shape?: (ITensorShape[]|null);\n\n    /** ListValue tensor */\n    tensor?: (ITensor[]|null);\n\n    /** ListValue func */\n    func?: (INameAttrList[]|null);\n  }\n}\n\n/** Properties of a NameAttrList. */\nexport declare interface INameAttrList {\n  /** NameAttrList name */\n  name?: (string|null);\n\n  /** NameAttrList attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a NodeDef. */\nexport declare interface INodeDef {\n  /** NodeDef name */\n  name?: (string|null);\n\n  /** NodeDef op */\n  op?: (string|null);\n\n  /** NodeDef input */\n  input?: (string[]|null);\n\n  /** NodeDef device */\n  device?: (string|null);\n\n  /** NodeDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a VersionDef. */\nexport declare interface IVersionDef {\n  /** VersionDef producer */\n  producer?: (number|null);\n\n  /** VersionDef minConsumer */\n  minConsumer?: (number|null);\n\n  /** VersionDef badConsumers */\n  badConsumers?: (number[]|null);\n}\n\n/** Properties of a GraphDef. */\nexport declare interface IGraphDef {\n  /** GraphDef node */\n  node?: (INodeDef[]|null);\n\n  /** GraphDef versions */\n  versions?: (IVersionDef|null);\n\n  /** GraphDef library */\n  library?: (IFunctionDefLibrary|null);\n}\n\n/** Properties of a CollectionDef. */\nexport declare interface ICollectionDef {\n  /** CollectionDef nodeList */\n  nodeList?: (CollectionDef.INodeList|null);\n\n  /** CollectionDef bytesList */\n  bytesList?: (CollectionDef.IBytesList|null);\n\n  /** CollectionDef int64List */\n  int64List?: (CollectionDef.IInt64List|null);\n\n  /** CollectionDef floatList */\n  floatList?: (CollectionDef.IFloatList|null);\n\n  /** CollectionDef anyList */\n  anyList?: (CollectionDef.IAnyList|null);\n}\n\nexport namespace CollectionDef {\n  /** Properties of a NodeList. */\n  export declare interface INodeList {\n    /** NodeList value */\n    value?: (string[]|null);\n  }\n\n  /** Properties of a BytesList. */\n  export declare interface IBytesList {\n    /** BytesList value */\n    value?: (Uint8Array[]|null);\n  }\n\n  /** Properties of an Int64List. */\n  export declare interface IInt64List {\n    /** Int64List value */\n    value?: ((number | string)[]|null);\n  }\n\n  /** Properties of a FloatList. */\n  export declare interface IFloatList {\n    /** FloatList value */\n    value?: (number[]|null);\n  }\n\n  /** Properties of an AnyList. */\n  export declare interface IAnyList {\n    /** AnyList value */\n    value?: (IAny[]|null);\n  }\n}\n\n/** Properties of a SaverDef. */\nexport declare interface ISaverDef {\n  /** SaverDef filenameTensorName */\n  filenameTensorName?: (string|null);\n\n  /** SaverDef saveTensorName */\n  saveTensorName?: (string|null);\n\n  /** SaverDef restoreOpName */\n  restoreOpName?: (string|null);\n\n  /** SaverDef maxToKeep */\n  maxToKeep?: (number|null);\n\n  /** SaverDef sharded */\n  sharded?: (boolean|null);\n\n  /** SaverDef keepCheckpointEveryNHours */\n  keepCheckpointEveryNHours?: (number|null);\n\n  /** SaverDef version */\n  version?: (SaverDef.CheckpointFormatVersion|null);\n}\n\nexport namespace SaverDef {\n  /** CheckpointFormatVersion enum. */\n  export enum CheckpointFormatVersion {'LEGACY' = 0, 'V1' = 1, 'V2' = 2}\n}\n\n/** Properties of a TensorInfo. */\nexport declare interface ITensorInfo {\n  /** TensorInfo name */\n  name?: (string|null);\n\n  /** TensorInfo cooSparse */\n  cooSparse?: (TensorInfo.ICooSparse|null);\n\n  /** TensorInfo dtype */\n  dtype?: (DataType|string|null);\n\n  /** TensorInfo tensorShape */\n  tensorShape?: (ITensorShape|null);\n\n  /** Resource id tensor was originally assigned to.  */\n  resourceId?: (number|null);\n}\n\nexport namespace TensorInfo {\n  /** Properties of a CooSparse. */\n  export declare interface ICooSparse {\n    /** CooSparse valuesTensorName */\n    valuesTensorName?: (string|null);\n\n    /** CooSparse indicesTensorName */\n    indicesTensorName?: (string|null);\n\n    /** CooSparse denseShapeTensorName */\n    denseShapeTensorName?: (string|null);\n  }\n}\n\n/** Properties of a SignatureDef. */\nexport declare interface ISignatureDef {\n  /** SignatureDef inputs */\n  inputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef outputs */\n  outputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef methodName */\n  methodName?: (string|null);\n}\n\n/** Properties of an AssetFileDef. */\nexport declare interface IAssetFileDef {\n  /** AssetFileDef tensorInfo */\n  tensorInfo?: (ITensorInfo|null);\n\n  /** AssetFileDef filename */\n  filename?: (string|null);\n}\n\n/** Properties of an OpDef. */\nexport declare interface IOpDef {\n  /** OpDef name */\n  name?: (string|null);\n\n  /** OpDef inputArg */\n  inputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef outputArg */\n  outputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef attr */\n  attr?: (OpDef.IAttrDef[]|null);\n\n  /** OpDef deprecation */\n  deprecation?: (OpDef.IOpDeprecation|null);\n\n  /** OpDef summary */\n  summary?: (string|null);\n\n  /** OpDef description */\n  description?: (string|null);\n\n  /** OpDef isCommutative */\n  isCommutative?: (boolean|null);\n\n  /** OpDef isAggregate */\n  isAggregate?: (boolean|null);\n\n  /** OpDef isStateful */\n  isStateful?: (boolean|null);\n\n  /** OpDef allowsUninitializedInput */\n  allowsUninitializedInput?: (boolean|null);\n}\n\nexport namespace OpDef {\n  /** Properties of an ArgDef. */\n  export declare interface IArgDef {\n    /** ArgDef name */\n    name?: (string|null);\n\n    /** ArgDef description */\n    description?: (string|null);\n\n    /** ArgDef type */\n    type?: (DataType|null);\n\n    /** ArgDef typeAttr */\n    typeAttr?: (string|null);\n\n    /** ArgDef numberAttr */\n    numberAttr?: (string|null);\n\n    /** ArgDef typeListAttr */\n    typeListAttr?: (string|null);\n\n    /** ArgDef isRef */\n    isRef?: (boolean|null);\n  }\n\n  /** Properties of an AttrDef. */\n  export declare interface IAttrDef {\n    /** AttrDef name */\n    name?: (string|null);\n\n    /** AttrDef type */\n    type?: (string|null);\n\n    /** AttrDef defaultValue */\n    defaultValue?: (IAttrValue|null);\n\n    /** AttrDef description */\n    description?: (string|null);\n\n    /** AttrDef hasMinimum */\n    hasMinimum?: (boolean|null);\n\n    /** AttrDef minimum */\n    minimum?: (number|string|null);\n\n    /** AttrDef allowedValues */\n    allowedValues?: (IAttrValue|null);\n  }\n\n  /** Properties of an OpDeprecation. */\n  export declare interface IOpDeprecation {\n    /** OpDeprecation version */\n    version?: (number|null);\n\n    /** OpDeprecation explanation */\n    explanation?: (string|null);\n  }\n}\n\n/** Properties of an OpList. */\nexport declare interface IOpList {\n  /** OpList op */\n  op?: (IOpDef[]|null);\n}\n\n/** Properties of a MetaGraphDef. */\nexport declare interface IMetaGraphDef {\n  /** MetaGraphDef metaInfoDef */\n  metaInfoDef?: (MetaGraphDef.IMetaInfoDef|null);\n\n  /** MetaGraphDef graphDef */\n  graphDef?: (IGraphDef|null);\n\n  /** MetaGraphDef saverDef */\n  saverDef?: (ISaverDef|null);\n\n  /** MetaGraphDef collectionDef */\n  collectionDef?: ({[k: string]: ICollectionDef}|null);\n\n  /** MetaGraphDef signatureDef */\n  signatureDef?: ({[k: string]: ISignatureDef}|null);\n\n  /** MetaGraphDef assetFileDef */\n  assetFileDef?: (IAssetFileDef[]|null);\n}\n\nexport namespace MetaGraphDef {\n  /** Properties of a MetaInfoDef. */\n  export declare interface IMetaInfoDef {\n    /** MetaInfoDef metaGraphVersion */\n    metaGraphVersion?: (string|null);\n\n    /** MetaInfoDef strippedOpList */\n    strippedOpList?: (IOpList|null);\n\n    /** MetaInfoDef anyInfo */\n    anyInfo?: (IAny|null);\n\n    /** MetaInfoDef tags */\n    tags?: (string[]|null);\n\n    /** MetaInfoDef tensorflowVersion */\n    tensorflowVersion?: (string|null);\n\n    /** MetaInfoDef tensorflowGitVersion */\n    tensorflowGitVersion?: (string|null);\n  }\n}\n\n/** Properties of a SavedModel. */\nexport declare interface ISavedModel {\n  /** SavedModel savedModelSchemaVersion */\n  savedModelSchemaVersion?: (number|string|null);\n\n  /** SavedModel metaGraphs */\n  metaGraphs?: (IMetaGraphDef[]|null);\n}\n\n/** Properties of a FunctionDefLibrary. */\nexport declare interface IFunctionDefLibrary {\n  /** FunctionDefLibrary function */\n  'function'?: (IFunctionDef[]|null);\n\n  /** FunctionDefLibrary gradient */\n  gradient?: (IGradientDef[]|null);\n}\n\n/** Properties of a FunctionDef. */\nexport declare interface IFunctionDef {\n  /** FunctionDef signature */\n  signature?: (IOpDef|null);\n\n  /** FunctionDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n\n  /** FunctionDef nodeDef */\n  nodeDef?: (INodeDef[]|null);\n\n  /** FunctionDef ret */\n  ret?: ({[k: string]: string}|null);\n}\n\n/** Properties of a GradientDef. */\nexport declare interface IGradientDef {\n  /** GradientDef functionName */\n  functionName?: (string|null);\n\n  /** GradientDef gradientFunc */\n  gradientFunc?: (string|null);\n}\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {clone, Tensor, util} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {ResourceManager} from '../../executor/resource_manager';\nimport {Node, ValueType} from '../types';\n\nexport function getParamValue(\n    paramName: string, node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext, resourceManager?: ResourceManager): ValueType {\n  const inputParam = node.inputParams[paramName];\n  if (inputParam && inputParam.inputIndexStart !== undefined) {\n    const start = inputParam.inputIndexStart;\n    const end = inputParam.inputIndexEnd === 0 ?\n        undefined :\n        (inputParam.inputIndexEnd === undefined ? start + 1 :\n                                                  inputParam.inputIndexEnd);\n    const shiftedStart = start < 0 ? node.inputNames.length + start : start;\n    if (inputParam.type === 'tensor') {\n      return getTensor(\n          node.inputNames[shiftedStart], tensorMap, context, resourceManager);\n    }\n    if (inputParam.type === 'tensors') {\n      // TODO(mattSoulanille): This filters out NoOp nodes during execution, but\n      // these should really never be in the execution graph in the first place.\n      // They're necessary for ordering the graph, but should not be visible\n      // during execution. Perhaps have different sets of children, one for\n      // control dependencies and another for real dependencies.\n      const inputs = node.inputs.slice(start, end);\n      const inputNames = node.inputNames.slice(start, end)\n        .filter((_name, index) => inputs[index]?.op !== 'NoOp');\n\n      return inputNames.map(\n          name => getTensor(name, tensorMap, context, resourceManager));\n    }\n    const tensor = getTensor(\n        node.inputNames[shiftedStart], tensorMap, context, resourceManager);\n    const data = tensor.dataSync();\n    return inputParam.type === 'number' ?\n        data[0] :\n        util.toNestedArray(tensor.shape, data);\n  }\n  const attrParam = node.attrParams[paramName];\n  return attrParam && attrParam.value;\n}\n\n/**\n * Retrieve the tensor from tensorsMap based on input name.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n * @param context contains tensors and information for running the current node.\n * @param resourceManager Optional. Contains global resources of the model.\n */\nexport function getTensor(\n    name: string, tensorsMap: NamedTensorsMap, context: ExecutionContext,\n    resourceManager?: ResourceManager): Tensor {\n  const [nodeName, index] = parseNodeName(name, context);\n\n  if (resourceManager != null) {\n    const tensor = resourceManager.getHashTableHandleByName(nodeName);\n    if (tensor != null) {\n      return tensor;\n    }\n  }\n\n  const contextId = context.currentContextIds.find(contextId => {\n    return !!tensorsMap[getNodeNameWithContextId(nodeName, contextId)];\n  });\n\n  return contextId !== undefined ?\n      tensorsMap[getNodeNameWithContextId(nodeName, contextId)][index] :\n      undefined;\n}\n\n/**\n * Retrieve the tensors based on input name for current context.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n */\nexport function getTensorsForCurrentContext(\n    name: string, tensorsMap: NamedTensorsMap,\n    context: ExecutionContext): Tensor[] {\n  return tensorsMap[getNodeNameWithContextId(name, context.currentContextId)];\n}\n\n/**\n * Returns the node name, outputName and index from the Node input name.\n * @param inputName The input name of the node, in format of\n * node_name:output_index, i.e. MatMul:0, if the output_index is not set, it is\n * default to 0.\n * If the input name contains output name i.e. StringSplit:indices:0, it will\n * return ['StringSplit', 0, 'indices'].\n */\nexport function getNodeNameAndIndex(\n    inputName: string, context?: ExecutionContext): [string, number, string] {\n  const [nodeName, index, outputName] = parseNodeName(inputName, context);\n\n  return [\n    getNodeNameWithContextId(nodeName, context && context.currentContextId),\n    index, outputName\n  ];\n}\n\nfunction getNodeNameWithContextId(name: string, contextId?: string): string {\n  return !!contextId ? `${name}-${contextId}` : name;\n}\n\nexport function parseNodeName(\n    name: string, context?: ExecutionContext): [string, number, string?] {\n  if (name === '') {\n    return ['', 0, undefined];\n  }\n\n  const isCacheEnabled = context != null && context.parseNodeNameCache != null;\n  if (isCacheEnabled) {\n    const cachedResult = context.parseNodeNameCache.get(name);\n    if (cachedResult != null) {\n      return cachedResult;\n    }\n  }\n  const parts = name.split(':');\n  let result: [string, number, string?];\n  if (parts.length === 1) {\n    result = [name, 0, undefined];\n  } else {\n    const nodeName = parts[0];\n    const outputName = parts.length === 3 ? parts[1] : undefined;\n    const index = Number(parts[parts.length - 1]);\n    result = [nodeName, index, outputName];\n  }\n  if (isCacheEnabled) {\n    context.parseNodeNameCache.set(name, result);\n  }\n  return result;\n}\n\nexport function split(arr: number[], size: number) {\n  const res = [];\n  for (let i = 0; i < arr.length; i += size) {\n    res.push(arr.slice(i, i + size));\n  }\n  return res;\n}\nexport function getPadding(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): ValueType {\n  let pad = getParamValue('pad', node, tensorMap, context);\n  if (pad === 'explicit') {\n    // This is 1d array, we need to convert it to 2d array\n    pad = getParamValue('explicitPaddings', node, tensorMap, context);\n    const explicitPadding: [\n      [number, number], [number, number], [number, number], [number, number]\n    ] = [[0, 0], [0, 0], [0, 0], [0, 0]];\n    for (let i = 0; i < 4; i++) {\n      explicitPadding[i][0] = (pad as number[])[i * 2];\n      explicitPadding[i][1] = (pad as number[])[i * 2 + 1];\n    }\n    return explicitPadding;\n  }\n  return pad;\n}\n\n/**\n *  Reuse the tensor if it is marked as keep, otherwise clone the tensor to\n *  avoid disposal. This is important for TensorArray and TensorList ops, since\n *  internally they use a tensor as the id for TensorArray and TensorList, and\n * to simplify lookup, they also use Tensor.id as the key to the internal map.\n * These id tensors have been marked as kept in the backend, we need avoid clone\n * them in order to create new Tensor.id.\n * @param tensor\n */\nexport function cloneTensor(tensor: Tensor): Tensor {\n  return tensor.kept ? tensor : clone(tensor);\n}\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Add',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'AddV2',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'AddN',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'tensors',\n        'type': 'tensors'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'BiasAdd',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sub',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'RealDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Div',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DivNoNan',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FloorDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Mul',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Maximum',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Minimum',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Pow',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SquaredDifference',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Mod',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FloorMod',\n    'category': 'arithmetic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  }\n];\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Abs',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Acos',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Asin',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Atan',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Atan2',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'y',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Ceil',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ClipByValue',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'clipValueMin',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'clipValueMax',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Complex',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'real',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'imag',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ComplexAbs',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Cos',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Cosh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Elu',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Exp',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Floor',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Log',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Imag',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Neg',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Real',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Prelu',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'alpha',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Relu',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Relu6',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Selu',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sigmoid',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sin',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sinh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Rsqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Square',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Tan',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Tanh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sign',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Round',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Expm1',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Log1p',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reciprocal',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Softplus',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Asinh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Acosh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Atanh',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Erf',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LeakyRelu',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 0.2\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IsNan',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IsFinite',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IsInf',\n    'category': 'basic_math',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'EmptyTensorList',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'start': 1,\n        'name': 'maxNumElements',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LoopCond',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'pred',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Switch',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'data',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'pred',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Merge',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'tensors',\n        'type': 'tensors'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Enter',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'frame_name',\n        'name': 'frameName',\n        'type': 'string'\n      },\n      {\n        'tfName': 'is_constant',\n        'name': 'isConstant',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Exit',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NextIteration',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'size',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'element_shape',\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'tfName': 'dynamic_size',\n        'name': 'dynamicSize',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'clear_after_read',\n        'name': 'clearAfterRead',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'identical_element_shapes',\n        'name': 'identicalElementShapes',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'tensor_array_name',\n        'name': 'name',\n        'type': 'string'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayWriteV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'index',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayReadV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'index',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayGatherV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'element_shape',\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayScatterV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayConcatV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'element_shape_except0',\n        'name': 'elementShapeExcept0',\n        'type': 'shape',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArraySplitV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'lengths',\n        'type': 'number[]'\n      },\n      {\n        'start': 3,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArraySizeV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'flowIn',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayCloseV3',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorArrayId',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'StatelessIf',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'cond',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'then_branch',\n        'name': 'thenBranch',\n        'type': 'func'\n      },\n      {\n        'tfName': 'else_branch',\n        'name': 'elseBranch',\n        'type': 'func'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'If',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'cond',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'then_branch',\n        'name': 'thenBranch',\n        'type': 'func'\n      },\n      {\n        'tfName': 'else_branch',\n        'name': 'elseBranch',\n        'type': 'func'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'StatelessWhile',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'cond',\n        'name': 'cond',\n        'type': 'func'\n      },\n      {\n        'tfName': 'body',\n        'name': 'body',\n        'type': 'func'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'While',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'cond',\n        'name': 'cond',\n        'type': 'func'\n      },\n      {\n        'tfName': 'body',\n        'name': 'body',\n        'type': 'func'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListScatter',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListScatterV2',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'start': 3,\n        'name': 'numElements',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListGather',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListGetItem',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'index',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListSetItem',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'index',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListReserve',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'start': 1,\n        'name': 'numElements',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListFromTensor',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListStack',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'num_elements',\n        'name': 'numElements',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListSplit',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'start': 2,\n        'name': 'lengths',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListConcat',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_shape',\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListConcatV2',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_shape',\n        'name': 'elementShape',\n        'type': 'shape'\n      },\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListPopBack',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'elementShape',\n        'type': 'shape'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListPushBack',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'element_dtype',\n        'name': 'elementDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListLength',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorListResize',\n    'category': 'control',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensorListId',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'size',\n        'type': 'number'\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'AvgPool',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'ksize',\n        'name': 'kernelSize',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'ksize',\n        'name': 'kernelSize',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': [],\n        'notSupported': true\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'MaxPoolWithArgmax',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'ksize',\n        'name': 'kernelSize',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'include_batch_in_index',\n        'name': 'includeBatchInIndex',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'AvgPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'ksize',\n        'name': 'kernelSize',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'ksize',\n        'name': 'kernelSize',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv1D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'stride',\n        'name': 'stride',\n        'type': 'number'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NWC'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'dilation',\n        'name': 'dilation',\n        'type': 'number',\n        'defaultValue': 1\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv2D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'useCudnnOnGpu',\n        'name': 'useCudnnOnGpu',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': '_FusedConv2D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'num_args',\n        'name': 'numArgs',\n        'type': 'number'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'use_cudnn_on_gpu',\n        'name': 'useCudnnOnGpu',\n        'type': 'bool',\n        'defaultValue': true\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'defaultValue': [\n          1,\n          1,\n          1,\n          1\n        ]\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.0001\n      },\n      {\n        'tfName': 'leakyrelu_alpha',\n        'name': 'leakyreluAlpha',\n        'type': 'number',\n        'defaultValue': 0.2\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv2DBackpropInput',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 2,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      },\n      {\n        'start': 0,\n        'name': 'outputShape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2d',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'input',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2dNative',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'input',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedDepthwiseConv2dNative',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'num_args',\n        'name': 'numArgs',\n        'type': 'number'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]',\n        'defaultValue': [\n          1,\n          1,\n          1,\n          1\n        ]\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'explicit_paddings',\n        'name': 'explicitPaddings',\n        'type': 'number[]',\n        'defaultValue': []\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv3D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {\n        'tfName': 'dilations',\n        'name': 'dilations',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Dilation2D',\n    'category': 'convolution',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'filter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'strides',\n        'name': 'strides',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'rates',\n        'name': 'dilations',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'padding',\n        'name': 'pad',\n        'type': 'string'\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Fill',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      },\n      {\n        'start': 1,\n        'name': 'value',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LinSpace',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'start',\n        'type': 'number'\n      },\n      {\n        'start': 1,\n        'name': 'stop',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'num',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'OneHot',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'depth',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'onValue',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {\n        'start': 3,\n        'name': 'offValue',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'name': 'axis',\n        'type': 'number',\n        'notSupported': true\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Ones',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'OnesLike',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'RandomStandardNormal',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'seed',\n        'name': 'seed',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'T',\n        'name': 'T',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'RandomUniform',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'minval',\n        'name': 'minval',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'maxval',\n        'name': 'maxval',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'seed',\n        'name': 'seed',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {\n        'tfName': 'T',\n        'name': 'T',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'RandomUniformInt',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'minval',\n        'name': 'minval',\n        'type': 'number'\n      },\n      {\n        'tfName': 'maxval',\n        'name': 'maxval',\n        'type': 'number'\n      },\n      {\n        'tfName': 'seed',\n        'name': 'seed',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Range',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'start',\n        'type': 'number'\n      },\n      {\n        'start': 1,\n        'name': 'stop',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'step',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'Tidx',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TruncatedNormal',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'means',\n        'name': 'mean',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'stddev',\n        'name': 'stdDev',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {\n        'tfName': 'seed',\n        'name': 'seed',\n        'type': 'number'\n      },\n      {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'T',\n        'name': 'T',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Zeros',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ZerosLike',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Multinomial',\n    'category': 'creation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'logits',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'numSamples',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'seed',\n        'name': 'seed',\n        'type': 'number'\n      },\n      {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'output_dtype',\n        'name': 'output_dtype',\n        'type': 'dtype'\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'NonMaxSuppressionV2',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'boxes',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scores',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'maxOutputSize',\n        'type': 'number'\n      },\n      {\n        'start': 3,\n        'name': 'iouThreshold',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV3',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'boxes',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scores',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'maxOutputSize',\n        'type': 'number'\n      },\n      {\n        'start': 3,\n        'name': 'iouThreshold',\n        'type': 'number'\n      },\n      {\n        'start': 4,\n        'name': 'scoreThreshold',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV4',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'boxes',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scores',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'maxOutputSize',\n        'type': 'number'\n      },\n      {\n        'start': 3,\n        'name': 'iouThreshold',\n        'type': 'number'\n      },\n      {\n        'start': 4,\n        'name': 'scoreThreshold',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'T_threshold',\n        'name': 'threshold',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'pad_to_max_output_size',\n        'name': 'padToMaxOutputSize',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV5',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'boxes',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scores',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'maxOutputSize',\n        'type': 'number'\n      },\n      {\n        'start': 3,\n        'name': 'iouThreshold',\n        'type': 'number'\n      },\n      {\n        'start': 4,\n        'name': 'scoreThreshold',\n        'type': 'number'\n      },\n      {\n        'start': 5,\n        'name': 'softNmsSigma',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Where',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'condition',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ListDiff',\n    'category': 'dynamic',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'y',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  }\n];\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'LowerBound',\n    'category': 'evaluation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'sortedSequence',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'values',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TopKV2',\n    'category': 'evaluation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'k',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'sorted',\n        'name': 'sorted',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'UpperBound',\n    'category': 'evaluation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'sortedSequence',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'values',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Unique',\n    'category': 'evaluation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'UniqueV2',\n    'category': 'evaluation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'PlaceholderWithDefault',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'default',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'shape',\n        'name': 'shape',\n        'type': 'shape'\n      },\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Placeholder',\n    'category': 'graph',\n    'attrs': [\n      {\n        'tfName': 'shape',\n        'name': 'shape',\n        'type': 'shape'\n      },\n      {\n        'tfName': 'dtype',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Const',\n    'category': 'graph'\n  },\n  {\n    'tfOpName': 'Identity',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IdentityN',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'x',\n        'type': 'tensors'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Snapshot',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Rank',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Size',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Shape',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ShapeN',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'x',\n        'type': 'tensors'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Print',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'data',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'message',\n        'name': 'message',\n        'type': 'string'\n      },\n      {\n        'tfName': 'first_n',\n        'name': 'firstN',\n        'type': 'number',\n        'notSupported': true\n      },\n      {\n        'tfName': 'summarize',\n        'name': 'summarize',\n        'type': 'number',\n        'defaultValue': 3\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NoOp',\n    'category': 'graph',\n    'inputs': []\n  },\n  {\n    'tfOpName': 'StopGradient',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FakeQuantWithMinMaxVars',\n    'category': 'graph',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'min',\n        'name': 'min',\n        'type': 'number'\n      },\n      {\n        'tfName': 'max',\n        'name': 'max',\n        'type': 'number'\n      }\n    ]\n  }\n];\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'HashTable',\n    'category': 'hash_table',\n    'inputs': [],\n    'attrs': [\n      {\n        'tfName': 'shared_name',\n        'name': 'sharedName',\n        'type': 'string'\n      },\n      {\n        'tfName': 'use_node_name_sharing',\n        'name': 'useNodeNameSharing',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'key_dtype',\n        'name': 'keyDType',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'value_dtype',\n        'name': 'valueDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'HashTableV2',\n    'category': 'hash_table',\n    'inputs': [],\n    'attrs': [\n      {\n        'tfName': 'shared_name',\n        'name': 'sharedName',\n        'type': 'string'\n      },\n      {\n        'tfName': 'use_node_name_sharing',\n        'name': 'useNodeNameSharing',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'key_dtype',\n        'name': 'keyDType',\n        'type': 'dtype'\n      },\n      {\n        'tfName': 'value_dtype',\n        'name': 'valueDType',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableImport',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'keys',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'values',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'Tin',\n        'name': 'tIn',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableImportV2',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'keys',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'values',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'Tin',\n        'name': 'tIn',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableFind',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'keys',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'defaultValue',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'Tin',\n        'name': 'tIn',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableFindV2',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'keys',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'defaultValue',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'Tin',\n        'name': 'tIn',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'Tout',\n        'name': 'tOut',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableSize',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LookupTableSizeV2',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'InitializeTable',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'keys',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'values',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'InitializeTableV2',\n    'category': 'hash_table',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tableHandle',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'keys',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'values',\n        'type': 'tensor'\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ResizeBilinear',\n    'category': 'image',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'images',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'size',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'align_corners',\n        'name': 'alignCorners',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'half_pixel_centers',\n        'name': 'halfPixelCenters',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ResizeNearestNeighbor',\n    'category': 'image',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'images',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'size',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'align_corners',\n        'name': 'alignCorners',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'half_pixel_centers',\n        'name': 'halfPixelCenters',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'CropAndResize',\n    'category': 'image',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'image',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'boxes',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'boxInd',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'cropSize',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'method',\n        'name': 'method',\n        'type': 'string'\n      },\n      {\n        'tfName': 'extrapolation_value',\n        'name': 'extrapolationValue',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ImageProjectiveTransformV3',\n    'category': 'image',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'images',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'transforms',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'outputShape',\n        'type': 'number[]'\n      },\n      {\n        'start': 3,\n        'name': 'fillValue',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'interpolation',\n        'name': 'interpolation',\n        'type': 'string'\n      },\n      {\n        'tfName': 'fill_mode',\n        'name': 'fillMode',\n        'type': 'string'\n      }\n    ]\n  }\n];\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Equal',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'NotEqual',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Greater',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'GreaterEqual',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Less',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LessEqual',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LogicalAnd',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LogicalNot',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LogicalOr',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Select',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'condition',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SelectV2',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'condition',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'BitwiseAnd',\n    'category': 'logical',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'y',\n        'type': 'tensor'\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': '_FusedMatMul',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'end': 0,\n        'name': 'args',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'num_args',\n        'name': 'numArgs',\n        'type': 'number'\n      },\n      {\n        'tfName': 'fused_ops',\n        'name': 'fusedOps',\n        'type': 'string[]',\n        'defaultValue': []\n      },\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.0001\n      },\n      {\n        'tfName': 'transpose_a',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'transpose_b',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'leakyrelu_alpha',\n        'name': 'leakyreluAlpha',\n        'type': 'number',\n        'defaultValue': 0.2\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'MatMul',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'transpose_a',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'transpose_b',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMul',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMulV2',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'b',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Transpose',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'perm',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Einsum',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'tensors',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'equation',\n        'name': 'equation',\n        'type': 'string'\n      },\n      {\n        'tfName': 'N',\n        'name': 'n',\n        'type': 'number',\n        'defaultValue': 2\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'MatrixBandPart',\n    'category': 'matrices',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'a',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'numLower',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'numUpper',\n        'type': 'tensor'\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'EuclideanNorm',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool',\n        'defaultValue': false\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNorm',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scale',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'offset',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'mean',\n        'type': 'tensor'\n      },\n      {\n        'start': 4,\n        'name': 'variance',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV2',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scale',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'offset',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'mean',\n        'type': 'tensor'\n      },\n      {\n        'start': 4,\n        'name': 'variance',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV3',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'scale',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'offset',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'mean',\n        'type': 'tensor'\n      },\n      {\n        'start': 4,\n        'name': 'variance',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LRN',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'depth_radius',\n        'name': 'radius',\n        'type': 'number',\n        'defaultValue': 5\n      },\n      {\n        'tfName': 'bias',\n        'name': 'bias',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {\n        'tfName': 'beta',\n        'name': 'beta',\n        'type': 'number',\n        'defaultValue': 0.5\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Softmax',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LogSoftmax',\n    'category': 'normalization',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Bincount',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'size',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'weights',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DenseBincount',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'size',\n        'type': 'number'\n      },\n      {\n        'start': 2,\n        'name': 'weights',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'binary_output',\n        'name': 'binaryOutput',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Max',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Mean',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Min',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Sum',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'All',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Any',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ArgMax',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ArgMin',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Prod',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Cumprod',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'exclusive',\n        'name': 'exclusive',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'reverse',\n        'name': 'reverse',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Cumsum',\n    'category': 'reduction',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'exclusive',\n        'name': 'exclusive',\n        'type': 'bool'\n      },\n      {\n        'tfName': 'reverse',\n        'name': 'reverse',\n        'type': 'bool'\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ConcatV2',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'end': -1,\n        'name': 'tensors',\n        'type': 'tensors'\n      },\n      {\n        'start': -1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'N',\n        'name': 'n',\n        'type': 'number',\n        'defaultValue': 2\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Concat',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 1,\n        'end': 0,\n        'name': 'tensors',\n        'type': 'tensors'\n      },\n      {\n        'start': 0,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'N',\n        'name': 'n',\n        'type': 'number',\n        'defaultValue': 2\n      }\n    ]\n  },\n  {\n    'tfOpName': 'GatherV2',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'axis',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'batch_dims',\n        'name': 'batchDims',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Gather',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'validate_indices',\n        'name': 'validateIndices',\n        'type': 'bool',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reverse',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'dims',\n        'type': 'bool[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ReverseV2',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Slice',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'begin',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'size',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'StridedSlice',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'begin',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'end',\n        'type': 'number[]'\n      },\n      {\n        'start': 3,\n        'name': 'strides',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'begin_mask',\n        'name': 'beginMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'end_mask',\n        'name': 'endMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'new_axis_mask',\n        'name': 'newAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'ellipsis_mask',\n        'name': 'ellipsisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'shrink_axis_mask',\n        'name': 'shrinkAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Pack',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'end': 0,\n        'name': 'tensors',\n        'type': 'tensors'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'name': 'axis',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Unpack',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'name': 'axis',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'num',\n        'name': 'num',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Tile',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'reps',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Split',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'axis',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'start': 1,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'num_split',\n        'name': 'numOrSizeSplits',\n        'type': 'number',\n        'defaultValue': 1\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SplitV',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'numOrSizeSplits',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'axis',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ScatterNd',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'values',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'GatherNd',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SparseToDense',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'sparseIndices',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'outputShape',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'sparseValues',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'defaultValue',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'validate_indices',\n        'name': 'validateIndices',\n        'type': 'bool',\n        'defaultValue': false,\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorScatterUpdate',\n    'category': 'slice_join',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'tensor',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'values',\n        'type': 'tensor'\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'SparseFillEmptyRows',\n    'category': 'sparse',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'values',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'denseShape',\n        'type': 'tensor'\n      },\n      {\n        'start': 3,\n        'name': 'defaultValue',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SparseReshape',\n    'category': 'sparse',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'inputIndices',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'inputShape',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'newShape',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SparseSegmentMean',\n    'category': 'sparse',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'data',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'segmentIds',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SparseSegmentSum',\n    'category': 'sparse',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'data',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'indices',\n        'type': 'tensor'\n      },\n      {\n        'start': 2,\n        'name': 'segmentIds',\n        'type': 'tensor'\n      }\n    ]\n  }\n];\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'FFT',\n    'category': 'spectral',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IFFT',\n    'category': 'spectral',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'RFFT',\n    'category': 'spectral',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IRFFT',\n    'category': 'spectral',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  }\n];\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'StaticRegexReplace',\n    'category': 'string',\n    'inputs': [\n      {\n      'start': 0,\n        'name': 'input',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'pattern',\n        'name': 'pattern',\n        'type': 'string'\n      },\n      {\n        'tfName': 'rewrite',\n        'name': 'rewrite',\n        'type': 'string'\n      },\n      {\n        'tfName': 'replace_global',\n        'name': 'replaceGlobal',\n        'type': 'bool'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'StringNGrams',\n    'category': 'string',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'data',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'dataSplits',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'separator',\n        'name': 'separator',\n        'type': 'string'\n      },\n      {\n        'tfName': 'ngram_widths',\n        'name': 'nGramWidths',\n        'type': 'number[]'\n      },\n      {\n        'tfName': 'left_pad',\n        'name': 'leftPad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'right_pad',\n        'name': 'rightPad',\n        'type': 'string'\n      },\n      {\n        'tfName': 'pad_width',\n        'name': 'padWidth',\n        'type': 'number'\n      },\n      {\n        'tfName': 'preserve_short_sequences',\n        'name': 'preserveShortSequences',\n        'type': 'bool'\n      }\n    ],\n    'outputs': [\n      'ngrams',\n      'ngrams_splits'\n    ]\n  },\n  {\n    'tfOpName': 'StringSplit',\n    'category': 'string',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'input',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'delimiter',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'skip_empty',\n        'name': 'skipEmpty',\n        'type': 'bool'\n      }\n    ],\n    'outputs': [\n      'indices',\n      'values',\n      'shape'\n    ]\n  },\n  {\n    'tfOpName': 'StringToHashBucketFast',\n    'category': 'string',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'input',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'num_buckets',\n        'name': 'numBuckets',\n        'type': 'number'\n      }\n    ]\n  }\n]\n;\n", "\n/**\n * @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Cast',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'SrcT',\n        'name': 'sdtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {\n        'tfName': 'DstT',\n        'name': 'dtype',\n        'type': 'dtype'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'ExpandDims',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'axis',\n        'type': 'number'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'MirrorPad',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'padding',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'mode',\n        'name': 'mode',\n        'type': 'string'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Pad',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'padding',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'constant_value',\n        'name': 'constantValue',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'PadV2',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'padding',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'constantValue',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reshape',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'EnsureShape',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Squeeze',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'tfDeprecatedName': 'squeeze_dims',\n        'name': 'axis',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'SpaceToBatchND',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'blockShape',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'paddings',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'BatchToSpaceND',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'blockShape',\n        'type': 'number[]'\n      },\n      {\n        'start': 2,\n        'name': 'crops',\n        'type': 'number[]'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DepthToSpace',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': [\n      {\n        'tfName': 'block_size',\n        'name': 'blockSize',\n        'type': 'number'\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string'\n      }\n    ]\n  },\n  {\n    'tfOpName': 'BroadcastTo',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 'x',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 'shape',\n        'type': 'number[]'\n      }\n    ],\n    'attrs': []\n  },\n  {\n    'tfOpName': 'BroadcastArgs',\n    'category': 'transformation',\n    'inputs': [\n      {\n        'start': 0,\n        'name': 's0',\n        'type': 'tensor'\n      },\n      {\n        'start': 1,\n        'name': 's1',\n        'type': 'tensor'\n      }\n    ],\n    'attrs': []\n  }\n]\n;\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, env} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\n\nimport {getRegisteredOp} from './custom_op/register';\nimport {getNodeNameAndIndex} from './executors/utils';\nimport * as arithmetic from './op_list/arithmetic';\nimport * as basicMath from './op_list/basic_math';\nimport * as control from './op_list/control';\nimport * as convolution from './op_list/convolution';\nimport * as creation from './op_list/creation';\nimport * as dynamic from './op_list/dynamic';\nimport * as evaluation from './op_list/evaluation';\nimport * as graph from './op_list/graph';\nimport * as hashTable from './op_list/hash_table';\nimport * as image from './op_list/image';\nimport * as logical from './op_list/logical';\nimport * as matrices from './op_list/matrices';\nimport * as normalization from './op_list/normalization';\nimport * as reduction from './op_list/reduction';\nimport * as sliceJoin from './op_list/slice_join';\nimport * as sparse from './op_list/sparse';\nimport * as spectral from './op_list/spectral';\nimport * as string from './op_list/string';\nimport * as transformation from './op_list/transformation';\nimport {Graph, InputParamValue, Node, OpMapper, ParamValue} from './types';\n\nexport class OperationMapper {\n  private static _instance: OperationMapper;\n\n  private opMappers: {[key: string]: OpMapper};\n\n  // Singleton instance for the mapper\n  public static get Instance() {\n    return this._instance || (this._instance = new this());\n  }\n\n  // Loads the op mapping from the JSON file.\n  private constructor() {\n    const ops = [\n      arithmetic, basicMath, control, convolution, creation, dynamic,\n      evaluation, graph, hashTable, image, logical, matrices, normalization,\n      reduction, sliceJoin, sparse, spectral, string, transformation\n    ];\n    const mappersJson: OpMapper[] = [].concat(...ops.map(op => op.json));\n\n    this.opMappers = mappersJson.reduce<{[key: string]: OpMapper}>(\n        (map, mapper: OpMapper) => {\n          map[mapper.tfOpName] = mapper;\n          return map;\n        },\n        {});\n  }\n\n  // Converts the model inference graph from Tensorflow GraphDef to local\n  // representation for TensorFlow.js API\n  transformGraph(\n      graph: tensorflow.IGraphDef,\n      signature: tensorflow.ISignatureDef = {}): Graph {\n    const tfNodes = graph.node;\n    const placeholders: Node[] = [];\n    const weights: Node[] = [];\n    const initNodes: Node[] = [];\n    const nodes = tfNodes.reduce<{[key: string]: Node}>((map, node) => {\n      map[node.name] = this.mapNode(node);\n      if (node.op.startsWith('Placeholder')) {\n        placeholders.push(map[node.name]);\n      } else if (node.op === 'Const') {\n        weights.push(map[node.name]);\n      } else if (node.input == null || node.input.length === 0) {\n        initNodes.push(map[node.name]);\n      }\n      return map;\n    }, {});\n\n    let inputs: Node[] = [];\n    const outputs: Node[] = [];\n    let inputNodeNameToKey: {[key: string]: string} = {};\n    let outputNodeNameToKey: {[key: string]: string} = {};\n    if (signature != null) {\n      inputNodeNameToKey = this.mapSignatureEntries(signature.inputs);\n      outputNodeNameToKey = this.mapSignatureEntries(signature.outputs);\n    }\n    const allNodes = Object.keys(nodes);\n    allNodes.forEach(key => {\n      const node = nodes[key];\n      node.inputNames.forEach((name, index) => {\n        const [nodeName, , outputName] = getNodeNameAndIndex(name);\n        const inputNode = nodes[nodeName];\n        if (inputNode.outputs != null) {\n          const outputIndex = inputNode.outputs.indexOf(outputName);\n          if (outputIndex !== -1) {\n            const inputName = `${nodeName}:${outputIndex}`;\n            // update the input name to use the mapped output index directly.\n            node.inputNames[index] = inputName;\n          }\n        }\n        node.inputs.push(inputNode);\n        inputNode.children.push(node);\n      });\n    });\n\n    // if signature has not outputs set, add any node that does not have\n    // outputs.\n    if (Object.keys(outputNodeNameToKey).length === 0) {\n      allNodes.forEach(key => {\n        const node = nodes[key];\n        if (node.children.length === 0) {\n          outputs.push(node);\n        }\n      });\n    } else {\n      Object.keys(outputNodeNameToKey).forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        const node = nodes[nodeName];\n        if (node != null) {\n          node.signatureKey = outputNodeNameToKey[name];\n          outputs.push(node);\n        }\n      });\n    }\n\n    if (Object.keys(inputNodeNameToKey).length > 0) {\n      Object.keys(inputNodeNameToKey).forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        const node = nodes[nodeName];\n        if (node) {\n          node.signatureKey = inputNodeNameToKey[name];\n          inputs.push(node);\n        }\n      });\n    } else {\n      inputs = placeholders;\n    }\n\n    let functions = {};\n    if (graph.library != null && graph.library.function != null) {\n      functions = graph.library.function.reduce((functions, func) => {\n        functions[func.signature.name] = this.mapFunction(func);\n        return functions;\n      }, {} as {[key: string]: Graph});\n    }\n\n    const result: Graph =\n        {nodes, inputs, outputs, weights, placeholders, signature, functions};\n\n    if (initNodes.length > 0) {\n      result.initNodes = initNodes;\n    }\n\n    return result;\n  }\n\n  private mapSignatureEntries(entries: {[k: string]: tensorflow.ITensorInfo}) {\n    return Object.keys(entries || {})\n        .reduce<{[key: string]: string}>((prev, curr) => {\n          prev[entries[curr].name] = curr;\n          return prev;\n        }, {});\n  }\n\n  private mapNode(node: tensorflow.INodeDef): Node {\n    // Unsupported ops will cause an error at run-time (not parse time), since\n    // they may not be used by the actual execution subgraph.\n    const mapper =\n        getRegisteredOp(node.op) || this.opMappers[node.op] || {} as OpMapper;\n    if (node.attr == null) {\n      node.attr = {};\n    }\n\n    const newNode: Node = {\n      name: node.name,\n      op: node.op,\n      category: mapper.category,\n      inputNames:\n          (node.input ||\n           []).map(input => input.startsWith('^') ? input.slice(1) : input),\n      inputs: [],\n      children: [],\n      inputParams: {},\n      attrParams: {},\n      rawAttrs: node.attr,\n      outputs: mapper.outputs\n    };\n\n    if (mapper.inputs != null) {\n      newNode.inputParams =\n          mapper.inputs.reduce<{[key: string]: InputParamValue}>(\n              (map, param) => {\n                map[param.name] = {\n                  type: param.type,\n                  inputIndexStart: param.start,\n                  inputIndexEnd: param.end\n                };\n                return map;\n              },\n              {});\n    }\n    if (mapper.attrs != null) {\n      newNode.attrParams =\n          mapper.attrs.reduce<{[key: string]: ParamValue}>((map, param) => {\n            const type = param.type;\n            let value = undefined;\n            switch (param.type) {\n              case 'string':\n                value = getStringParam(\n                    node.attr, param.tfName, param.defaultValue as string);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string);\n                }\n                break;\n              case 'string[]':\n                value = getStringArrayParam(\n                    node.attr, param.tfName, param.defaultValue as string[]);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string[]);\n                }\n                break;\n              case 'number':\n                value = getNumberParam(\n                    node.attr, param.tfName,\n                    (param.defaultValue || 0) as number);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumberParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number);\n                }\n                break;\n              case 'number[]':\n                value = getNumericArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumericArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'bool':\n                value = getBoolParam(\n                    node.attr, param.tfName, param.defaultValue as boolean);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean);\n                }\n                break;\n              case 'bool[]':\n                value = getBoolArrayParam(\n                    node.attr, param.tfName, param.defaultValue as boolean[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean[]);\n                }\n                break;\n              case 'shape':\n                value = getTensorShapeParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'shape[]':\n                value = getTensorShapeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[][]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[][]);\n                }\n                break;\n              case 'dtype':\n                value = getDtypeParam(\n                    node.attr, param.tfName, param.defaultValue as DataType);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType);\n                }\n                break;\n              case 'dtype[]':\n                value = getDtypeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as DataType[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType[]);\n                }\n                break;\n              case 'func':\n                value = getFuncParam(\n                    node.attr, param.tfName, param.defaultValue as string);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getFuncParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string);\n                }\n                break;\n              case 'tensor':\n              case 'tensors':\n                break;\n              default:\n                throw new Error(\n                    `Unsupported param type: ${param.type} for op: ${node.op}`);\n            }\n            map[param.name] = {value, type};\n            return map;\n          }, {});\n    }\n    return newNode;\n  }\n\n  // map the TFunctionDef to TFJS graph object\n  private mapFunction(functionDef: tensorflow.IFunctionDef): Graph {\n    const tfNodes = functionDef.nodeDef;\n    const placeholders: Node[] = [];\n    const weights: Node[] = [];\n    let nodes: {[key: string]: Node} = {};\n    if (tfNodes != null) {\n      nodes = tfNodes.reduce<{[key: string]: Node}>((map, node) => {\n        map[node.name] = this.mapNode(node);\n        if (node.op === 'Const') {\n          weights.push(map[node.name]);\n        }\n        return map;\n      }, {});\n    }\n    const inputs: Node[] = [];\n    const outputs: Node[] = [];\n\n    functionDef.signature.inputArg.forEach(arg => {\n      const [nodeName, ] = getNodeNameAndIndex(arg.name);\n      const node: Node = {\n        name: nodeName,\n        op: 'Placeholder',\n        inputs: [],\n        inputNames: [],\n        category: 'graph',\n        inputParams: {},\n        attrParams: {dtype: {value: parseDtypeParam(arg.type), type: 'dtype'}},\n        children: []\n      };\n      node.signatureKey = arg.name;\n      inputs.push(node);\n      nodes[nodeName] = node;\n    });\n\n    const allNodes = Object.keys(nodes);\n    allNodes.forEach(key => {\n      const node = nodes[key];\n      node.inputNames.forEach((name, index) => {\n        const [nodeName, , outputName] = getNodeNameAndIndex(name);\n        const inputNode = nodes[nodeName];\n        if (inputNode.outputs != null) {\n          const outputIndex = inputNode.outputs.indexOf(outputName);\n          if (outputIndex !== -1) {\n            const inputName = `${nodeName}:${outputIndex}`;\n            // update the input name to use the mapped output index directly.\n            node.inputNames[index] = inputName;\n          }\n        }\n        node.inputs.push(inputNode);\n        inputNode.children.push(node);\n      });\n    });\n\n    const returnNodeMap = functionDef.ret;\n\n    functionDef.signature.outputArg.forEach(output => {\n      const [nodeName, index] = getNodeNameAndIndex(returnNodeMap[output.name]);\n      const node = nodes[nodeName];\n      if (node != null) {\n        node.defaultOutput = index;\n        outputs.push(node);\n      }\n    });\n\n    const signature = this.mapArgsToSignature(functionDef);\n    return {nodes, inputs, outputs, weights, placeholders, signature};\n  }\n\n  private mapArgsToSignature(functionDef: tensorflow.IFunctionDef):\n      tensorflow.ISignatureDef {\n    return {\n      methodName: functionDef.signature.name,\n      inputs: functionDef.signature.inputArg.reduce(\n          (map, arg) => {\n            map[arg.name] = this.mapArgToTensorInfo(arg);\n            return map;\n          },\n          {} as {[key: string]: tensorflow.ITensorInfo}),\n      outputs: functionDef.signature.outputArg.reduce(\n          (map, arg) => {\n            map[arg.name] = this.mapArgToTensorInfo(arg, functionDef.ret);\n            return map;\n          },\n          {} as {[key: string]: tensorflow.ITensorInfo}),\n    };\n  }\n\n  private mapArgToTensorInfo(\n      arg: tensorflow.OpDef.IArgDef,\n      nameMap?: {[key: string]: string}): tensorflow.ITensorInfo {\n    let name = arg.name;\n    if (nameMap != null) {\n      name = nameMap[name];\n    }\n    return {name, dtype: arg.type};\n  }\n}\n\nexport function decodeBase64(text: string): string {\n  const global = env().global;\n  if (typeof global.atob !== 'undefined') {\n    return global.atob(text);\n  } else if (typeof Buffer !== 'undefined') {\n    return new Buffer(text, 'base64').toString();\n  } else {\n    throw new Error(\n        'Unable to decode base64 in this environment. ' +\n        'Missing built-in atob() or Buffer()');\n  }\n}\n\nexport function parseStringParam(s: []|string, keepCase: boolean): string {\n  const value =\n      Array.isArray(s) ? String.fromCharCode.apply(null, s) : decodeBase64(s);\n  return keepCase ? value : value.toLowerCase();\n}\n\nexport function getStringParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string,\n    keepCase = false): string {\n  const param = attrs[name];\n  if (param != null) {\n    return parseStringParam(param.s, keepCase);\n  }\n  return def;\n}\n\nexport function getBoolParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean): boolean {\n  const param = attrs[name];\n  return param ? param.b : def;\n}\n\nexport function getNumberParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number): number {\n  const param = attrs[name] || {};\n  const value =\n      param['i'] != null ? param['i'] : (param['f'] != null ? param['f'] : def);\n  return (typeof value === 'number') ? value : parseInt(value, 10);\n}\n\nexport function parseDtypeParam(value: string|tensorflow.DataType): DataType {\n  if (typeof (value) === 'string') {\n    // tslint:disable-next-line:no-any\n    value = tensorflow.DataType[value as any];\n  }\n  switch (value) {\n    case tensorflow.DataType.DT_FLOAT:\n    case tensorflow.DataType.DT_HALF:\n      return 'float32';\n    case tensorflow.DataType.DT_INT32:\n    case tensorflow.DataType.DT_INT64:\n    case tensorflow.DataType.DT_INT8:\n    case tensorflow.DataType.DT_UINT8:\n      return 'int32';\n    case tensorflow.DataType.DT_BOOL:\n      return 'bool';\n    case tensorflow.DataType.DT_DOUBLE:\n      return 'float32';\n    case tensorflow.DataType.DT_STRING:\n      return 'string';\n    case tensorflow.DataType.DT_COMPLEX64:\n    case tensorflow.DataType.DT_COMPLEX128:\n      return 'complex64';\n    default:\n      // Unknown dtype error will happen at runtime (instead of parse time),\n      // since these nodes might not be used by the actual subgraph execution.\n      return null;\n  }\n}\n\nexport function getFuncParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: string): string {\n  const param = attrs[name];\n  if (param && param.func) {\n    return param.func.name;\n  }\n  return def;\n}\n\nexport function getDtypeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType): DataType {\n  const param = attrs[name];\n  if (param && param.type) {\n    return parseDtypeParam(param.type);\n  }\n  return def;\n}\n\nexport function getDtypeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType[]): DataType[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.type) {\n    return param.list.type.map(v => parseDtypeParam(v));\n  }\n  return def;\n}\n\nexport function parseTensorShapeParam(shape: tensorflow.ITensorShape): number[]|\n    undefined {\n  if (shape.unknownRank) {\n    return undefined;\n  }\n  if (shape.dim != null) {\n    return shape.dim.map(\n        dim =>\n            (typeof dim.size === 'number') ? dim.size : parseInt(dim.size, 10));\n  }\n  return [];\n}\n\nexport function getTensorShapeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def?: number[]): number[]|undefined {\n  const param = attrs[name];\n  if (param && param.shape) {\n    return parseTensorShapeParam(param.shape);\n  }\n  return def;\n}\n\nexport function getNumericArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[]): number[] {\n  const param = attrs[name];\n  if (param) {\n    return ((param.list.f && param.list.f.length ? param.list.f :\n                                                   param.list.i) ||\n            [])\n        .map(v => (typeof v === 'number') ? v : parseInt(v, 10));\n  }\n  return def;\n}\n\nexport function getStringArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string[],\n    keepCase = false): string[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.s) {\n    return param.list.s.map((v) => {\n      return parseStringParam(v, keepCase);\n    });\n  }\n  return def;\n}\n\nexport function getTensorShapeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[][]): number[][] {\n  const param = attrs[name];\n  if (param && param.list && param.list.shape) {\n    return param.list.shape.map((v) => {\n      return parseTensorShapeParam(v);\n    });\n  }\n  return def;\n}\n\nexport function getBoolArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean[]): boolean[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.b) {\n    return param.list.b;\n  }\n  return def;\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {getTensor} from '../executors/utils';\nimport {getBoolArrayParam, getBoolParam, getDtypeArrayParam, getDtypeParam, getNumberParam, getNumericArrayParam, getStringArrayParam, getStringParam, getTensorShapeArrayParam, getTensorShapeParam} from '../operation_mapper';\nimport {GraphNode, Node, ValueType} from '../types';\n\n/**\n * Helper class for lookup inputs and params for nodes in the model graph.\n */\nexport class NodeValueImpl implements GraphNode {\n  public readonly inputs: Tensor[] = [];\n  public readonly attrs: {[key: string]: ValueType} = {};\n  constructor(\n      private node: Node, private tensorMap: NamedTensorsMap,\n      private context: ExecutionContext) {\n    this.inputs = node.inputNames.map(name => this.getInput(name));\n    if (node.rawAttrs != null) {\n      this.attrs = Object.keys(node.rawAttrs)\n                       .reduce((attrs: {[key: string]: ValueType}, key) => {\n                         attrs[key] = this.getAttr(key);\n                         return attrs;\n                       }, {});\n    }\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getInput(name: string): Tensor {\n    return getTensor(name, this.tensorMap, this.context);\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getAttr(name: string, defaultValue?: ValueType): ValueType {\n    const value = this.node.rawAttrs[name];\n    if (value.tensor != null) {\n      return getTensor(name, this.tensorMap, this.context);\n    }\n    if (value.i != null || value.f != null) {\n      return getNumberParam(this.node.rawAttrs, name, defaultValue as number);\n    }\n    if (value.s != null) {\n      return getStringParam(this.node.rawAttrs, name, defaultValue as string);\n    }\n    if (value.b != null) {\n      return getBoolParam(this.node.rawAttrs, name, defaultValue as boolean);\n    }\n    if (value.shape != null) {\n      return getTensorShapeParam(\n          this.node.rawAttrs, name, defaultValue as number[]);\n    }\n    if (value.type != null) {\n      return getDtypeParam(this.node.rawAttrs, name, defaultValue as DataType);\n    }\n    if (value.list != null) {\n      if (value.list.i != null || value.list.f != null) {\n        return getNumericArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[]);\n      }\n      if (value.list.s != null) {\n        return getStringArrayParam(\n            this.node.rawAttrs, name, defaultValue as string[]);\n      }\n      if (value.list.shape != null) {\n        return getTensorShapeArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[][]);\n      }\n      if (value.list.b != null) {\n        return getBoolArrayParam(\n            this.node.rawAttrs, name, defaultValue as boolean[]);\n      }\n      if (value.list.type != null) {\n        return getDtypeArrayParam(\n            this.node.rawAttrs, name, defaultValue as DataType[]);\n      }\n    }\n\n    return defaultValue;\n  }\n}\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * This file exports ops used by the converters executors. By default it\n * re-exports all ops. In a custom build this is aliased to a file that will\n * only exports ops for a given model.json.\n */\nexport * from './ops';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'BiasAdd':\n        case 'AddV2':\n        case 'Add': {\n          return [ops.add(\n              (getParamValue('a', node, tensorMap, context) as Tensor),\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'AddN': {\n          return [ops.addN((\n              getParamValue('tensors', node, tensorMap, context) as Tensor[]))];\n        }\n        case 'FloorMod':\n        case 'Mod':\n          return [ops.mod(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        case 'Mul':\n          return [ops.mul(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        case 'RealDiv':\n        case 'Div': {\n          return [ops.div(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'DivNoNan': {\n          return [ops.divNoNan(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'FloorDiv': {\n          return [ops.floorDiv(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Sub': {\n          return [ops.sub(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Minimum': {\n          return [ops.minimum(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Maximum': {\n          return [ops.maximum(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Pow': {\n          return [ops.pow(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'SquaredDifference': {\n          return [ops.squaredDifference(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'arithmetic';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Abs':\n        case 'ComplexAbs':\n          return [ops.abs(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Acos':\n          return [ops.acos(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Acosh':\n          return [ops.acosh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Asin':\n          return [ops.asin(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Asinh':\n          return [ops.asinh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Atan':\n          return [ops.atan(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Atan2':\n          return [ops.atan2(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('y', node, tensorMap, context) as Tensor)];\n        case 'Atanh':\n          return [ops.atanh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Ceil':\n          return [ops.ceil(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Complex':\n          return [ops.complex(\n              getParamValue('real', node, tensorMap, context) as Tensor,\n              getParamValue('imag', node, tensorMap, context) as Tensor)];\n        case 'Cos':\n          return [ops.cos(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Cosh':\n          return [ops.cosh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Elu':\n          return [ops.elu(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Erf':\n          return [ops.erf(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Exp':\n          return [ops.exp(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Expm1': {\n          return [ops.expm1(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Floor':\n          return [ops.floor(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Log':\n          return [ops.log(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Log1p': {\n          return [ops.log1p(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Imag':\n          return [ops.imag(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n\n        case 'Neg':\n          return [ops.neg(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Reciprocal': {\n          return [ops.reciprocal(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Real':\n          return [ops.real(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Relu':\n          return [ops.relu(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Round': {\n          return [ops.round(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Selu':\n          return [ops.selu(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Sigmoid':\n          return [ops.sigmoid(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Sin':\n          return [ops.sin(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Sign': {\n          return [ops.sign(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Sinh': {\n          return [ops.sinh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Softplus': {\n          return [ops.softplus(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Sqrt': {\n          return [ops.sqrt(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Square': {\n          return [ops.square(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Tanh': {\n          return [ops.tanh(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'Tan':\n          return [ops.tan(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'ClipByValue':\n          return [ops.clipByValue(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('clipValueMin', node, tensorMap, context) as number,\n              getParamValue('clipValueMax', node, tensorMap, context) as\n                  number)];\n        case 'Relu6':\n          return [ops.relu6(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        case 'Rsqrt':\n          return [ops.rsqrt(getTensor(node.inputNames[0], tensorMap, context))];\n        case 'LeakyRelu':\n          return [ops.leakyRelu(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('alpha', node, tensorMap, context) as number)];\n        case 'Prelu':\n          return [ops.prelu(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('alpha', node, tensorMap, context) as Tensor)];\n        case 'IsNan':\n          return [ops.isNaN(getTensor(node.inputNames[0], tensorMap, context))];\n        case 'IsInf':\n          return [ops.isInf(getTensor(node.inputNames[0], tensorMap, context))];\n        case 'IsFinite':\n          return [ops.isFinite(\n              getTensor(node.inputNames[0], tensorMap, context))];\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'basic_math';\n", "\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * This differs from util.assertShapesMatch in that it allows values of\n * negative one, an undefined size of a dimensinon, in a shape to match\n * anything.\n */\n\nimport {Tensor, util} from '@tensorflow/tfjs-core';\n\n/**\n * Used by TensorList and TensorArray to verify if elementShape matches, support\n * negative value as the dim shape.\n * @param shapeA\n * @param shapeB\n * @param errorMessagePrefix\n */\nexport function assertShapesMatchAllowUndefinedSize(\n    shapeA: number|number[], shapeB: number|number[],\n    errorMessagePrefix = ''): void {\n  // constant shape means unknown rank\n  if (typeof shapeA === 'number' || typeof shapeB === 'number') {\n    return;\n  }\n  util.assert(\n      shapeA.length === shapeB.length,\n      () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n  for (let i = 0; i < shapeA.length; i++) {\n    const dim0 = shapeA[i];\n    const dim1 = shapeB[i];\n    util.assert(\n        dim0 < 0 || dim1 < 0 || dim0 === dim1,\n        () =>\n            errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n  }\n}\n\nexport function fullDefinedShape(elementShape: number|number[]): boolean {\n  if (typeof elementShape === 'number' || elementShape.some(dim => dim < 0)) {\n    return false;\n  }\n  return true;\n}\n/**\n * Generate the output element shape from the list elementShape, list tensors\n * and input param.\n * @param listElementShape\n * @param tensors\n * @param elementShape\n */\nexport function inferElementShape(\n    listElementShape: number|number[], tensors: Tensor[],\n    elementShape: number|number[]): number[] {\n  let partialShape = mergeElementShape(listElementShape, elementShape);\n  const notfullDefinedShape = !fullDefinedShape(partialShape);\n  if (notfullDefinedShape && tensors.length === 0) {\n    throw new Error(\n        `Tried to calculate elements of an empty list` +\n        ` with non-fully-defined elementShape: ${partialShape}`);\n  }\n  if (notfullDefinedShape) {\n    tensors.forEach(tensor => {\n      partialShape = mergeElementShape(tensor.shape, partialShape);\n    });\n  }\n  if (!fullDefinedShape(partialShape)) {\n    throw new Error(`Non-fully-defined elementShape: ${partialShape}`);\n  }\n  return partialShape as number[];\n}\n\nexport function mergeElementShape(\n    elementShapeA: number|number[], elementShapeB: number|number[]): number|\n    number[] {\n  if (typeof elementShapeA === 'number') {\n    return elementShapeB;\n  }\n  if (typeof elementShapeB === 'number') {\n    return elementShapeA;\n  }\n\n  if (elementShapeA.length !== elementShapeB.length) {\n    throw new Error(`Incompatible ranks during merge: ${elementShapeA} vs. ${\n        elementShapeB}`);\n  }\n\n  const result: number[] = [];\n  for (let i = 0; i < elementShapeA.length; ++i) {\n    const dim0 = elementShapeA[i];\n    const dim1 = elementShapeB[i];\n    if (dim0 >= 0 && dim1 >= 0 && dim0 !== dim1) {\n      throw new Error(`Incompatible shape during merge: ${elementShapeA} vs. ${\n          elementShapeB}`);\n    }\n    result[i] = dim0 >= 0 ? dim0 : dim1;\n  }\n  return result;\n}\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {concat, DataType, keep, reshape, scalar, slice, stack, Tensor, tensor, tidy, unstack} from '@tensorflow/tfjs-core';\n\nimport {assertShapesMatchAllowUndefinedSize} from './tensor_utils';\n\nexport interface TensorWithState {\n  tensor?: Tensor;\n  written?: boolean;\n  read?: boolean;\n  cleared?: boolean;\n}\n/**\n * The TensorArray object keeps an array of Tensors.  It\n * allows reading from the array and writing to the array.\n */\nexport class TensorArray {\n  private tensors: TensorWithState[] = [];\n  private closed_ = false;\n  readonly idTensor: Tensor;\n  constructor(\n      readonly name: string, readonly dtype: DataType, private maxSize: number,\n      private elementShape: number[], readonly identicalElementShapes: boolean,\n      readonly dynamicSize: boolean, readonly clearAfterRead: boolean) {\n    this.idTensor = scalar(0);\n    keep(this.idTensor);\n  }\n\n  get id() {\n    return this.idTensor.id;\n  }\n\n  get closed() {\n    return this.closed_;\n  }\n\n  /**\n   * Dispose the tensors and idTensor and mark the TensoryArray as closed.\n   */\n  clearAndClose(keepIds?: Set<number>) {\n    this.tensors.forEach(tensor => {\n      if (keepIds == null || !keepIds.has(tensor.tensor.id)) {\n        tensor.tensor.dispose();\n      }\n    });\n    this.tensors = [];\n    this.closed_ = true;\n    this.idTensor.dispose();\n  }\n\n  size(): number {\n    return this.tensors.length;\n  }\n\n  /**\n   * Read the value at location index in the TensorArray.\n   * @param index Number the index to read from.\n   */\n  read(index: number): Tensor {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || index >= this.size()) {\n      throw new Error(`Tried to read from index ${index}, but array size is: ${\n          this.size()}`);\n    }\n\n    const tensorWithState = this.tensors[index];\n    if (tensorWithState.cleared) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not read index ${\n              index} twice because it was cleared after a previous read ` +\n          `(perhaps try setting clear_after_read = false?).`);\n    }\n\n    if (this.clearAfterRead) {\n      tensorWithState.cleared = true;\n    }\n\n    tensorWithState.read = true;\n    return tensorWithState.tensor;\n  }\n\n  /**\n   * Helper method to read multiple tensors from the specified indices.\n   */\n  readMany(indices: number[]): Tensor[] {\n    return indices.map(index => this.read(index));\n  }\n\n  /**\n   * Write value into the index of the TensorArray.\n   * @param index number the index to write to.\n   * @param tensor\n   */\n  write(index: number, tensor: Tensor) {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || !this.dynamicSize && index >= this.maxSize) {\n      throw new Error(`Tried to write to index ${\n          index}, but array is not resizeable and size is: ${this.maxSize}`);\n    }\n\n    const t = this.tensors[index] || {};\n\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray ${\n          this.name}: Could not write to TensorArray index ${index},\n          because the value dtype is ${\n          tensor.dtype}, but TensorArray dtype is ${this.dtype}.`);\n    }\n\n    // Set the shape for the first time write to unknow shape tensor array\n    if (this.size() === 0 &&\n        (this.elementShape == null || this.elementShape.length === 0)) {\n      this.elementShape = tensor.shape;\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape,\n        `TensorArray ${this.name}: Could not write to TensorArray index ${\n            index}.`);\n\n    if (t.read) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been read.`);\n    }\n\n    if (t.written) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been written.`);\n    }\n\n    t.tensor = tensor;\n    keep(tensor);\n    t.written = true;\n\n    this.tensors[index] = t;\n  }\n\n  /**\n   * Helper method to write multiple tensors to the specified indices.\n   */\n  writeMany(indices: number[], tensors: Tensor[]) {\n    if (indices.length !== tensors.length) {\n      throw new Error(\n          `TensorArray ${this.name}: could not write multiple tensors,` +\n          `because the index size: ${\n              indices.length} is not the same as tensors size: ${\n              tensors.length}.`);\n    }\n\n    indices.forEach((i, index) => this.write(i, tensors[index]));\n  }\n\n  /**\n   * Return selected values in the TensorArray as a packed Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param [indices] number[] Optional. Taking values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size(). If not specified returns\n   *    all tensors in the original order.\n   * @param [dtype]\n   */\n  gather(indices?: number[], dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but gather requested dtype ${dtype}`);\n    }\n\n    if (!indices) {\n      indices = [];\n      for (let i = 0; i < this.size(); i++) {\n        indices.push(i);\n      }\n    } else {\n      indices = indices.slice(0, this.size());\n    }\n\n    if (indices.length === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    // Read all the PersistentTensors into a vector to keep track of\n    // their memory.\n    const tensors = this.readMany(indices);\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape, 'TensorArray shape mismatch: ');\n\n    return stack(tensors, 0);\n  }\n\n  /**\n   * Return the values in the TensorArray as a concatenated Tensor.\n   */\n  concat(dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but concat requested dtype ${dtype}`);\n    }\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    const indices = [];\n    for (let i = 0; i < this.size(); i++) {\n      indices.push(i);\n    }\n    // Collect all the tensors from the tensors array.\n    const tensors = this.readMany(indices);\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape,\n        `TensorArray shape mismatch: tensor array shape (${\n            this.elementShape}) vs first tensor shape (${tensors[0].shape})`);\n\n    return concat(tensors, 0);\n  }\n\n  /**\n   * Scatter the values of a Tensor in specific indices of a TensorArray.\n   * @param indices number[] values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size().\n   * @param tensor Tensor input tensor.\n   */\n  scatter(indices: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n\n    if (indices.length !== tensor.shape[0]) {\n      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n          indices.length} vs. ${tensor.shape[0]}`);\n    }\n\n    const maxIndex = Math.max(...indices);\n\n    if (!this.dynamicSize && maxIndex >= this.maxSize) {\n      throw new Error(\n          `Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`);\n    }\n\n    this.writeMany(indices, unstack(tensor, 0));\n  }\n\n  /**\n   * Split the values of a Tensor into the TensorArray.\n   * @param length number[] with the lengths to use when splitting value along\n   *    its first dimension.\n   * @param tensor Tensor, the tensor to split.\n   */\n  split(length: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n    let totalLength = 0;\n    const cumulativeLengths = length.map(len => {\n      totalLength += len;\n      return totalLength;\n    });\n\n    if (totalLength !== tensor.shape[0]) {\n      throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n    }\n\n    if (!this.dynamicSize && length.length !== this.maxSize) {\n      throw new Error(\n          `TensorArray's size is not equal to the size of lengths (${\n              this.maxSize} vs. ${length.length}), ` +\n          'and the TensorArray is not marked as dynamically resizeable');\n    }\n\n    const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n    const tensors: Tensor[] = [];\n    tidy(() => {\n      tensor = reshape(tensor, [1, totalLength, elementPerRow]);\n      for (let i = 0; i < length.length; ++i) {\n        const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n        const indices = [0, previousLength, 0];\n        const sizes = [1, length[i], elementPerRow];\n        tensors[i] = reshape(slice(tensor, indices, sizes), this.elementShape);\n      }\n      return tensors;\n    });\n    const indices = [];\n    for (let i = 0; i < length.length; i++) {\n      indices[i] = i;\n    }\n    this.writeMany(indices, tensors);\n  }\n}\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {concat, DataType, keep, reshape, scalar, slice, stack, Tensor, tensor, tidy, unstack} from '@tensorflow/tfjs-core';\n\nimport {assertShapesMatchAllowUndefinedSize, inferElementShape, mergeElementShape} from './tensor_utils';\n\n/**\n * TensorList stores a container of `tf.Tensor` objects, which are accessible\n * via tensors field.\n *\n * In order to get a copy of the underlying list, use the copy method:\n * ```\n *    TensorList b = a.copy();\n *    b.tensors().pushBack(t);  // This does not modify a.tensors().\n * ```\n *\n * Note that this is not a deep copy: the memory locations of the underlying\n * tensors will still point to the same locations of the corresponding tensors\n * in the original.\n */\n\nexport class TensorList {\n  readonly idTensor: Tensor;\n  maxNumElements: number;\n\n  get id() {\n    return this.idTensor.id;\n  }\n  /**\n   *\n   * @param tensors list of tensors\n   * @param elementShape shape of each tensor, this can be a single number (any\n   * shape is allowed) or partial shape (dim = -1).\n   * @param elementDtype data type of each tensor\n   * @param maxNumElements The maximum allowed size of `tensors`. Defaults to -1\n   *   meaning that the size of `tensors` is unbounded.\n   */\n  constructor(\n      readonly tensors: Tensor[], readonly elementShape: number|number[],\n      readonly elementDtype: DataType, maxNumElements = -1) {\n    if (tensors != null) {\n      tensors.forEach(tensor => {\n        if (elementDtype !== tensor.dtype) {\n          throw new Error(`Invalid data types; op elements ${\n              elementDtype}, but list elements ${tensor.dtype}`);\n        }\n        assertShapesMatchAllowUndefinedSize(\n            elementShape, tensor.shape, 'TensorList shape mismatch: ');\n\n        keep(tensor);\n      });\n    }\n    this.idTensor = scalar(0);\n    this.maxNumElements = maxNumElements;\n    keep(this.idTensor);\n  }\n\n  /**\n   * Get a new TensorList containing a copy of the underlying tensor container.\n   */\n  copy(): TensorList {\n    return new TensorList(\n        [...this.tensors], this.elementShape, this.elementDtype);\n  }\n\n  /**\n   * Dispose the tensors and idTensor and clear the tensor list.\n   */\n  clearAndClose(keepIds?: Set<number>) {\n    this.tensors.forEach(tensor => {\n      if (keepIds == null || !keepIds.has(tensor.id)) {\n        tensor.dispose();\n      }\n    });\n    this.tensors.length = 0;\n    this.idTensor.dispose();\n  }\n  /**\n   * The size of the tensors in the tensor list.\n   */\n  size() {\n    return this.tensors.length;\n  }\n\n  /**\n   * Return a tensor that stacks a list of rank-R tf.Tensors into one rank-(R+1)\n   * tf.Tensor.\n   * @param elementShape shape of each tensor\n   * @param elementDtype data type of each tensor\n   * @param numElements the number of elements to stack\n   */\n  stack(elementShape: number[], elementDtype: DataType, numElements = -1):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n    if (numElements !== -1 && this.tensors.length !== numElements) {\n      throw new Error(`Operation expected a list with ${\n          numElements} elements but got a list with ${\n          this.tensors.length} elements.`);\n    }\n    assertShapesMatchAllowUndefinedSize(\n        elementShape, this.elementShape, 'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    return tidy(() => {\n      const reshapedTensors =\n          this.tensors.map(tensor => reshape(tensor, outputElementShape));\n      return stack(reshapedTensors, 0);\n    });\n  }\n\n  /**\n   * Pop a tensor from the end of the list.\n   * @param elementShape shape of the tensor\n   * @param elementDtype data type of the tensor\n   */\n  popBack(elementShape: number[], elementDtype: DataType): Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n\n    if (this.size() === 0) {\n      throw new Error('Trying to pop from an empty list.');\n    }\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    const tensor = this.tensors.pop();\n    tensor.kept = false;\n\n    assertShapesMatchAllowUndefinedSize(\n        tensor.shape, elementShape, 'TensorList shape mismatch: ');\n\n    return reshape(tensor, outputElementShape);\n  }\n\n  /**\n   * Push a tensor to the end of the list.\n   * @param tensor Tensor to be pushed.\n   */\n  pushBack(tensor: Tensor) {\n    if (tensor.dtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          tensor.dtype}, but list elements ${this.elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        tensor.shape, this.elementShape, 'TensorList shape mismatch: ');\n\n    if (this.maxNumElements === this.size()) {\n      throw new Error(`Trying to push element into a full list.`);\n    }\n    keep(tensor);\n    this.tensors.push(tensor);\n  }\n\n  /**\n   * Update the size of the list.\n   * @param size the new size of the list.\n   */\n  resize(size: number) {\n    if (size < 0) {\n      throw new Error(\n          `TensorListResize expects size to be non-negative. Got: ${size}`);\n    }\n\n    if (this.maxNumElements !== -1 && size > this.maxNumElements) {\n      throw new Error(`TensorListResize input size ${\n          size} is greater maxNumElement ${this.maxNumElements}.`);\n    }\n\n    const destTensorList: TensorList = new TensorList(\n        [], this.elementShape, this.elementDtype, this.maxNumElements);\n    destTensorList.tensors.length = size;\n    for (let i = 0; i < Math.min(this.tensors.length, size); ++i) {\n      destTensorList.tensors[i] = this.tensors[i];\n    }\n    return destTensorList;\n  }\n\n  /**\n   * Retrieve the element at the provided index\n   * @param elementShape shape of the tensor\n   * @param elementDtype dtype of the tensor\n   * @param elementIndex index of the tensor\n   */\n  getItem(elementIndex: number, elementShape: number[], elementDtype: DataType):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n    if (elementIndex < 0 || elementIndex > this.tensors.length) {\n      throw new Error(`Trying to access element ${\n          elementIndex} in a list with ${this.tensors.length} elements.`);\n    }\n\n    if (this.tensors[elementIndex] == null) {\n      throw new Error(`element at index ${elementIndex} is null.`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.tensors[elementIndex].shape, elementShape,\n        'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    return reshape(this.tensors[elementIndex], outputElementShape);\n  }\n\n  /**\n   * Set the tensor at the index\n   * @param elementIndex index of the tensor\n   * @param tensor the tensor to be inserted into the list\n   */\n  setItem(elementIndex: number, tensor: Tensor) {\n    if (tensor.dtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          tensor.dtype}, but list elements ${this.elementDtype}`);\n    }\n\n    if (elementIndex < 0 ||\n        this.maxNumElements !== -1 && elementIndex >= this.maxNumElements) {\n      throw new Error(`Trying to set element ${\n          elementIndex} in a list with max ${this.maxNumElements} elements.`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape, 'TensorList shape mismatch: ');\n    keep(tensor);\n\n    // dispose the previous value if it is replacing.\n    if (this.tensors[elementIndex] != null) {\n      this.tensors[elementIndex].kept = false;\n    }\n\n    this.tensors[elementIndex] = tensor;\n  }\n\n  /**\n   * Return selected values in the TensorList as a stacked Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param indices indices of tensors to gather\n   * @param elementDtype output tensor dtype\n   * @param elementShape output tensor element shape\n   */\n  gather(indices: number[], elementDtype: DataType, elementShape: number[]):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, elementShape, 'TensorList shape mismatch: ');\n\n    // When indices is greater than the size of the list, indices beyond the\n    // size of the list are ignored.\n    indices = indices.slice(0, this.size());\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    if (indices.length === 0) {\n      return tensor([], [0].concat(outputElementShape));\n    }\n\n    return tidy(() => {\n      const tensors =\n          indices.map(i => reshape(this.tensors[i], outputElementShape));\n      return stack(tensors, 0);\n    });\n  }\n\n  /**\n   * Return the values in the TensorList as a concatenated Tensor.\n   * @param elementDtype output tensor dtype\n   * @param elementShape output tensor element shape\n   */\n  concat(elementDtype: DataType, elementShape: number[]): Tensor {\n    if (!!elementDtype && elementDtype !== this.elementDtype) {\n      throw new Error(`TensorList dtype is ${\n          this.elementDtype} but concat requested dtype ${elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, elementShape, 'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(outputElementShape));\n    }\n    return tidy(() => {\n      const tensors = this.tensors.map(t => reshape(t, outputElementShape));\n      return concat(tensors, 0);\n    });\n  }\n}\n\n/**\n * Creates a TensorList which, when stacked, has the value of tensor.\n * @param tensor from tensor\n * @param elementShape output tensor element shape\n */\nexport function fromTensor(\n    tensor: Tensor, elementShape: number[], elementDtype: DataType) {\n  const dtype = tensor.dtype;\n  if (tensor.shape.length < 1) {\n    throw new Error(\n        `Tensor must be at least a vector, but saw shape: ${tensor.shape}`);\n  }\n  if (tensor.dtype !== elementDtype) {\n    throw new Error(`Invalid data types; op elements ${\n        tensor.dtype}, but list elements ${elementDtype}`);\n  }\n  const tensorElementShape = tensor.shape.slice(1);\n  assertShapesMatchAllowUndefinedSize(\n      tensorElementShape, elementShape, 'TensorList shape mismatch: ');\n  const tensorList: Tensor[] = unstack(tensor);\n  return new TensorList(tensorList, elementShape, dtype);\n}\n\n/**\n * Return a TensorList of the given size with empty elements.\n * @param elementShape the shape of the future elements of the list\n * @param elementDtype the desired type of elements in the list\n * @param numElements the number of elements to reserve\n * @param maxNumElements the maximum number of elements in th list\n */\nexport function reserve(\n    elementShape: number[], elementDtype: DataType, numElements: number,\n    maxNumElements: number) {\n  return new TensorList([], elementShape, elementDtype, maxNumElements);\n}\n\n/**\n * Put tensors at specific indices of a stacked tensor into a TensorList.\n * @param indices list of indices on how to scatter the tensor.\n * @param tensor input tensor.\n * @param elementShape the shape of the future elements of the list\n * @param numElements the number of elements to scatter\n */\nexport function scatter(\n    tensor: Tensor, indices: number[], elementShape: number[],\n    numElements?: number): TensorList {\n  if (indices.length !== tensor.shape[0]) {\n    throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n        indices.length} vs. ${tensor.shape[0]}`);\n  }\n\n  const maxIndex = Math.max(...indices);\n\n  if (numElements != null && numElements !== -1 && maxIndex >= numElements) {\n    throw new Error(\n        `Max index must be < array size (${maxIndex}  vs. ${numElements})`);\n  }\n\n  const list = new TensorList([], elementShape, tensor.dtype, numElements);\n  const tensors = unstack(tensor, 0);\n  indices.forEach((value, index) => {\n    list.setItem(value, tensors[index]);\n  });\n  return list;\n}\n\n/**\n * Split the values of a Tensor into a TensorList.\n * @param length the lengths to use when splitting value along\n *    its first dimension.\n * @param tensor the tensor to split.\n * @param elementShape the shape of the future elements of the list\n */\nexport function split(\n    tensor: Tensor, length: number[], elementShape: number[]) {\n  let totalLength = 0;\n  const cumulativeLengths = length.map(len => {\n    totalLength += len;\n    return totalLength;\n  });\n\n  if (totalLength !== tensor.shape[0]) {\n    throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n  }\n\n  const shapeWithoutFirstDim = tensor.shape.slice(1);\n  const outputElementShape =\n      mergeElementShape(shapeWithoutFirstDim, elementShape);\n  const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n  const tensors: Tensor[] = tidy(() => {\n    const tensors = [];\n    tensor = reshape(tensor, [1, totalLength, elementPerRow]);\n    for (let i = 0; i < length.length; ++i) {\n      const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n      const indices = [0, previousLength, 0];\n      const sizes = [1, length[i], elementPerRow];\n      tensors[i] = reshape(\n          slice(tensor, indices, sizes), outputElementShape as number[]);\n    }\n    tensor.dispose();\n    return tensors;\n  });\n\n  const list = new TensorList([], elementShape, tensor.dtype, length.length);\n\n  for (let i = 0; i < tensors.length; i++) {\n    list.setItem(i, tensors[i]);\n  }\n  return list;\n}\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, scalar, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {TensorArray} from '../../executor/tensor_array';\nimport {fromTensor, reserve, scatter, split} from '../../executor/tensor_list';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {cloneTensor, getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): Promise<Tensor[]> => {\n  switch (node.op) {\n    case 'If':\n    case 'StatelessIf': {\n      const thenFunc =\n          getParamValue('thenBranch', node, tensorMap, context) as string;\n      const elseFunc =\n          getParamValue('elseBranch', node, tensorMap, context) as string;\n      const cond = getParamValue('cond', node, tensorMap, context) as Tensor;\n      const args = getParamValue('args', node, tensorMap, context) as Tensor[];\n      const condValue = await cond.data();\n      if (condValue[0]) {\n        return context.functionMap[thenFunc].executeFunctionAsync(\n            args, context.tensorArrayMap, context.tensorListMap);\n      } else {\n        return context.functionMap[elseFunc].executeFunctionAsync(\n            args, context.tensorArrayMap, context.tensorListMap);\n      }\n    }\n    case 'While':\n    case 'StatelessWhile': {\n      const bodyFunc =\n          getParamValue('body', node, tensorMap, context) as string;\n      const condFunc =\n          getParamValue('cond', node, tensorMap, context) as string;\n      const args = getParamValue('args', node, tensorMap, context) as Tensor[];\n\n      // Calculate the condition of the loop\n      const condResult =\n          (await context.functionMap[condFunc].executeFunctionAsync(\n              args, context.tensorArrayMap, context.tensorListMap));\n      const argIds = args.map(tensor => tensor.id);\n      let condValue = await condResult[0].data();\n      // Dispose the intermediate tensors for condition function\n      condResult.forEach(tensor => {\n        if (!tensor.kept && argIds.indexOf(tensor.id) === -1) {\n          tensor.dispose();\n        }\n      });\n\n      let result: Tensor[] = args;\n\n      while (condValue[0]) {\n        // Record the previous result for intermediate tensor tracking\n        const origResult = result;\n        // Execution the body of the loop\n        result = await context.functionMap[bodyFunc].executeFunctionAsync(\n            result, context.tensorArrayMap, context.tensorListMap);\n        const resultIds = result.map(tensor => tensor.id);\n\n        // Dispose the intermediate tensor for body function that is not global\n        // kept, not input/output of the body function\n        origResult.forEach(tensor => {\n          if (!tensor.kept && argIds.indexOf(tensor.id) === -1 &&\n              resultIds.indexOf(tensor.id) === -1) {\n            tensor.dispose();\n          }\n        });\n\n        // Recalcuate the condition of the loop using the latest results.\n        const condResult =\n            (await context.functionMap[condFunc].executeFunctionAsync(\n                result, context.tensorArrayMap, context.tensorListMap));\n        condValue = await condResult[0].data();\n        // Dispose the intermediate tensors for condition function\n        condResult.forEach(tensor => {\n          if (!tensor.kept && argIds.indexOf(tensor.id) === -1 &&\n              resultIds.indexOf(tensor.id) === -1) {\n            tensor.dispose();\n          }\n        });\n      }\n      return result;\n    }\n    case 'LoopCond': {\n      const pred = getParamValue('pred', node, tensorMap, context) as Tensor;\n      return [cloneTensor(pred)];\n    }\n    case 'Switch': {\n      const pred = getParamValue('pred', node, tensorMap, context) as Tensor;\n      let data = getParamValue('data', node, tensorMap, context) as Tensor;\n      if (!data.kept) {\n        data = cloneTensor(data);\n      }\n      // Outputs nodes :0 => false, :1 => true\n      return (await pred.data())[0] ? [undefined, data] : [data, undefined];\n    }\n    case 'Merge': {\n      const inputName = node.inputNames.find(\n          name => getTensor(name, tensorMap, context) !== undefined);\n      if (inputName) {\n        const data = getTensor(inputName, tensorMap, context);\n        return [cloneTensor(data)];\n      }\n      return undefined;\n    }\n    case 'Enter': {\n      const frameId =\n          getParamValue('frameName', node, tensorMap, context) as string;\n      const data = getParamValue('tensor', node, tensorMap, context) as Tensor;\n      context.enterFrame(frameId);\n      return [cloneTensor(data)];\n    }\n    case 'Exit': {\n      const data = getParamValue('tensor', node, tensorMap, context) as Tensor;\n      context.exitFrame();\n      return [cloneTensor(data)];\n    }\n    case 'NextIteration': {\n      const data = getParamValue('tensor', node, tensorMap, context) as Tensor;\n      context.nextIteration();\n      return [cloneTensor(data)];\n    }\n    case 'TensorArrayV3': {\n      const size = getParamValue('size', node, tensorMap, context) as number;\n      const dtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const dynamicSize =\n          getParamValue('dynamicSize', node, tensorMap, context) as boolean;\n      const clearAfterRead =\n          getParamValue('clearAfterRead', node, tensorMap, context) as boolean;\n      const identicalElementShapes =\n          getParamValue('identicalElementShapes', node, tensorMap, context) as\n          boolean;\n      const name = getParamValue('name', node, tensorMap, context) as string;\n      const tensorArray = new TensorArray(\n          name, dtype, size, elementShape, identicalElementShapes, dynamicSize,\n          clearAfterRead);\n      context.addTensorArray(tensorArray);\n      return [tensorArray.idTensor, scalar(1.0)];\n    }\n    case 'TensorArrayWriteV3': {\n      const id =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const index = getParamValue('index', node, tensorMap, context) as number;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const writeTensorArray = context.getTensorArray(id.id);\n      writeTensorArray.write(index, writeTensor);\n      return [writeTensorArray.idTensor];\n    }\n    case 'TensorArrayReadV3': {\n      const readId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const readIndex =\n          getParamValue('index', node, tensorMap, context) as number;\n      const readTensorArray = context.getTensorArray(readId.id);\n      return [readTensorArray.read(readIndex)];\n    }\n    case 'TensorArrayGatherV3': {\n      const gatherId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const gatherIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const gatherDtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      const gatherTensorArray = context.getTensorArray(gatherId.id);\n      return [gatherTensorArray.gather(gatherIndices, gatherDtype)];\n    }\n    case 'TensorArrayScatterV3': {\n      const scatterId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const scatterIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const scatterTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const scatterTensorArray = context.getTensorArray(scatterId.id);\n      scatterTensorArray.scatter(scatterIndices, scatterTensor);\n      return [scatterTensorArray.idTensor];\n    }\n    case 'TensorArrayConcatV3': {\n      const concatId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const concatTensorArray = context.getTensorArray(concatId.id);\n      const concatDtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      return [concatTensorArray.concat(concatDtype)];\n    }\n    case 'TensorArraySplitV3': {\n      const splitId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const splitTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const lengths =\n          getParamValue('lengths', node, tensorMap, context) as number[];\n      const splitTensorArray = context.getTensorArray(splitId.id);\n      splitTensorArray.split(lengths, splitTensor);\n      return [splitTensorArray.idTensor];\n    }\n    case 'TensorArraySizeV3': {\n      const sizeId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const sizeTensorArray = context.getTensorArray(sizeId.id);\n      return [scalar(sizeTensorArray.size(), 'int32')];\n    }\n    case 'TensorArrayCloseV3': {\n      const closeId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as Tensor;\n      const closeTensorArray = context.getTensorArray(closeId.id);\n      closeTensorArray.clearAndClose();\n      return [closeTensorArray.idTensor];\n    }\n    case 'TensorListSetItem': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const index = getParamValue('index', node, tensorMap, context) as number;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const tensorList = context.getTensorList(idTensor.id);\n      tensorList.setItem(index, writeTensor);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListGetItem': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const readIndex =\n          getParamValue('index', node, tensorMap, context) as number;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n\n      const elementDType =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.getItem(readIndex, elementShape, elementDType)];\n    }\n    case 'TensorListScatterV2':\n    case 'TensorListScatter': {\n      const scatterIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const scatterTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const numElements =\n          getParamValue('numElements', node, tensorMap, context) as number;\n      const tensorList =\n          scatter(scatterTensor, scatterIndices, elementShape, numElements);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListReserve':\n    case 'EmptyTensorList': {\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      let numElementsParam;\n\n      if (node.op === 'TensorListReserve') {\n        numElementsParam = 'numElements';\n      } else {\n        numElementsParam = 'maxNumElements';\n      }\n\n      const numElements =\n          getParamValue(numElementsParam, node, tensorMap, context) as number;\n      const maxNumElements = node.op === 'TensorListReserve' ? -1 : numElements;\n      const tensorList =\n          reserve(elementShape, elementDtype, numElements, maxNumElements);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListGather': {\n      const gatherId =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const gatherIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = context.getTensorList(gatherId.id);\n      return [tensorList.gather(gatherIndices, elementDtype, elementShape)];\n    }\n    case 'TensorListStack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const numElements =\n          getParamValue('numElements', node, tensorMap, context) as number;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.stack(elementShape, elementDtype, numElements)];\n    }\n    case 'TensorListFromTensor': {\n      const tensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDtype =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = fromTensor(tensor, elementShape, elementDtype);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListConcat':\n    case 'TensorListConcatV2': {\n      const concatId =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const tensorList = context.getTensorList(concatId.id);\n      const concatDtype =\n          getParamValue('dtype', node, tensorMap, context) as DataType;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      return [tensorList.concat(concatDtype, elementShape)];\n    }\n    case 'TensorListPushBack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const tensorList = context.getTensorList(idTensor.id);\n      tensorList.pushBack(writeTensor);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListPopBack': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const elementDType =\n          getParamValue('elementDType', node, tensorMap, context) as DataType;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [tensorList.popBack(elementShape, elementDType)];\n    }\n    case 'TensorListSplit': {\n      const splitTensor =\n          getParamValue('tensor', node, tensorMap, context) as Tensor;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const lengths =\n          getParamValue('lengths', node, tensorMap, context) as number[];\n\n      const tensorList = split(splitTensor, lengths, elementShape);\n      context.addTensorList(tensorList);\n      return [tensorList.idTensor];\n    }\n    case 'TensorListLength': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const tensorList = context.getTensorList(idTensor.id);\n      return [scalar(tensorList.size(), 'int32')];\n    }\n    case 'TensorListResize': {\n      const idTensor =\n          getParamValue('tensorListId', node, tensorMap, context) as Tensor;\n      const size = getParamValue('size', node, tensorMap, context) as number;\n\n      const srcTensorList = context.getTensorList(idTensor.id);\n      const destTensorList = srcTensorList.resize(size);\n      context.addTensorList(destTensorList);\n      return [destTensorList.idTensor];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'control';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Rank, Tensor, Tensor3D, Tensor4D, Tensor5D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getPadding, getParamValue} from './utils';\n\nfunction fusedConvAndDepthWiseParams(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) {\n  const [extraOp, activationFunc] =\n      (getParamValue('fusedOps', node, tensorMap, context) as string[]);\n\n  const isBiasAdd = extraOp === 'biasadd';\n  const noBiasAdd = !isBiasAdd;\n  const isPrelu = activationFunc === 'prelu';\n  const isBatchNorm = extraOp === 'fusedbatchnorm';\n\n  const numArgs =\n      (getParamValue('numArgs', node, tensorMap, context) as number);\n  if (isBiasAdd) {\n    if (isPrelu && numArgs !== 2) {\n      throw new Error(\n          'FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu ' +\n          'must have two extra arguments: bias and alpha.');\n    }\n    if (!isPrelu && isBiasAdd && numArgs !== 1) {\n      throw new Error(\n          'FusedConv2d and DepthwiseConv2d with BiasAdd must have ' +\n          'one extra argument: bias.');\n    }\n  }\n  if (isBatchNorm) {\n    throw new Error(\n        'FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported');\n  }\n  const stride = getParamValue('strides', node, tensorMap, context) as number[];\n  const pad = getPadding(node, tensorMap, context);\n  const dataFormat =\n      (getParamValue('dataFormat', node, tensorMap, context) as string)\n          .toUpperCase();\n  const dilations =\n      getParamValue('dilations', node, tensorMap, context) as number[];\n  let [biasArg, preluArg] =\n      getParamValue('args', node, tensorMap, context) as Tensor[];\n  if (noBiasAdd) {\n    preluArg = biasArg;\n    biasArg = undefined;\n  }\n  const leakyreluAlpha =\n      getParamValue('leakyreluAlpha', node, tensorMap, context) as number;\n\n  return {\n    stride,\n    pad,\n    dataFormat,\n    dilations,\n    biasArg,\n    preluArg,\n    activationFunc,\n    leakyreluAlpha\n  };\n}\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Conv1D': {\n          const stride =\n              getParamValue('stride', node, tensorMap, context) as number;\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilation =\n              getParamValue('dilation', node, tensorMap, context) as number;\n          return [ops.conv1d(\n              getParamValue('x', node, tensorMap, context) as Tensor3D,\n              getParamValue('filter', node, tensorMap, context) as Tensor3D,\n              stride, pad as 'valid' | 'same', dataFormat as 'NWC' | 'NCW',\n              dilation)];\n        }\n        case 'Conv2D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getPadding(node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          return [ops.conv2d(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor4D,\n              [stride[1], stride[2]], pad as 'valid' | 'same',\n              dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n        }\n        case '_FusedConv2D': {\n          const {\n            stride,\n            pad,\n            dataFormat,\n            dilations,\n            biasArg,\n            preluArg,\n            activationFunc,\n            leakyreluAlpha\n          } = fusedConvAndDepthWiseParams(node, tensorMap, context);\n\n          return [ops.fused.conv2d({\n            x: getParamValue('x', node, tensorMap, context) as Tensor3D |\n                Tensor4D,\n            filter: getParamValue('filter', node, tensorMap, context) as\n                Tensor4D,\n            strides: [stride[1], stride[2]],\n            pad: pad as 'valid' | 'same',\n            dataFormat: dataFormat as 'NHWC' | 'NCHW',\n            dilations: [dilations[1], dilations[2]],\n            bias: biasArg,\n            activation: activationFunc as tfOps.fused.Activation,\n            preluActivationWeights: preluArg,\n            leakyreluAlpha\n          })];\n        }\n\n        case 'FusedDepthwiseConv2dNative': {\n          const {\n            stride,\n            pad,\n            dataFormat,\n            dilations,\n            biasArg,\n            preluArg,\n            activationFunc,\n            leakyreluAlpha,\n          } = fusedConvAndDepthWiseParams(node, tensorMap, context);\n\n          return [ops.fused.depthwiseConv2d({\n            x: getParamValue('x', node, tensorMap, context) as Tensor3D |\n                Tensor4D,\n            filter: getParamValue('filter', node, tensorMap, context) as\n                Tensor4D,\n            strides: [stride[1], stride[2]],\n            pad: pad as 'valid' | 'same',\n            dataFormat: dataFormat as 'NHWC' | 'NCHW',\n            dilations: [dilations[1], dilations[2]],\n            bias: biasArg,\n            activation: activationFunc as tfOps.fused.Activation,\n            preluActivationWeights: preluArg,\n            leakyreluAlpha\n          })];\n        }\n        case 'Conv2DBackpropInput':\n        case 'Conv2dTranspose': {\n          const shape = getParamValue(\n                            'outputShape', node, tensorMap,\n                            context) as [number, number, number] |\n              [number, number, number, number];\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getPadding(node, tensorMap, context);\n          return [ops.conv2dTranspose(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor4D,\n              shape, [stride[1], stride[2]], pad as 'valid' | 'same')];\n        }\n        case 'DepthwiseConv2dNative':\n        case 'DepthwiseConv2d': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getPadding(node, tensorMap, context);\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n\n          return [ops.depthwiseConv2d(\n              getParamValue('input', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor4D,\n              [stride[1], stride[2]], pad as 'valid' | 'same',\n              dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n        }\n        case 'Conv3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          return [ops.conv3d(\n              getParamValue('x', node, tensorMap, context) as Tensor4D |\n                  Tensor<Rank.R5>,\n              getParamValue('filter', node, tensorMap, context) as\n                  Tensor<Rank.R5>,\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same',\n              dataFormat as 'NDHWC' | 'NCDHW',\n              [dilations[1], dilations[2], dilations[3]])];\n        }\n        case 'AvgPool': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [ops.avgPool(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n              pad as 'valid' | 'same')];\n        }\n        case 'MaxPool': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [ops.maxPool(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n              pad as 'valid' | 'same')];\n        }\n        case 'MaxPoolWithArgmax': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n          const includeBatchInIndex =\n              getParamValue('includeBatchInIndex', node, tensorMap, context) as\n              boolean;\n          const {result, indexes} = ops.maxPoolWithArgmax(\n              getParamValue('x', node, tensorMap, context) as Tensor4D,\n              [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n              pad as 'valid' | 'same', includeBatchInIndex);\n          return [result, indexes];\n        }\n        case 'AvgPool3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [ops.avgPool3d(\n              getParamValue('x', node, tensorMap, context) as Tensor5D,\n              [kernelSize[1], kernelSize[2], kernelSize[3]],\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n        }\n\n        case 'MaxPool3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [ops.maxPool3d(\n              getParamValue('x', node, tensorMap, context) as Tensor5D,\n              [kernelSize[1], kernelSize[2], kernelSize[3]],\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n        }\n\n        case 'Dilation2D': {\n          const strides =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n\n          // strides: [1, stride_height, stride_width, 1].\n          const strideHeight = strides[1];\n          const strideWidth = strides[2];\n\n          // dilations: [1, dilation_height, dilation_width, 1].\n          const dilationHeight = dilations[1];\n          const dilationWidth = dilations[2];\n\n          return [ops.dilation2d(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as Tensor3D,\n              [strideHeight, strideWidth], pad as 'valid' | 'same',\n              [dilationHeight, dilationWidth], 'NHWC' /* dataFormat */)];\n        }\n\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'convolution';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor, Tensor1D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Fill': {\n          const shape =\n              getParamValue('shape', node, tensorMap, context) as number[];\n          const dtype =\n              getParamValue('dtype', node, tensorMap, context) as DataType;\n          const value =\n              getParamValue('value', node, tensorMap, context) as number;\n          return [ops.fill(shape, value, dtype)];\n        }\n        case 'LinSpace': {\n          const start =\n              getParamValue('start', node, tensorMap, context) as number;\n          const stop =\n              getParamValue('stop', node, tensorMap, context) as number;\n          const num = getParamValue('num', node, tensorMap, context) as number;\n          return [ops.linspace(start, stop, num)];\n        }\n        case 'Multinomial': {\n          const logits =\n              getParamValue('logits', node, tensorMap, context) as Tensor1D;\n          const numSamples =\n              getParamValue('numSamples', node, tensorMap, context) as number;\n          const seed =\n              getParamValue('seed', node, tensorMap, context) as number;\n          return [ops.multinomial(logits, numSamples, seed)];\n        }\n        case 'OneHot': {\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor1D;\n          const depth =\n              getParamValue('depth', node, tensorMap, context) as number;\n          const onValue =\n              getParamValue('onValue', node, tensorMap, context) as number;\n          const offValue =\n              getParamValue('offValue', node, tensorMap, context) as number;\n          const dtype =\n              getParamValue('dtype', node, tensorMap, context) as DataType;\n          return [ops.oneHot(indices, depth, onValue, offValue, dtype)];\n        }\n        case 'Ones': {\n          return [ops.ones(\n              getParamValue('shape', node, tensorMap, context) as number[],\n              getParamValue('dtype', node, tensorMap, context) as DataType)];\n        }\n        case 'OnesLike': {\n          return [ops.onesLike(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'RandomStandardNormal': {\n          return [ops.randomStandardNormal(\n              getParamValue('shape', node, tensorMap, context) as number[],\n              getParamValue('dtype', node, tensorMap, context) as 'float32' |\n                  'int32',\n              getParamValue('seed', node, tensorMap, context) as number)];\n        }\n        case 'RandomUniform': {\n          return [ops.randomUniform(\n              // tslint:disable-next-line:no-any\n              getParamValue('shape', node, tensorMap, context) as any,\n              getParamValue('minval', node, tensorMap, context) as number,\n              getParamValue('maxval', node, tensorMap, context) as number,\n              getParamValue('dtype', node, tensorMap, context) as DataType)];\n        }\n        case 'RandomUniformInt': {\n          return [ops.randomUniformInt(\n              getParamValue('shape', node, tensorMap, context) as number[],\n              getParamValue('minval', node, tensorMap, context) as number,\n              getParamValue('maxval', node, tensorMap, context) as number,\n              getParamValue('seed', node, tensorMap, context) as number)];\n        }\n        case 'Range': {\n          const start =\n              getParamValue('start', node, tensorMap, context) as number;\n          const stop =\n              getParamValue('stop', node, tensorMap, context) as number;\n          const step =\n              getParamValue('step', node, tensorMap, context) as number;\n          return [ops.range(\n              start, stop, step,\n              getParamValue('dtype', node, tensorMap, context) as 'float32' |\n                  'int32')];\n        }\n        case 'TruncatedNormal': {\n          const shape =\n              getParamValue('shape', node, tensorMap, context) as number[];\n          const mean =\n              getParamValue('mean', node, tensorMap, context) as number;\n          const stdDev =\n              getParamValue('stdDev', node, tensorMap, context) as number;\n          const seed =\n              getParamValue('seed', node, tensorMap, context) as number;\n          return [ops.truncatedNormal(\n              shape, mean, stdDev,\n              getParamValue('dtype', node, tensorMap, context) as 'float32' |\n                  'int32',\n              seed)];\n        }\n        case 'Zeros': {\n          return [ops.zeros(\n              getParamValue('shape', node, tensorMap, context) as number[],\n              getParamValue('dtype', node, tensorMap, context) as DataType)];\n        }\n        case 'ZerosLike': {\n          return [ops.zerosLike(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'creation';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport { ResourceManager } from '../../executor/resource_manager';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nfunction nmsParams(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) {\n  const boxes = getParamValue('boxes', node, tensorMap, context) as Tensor;\n  const scores = getParamValue('scores', node, tensorMap, context) as Tensor;\n  const maxOutputSize =\n      getParamValue('maxOutputSize', node, tensorMap, context) as number;\n  const iouThreshold =\n      getParamValue('iouThreshold', node, tensorMap, context) as number;\n  const scoreThreshold =\n      getParamValue('scoreThreshold', node, tensorMap, context) as number;\n  const softNmsSigma =\n      getParamValue('softNmsSigma', node, tensorMap, context) as number;\n\n  return {\n    boxes,\n    scores,\n    maxOutputSize,\n    iouThreshold,\n    scoreThreshold,\n    softNmsSigma\n  };\n}\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext, resourceManager: ResourceManager,\n    ops = tfOps): Promise<Tensor[]> => {\n  switch (node.op) {\n    case 'NonMaxSuppressionV5': {\n      const {\n        boxes,\n        scores,\n        maxOutputSize,\n        iouThreshold,\n        scoreThreshold,\n        softNmsSigma\n      } = nmsParams(node, tensorMap, context);\n\n      const result = await ops.image.nonMaxSuppressionWithScoreAsync(\n          boxes as Tensor2D, scores as Tensor1D, maxOutputSize, iouThreshold,\n          scoreThreshold, softNmsSigma);\n\n      return [result.selectedIndices, result.selectedScores];\n    }\n    case 'NonMaxSuppressionV4': {\n      const {boxes, scores, maxOutputSize, iouThreshold, scoreThreshold} =\n          nmsParams(node, tensorMap, context);\n\n      const padToMaxOutputSize =\n          getParamValue('padToMaxOutputSize', node, tensorMap, context) as\n          boolean;\n\n      const result = await ops.image.nonMaxSuppressionPaddedAsync(\n          boxes as Tensor2D, scores as Tensor1D, maxOutputSize, iouThreshold,\n          scoreThreshold, padToMaxOutputSize);\n\n      return [result.selectedIndices, result.validOutputs];\n    }\n    case 'NonMaxSuppressionV3':\n    case 'NonMaxSuppressionV2': {\n      const {boxes, scores, maxOutputSize, iouThreshold, scoreThreshold} =\n          nmsParams(node, tensorMap, context);\n\n      return [await ops.image.nonMaxSuppressionAsync(\n          boxes as Tensor2D, scores as Tensor1D, maxOutputSize, iouThreshold,\n          scoreThreshold)];\n    }\n    case 'Where': {\n      const condition = ops.cast(\n          (getParamValue('condition', node, tensorMap, context) as Tensor),\n          'bool');\n      const result = [await ops.whereAsync(condition)];\n      condition.dispose();\n      return result;\n    }\n    case 'ListDiff': {\n      return ops.setdiff1dAsync(\n          getParamValue('x', node, tensorMap, context) as Tensor,\n          getParamValue('y', node, tensorMap, context) as Tensor);\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'dynamic';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps):\n        Tensor[] => {\n          switch (node.op) {\n            case 'LowerBound': {\n              const sortedSequence =\n                  getParamValue('sortedSequence', node, tensorMap, context) as\n                  Tensor;\n              const values =\n                  getParamValue('values', node, tensorMap, context) as Tensor;\n              return [ops.lowerBound(sortedSequence, values)];\n            }\n            case 'TopKV2': {\n              const x = getParamValue('x', node, tensorMap, context) as Tensor;\n              const k = getParamValue('k', node, tensorMap, context) as number;\n              const sorted =\n                  getParamValue('sorted', node, tensorMap, context) as boolean;\n              const result = ops.topk(x, k, sorted);\n              return [result.values, result.indices];\n            }\n            case 'UpperBound': {\n              const sortedSequence =\n                  getParamValue('sortedSequence', node, tensorMap, context) as\n                  Tensor;\n              const values =\n                  getParamValue('values', node, tensorMap, context) as Tensor;\n              return [ops.upperBound(sortedSequence, values)];\n            }\n            case 'Unique': {\n              const x = getParamValue('x', node, tensorMap, context) as Tensor;\n              const result = ops.unique(x);\n              return [result.values, result.indices];\n            }\n            case 'UniqueV2': {\n              const x = getParamValue('x', node, tensorMap, context) as Tensor;\n              const axis =\n                  getParamValue('axis', node, tensorMap, context) as number;\n              const result = ops.unique(x, axis);\n              return [result.values, result.indices];\n            }\n            default:\n              throw TypeError(`Node type ${node.op} is not implemented`);\n          }\n        };\n\nexport const CATEGORY = 'evaluation';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {cloneTensor, getParamValue, getTensor} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Const': {\n          return tensorMap[node.name];\n        }\n        case 'PlaceholderWithDefault':\n          const def =\n              getParamValue('default', node, tensorMap, context) as Tensor;\n          return [getTensor(node.name, tensorMap, context) || def];\n        case 'Placeholder':\n          return [getTensor(node.name, tensorMap, context)];\n        case 'Identity':\n        case 'StopGradient':\n        case 'FakeQuantWithMinMaxVars': {  // This op is currently ignored.\n          const data = getParamValue('x', node, tensorMap, context) as Tensor;\n          return [cloneTensor(data)];\n        }\n        case 'IdentityN':\n          return (getParamValue('x', node, tensorMap, context) as Tensor[])\n              .map((t: Tensor) => cloneTensor(t));\n        case 'Snapshot':\n          const snapshot =\n              (getParamValue('x', node, tensorMap, context) as Tensor);\n          return [cloneTensor(snapshot)];\n        case 'Shape':\n          return [ops.tensor1d(\n              (getParamValue('x', node, tensorMap, context) as Tensor).shape,\n              'int32')];\n        case 'ShapeN':\n          return (getParamValue('x', node, tensorMap, context) as Tensor[])\n              .map((t: Tensor) => ops.tensor1d(t.shape));\n        case 'Size':\n          return [ops.scalar(\n              (getParamValue('x', node, tensorMap, context) as Tensor).size,\n              'int32')];\n        case 'Rank':\n          return [ops.scalar(\n              (getParamValue('x', node, tensorMap, context) as Tensor).rank,\n              'int32')];\n        case 'NoOp':\n          return [ops.scalar(1)];\n        case 'Print':\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          const data =\n              getParamValue('data', node, tensorMap, context) as Tensor[];\n          const message =\n              getParamValue('message', node, tensorMap, context) as string;\n          const summarize =\n              getParamValue('summarize', node, tensorMap, context) as number;\n          console.warn(\n              'The graph has a tf.print() operation,' +\n              'usually used for debugging, which slows down performance.');\n          console.log(message);\n          for (let i = 0; i < data.length; i++) {\n            console.log(Array.prototype.slice.call(data[i].dataSync())\n                            .slice(0, summarize));\n          }\n          return [input];\n\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'graph';\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {DataType, keep, scalar, stack, Tensor, tidy, unstack, util} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\n/**\n * Hashtable contains a set of tensors, which can be accessed by key.\n */\nexport class HashTable {\n  readonly handle: Tensor;\n\n  // tslint:disable-next-line: no-any\n  private tensorMap: Map<any, Tensor>;\n\n  get id() {\n    return this.handle.id;\n  }\n\n  /**\n   * Constructor of HashTable. Creates a hash table.\n   *\n   * @param keyDType `dtype` of the table keys.\n   * @param valueDType `dtype` of the table values.\n   */\n  constructor(readonly keyDType: DataType, readonly valueDType: DataType) {\n    this.handle = scalar(0);\n    // tslint:disable-next-line: no-any\n    this.tensorMap = new Map<any, Tensor>();\n\n    keep(this.handle);\n  }\n\n  /**\n   * Dispose the tensors and handle and clear the hashtable.\n   */\n  clearAndClose() {\n    this.tensorMap.forEach(value => value.dispose());\n    this.tensorMap.clear();\n    this.handle.dispose();\n  }\n\n  /**\n   * The number of items in the hash table.\n   */\n  size(): number {\n    return this.tensorMap.size;\n  }\n\n  /**\n   * The number of items in the hash table as a rank-0 tensor.\n   */\n  tensorSize(): Tensor {\n    return tfOps.scalar(this.size(), 'int32');\n  }\n\n  /**\n   * Replaces the contents of the table with the specified keys and values.\n   * @param keys Keys to store in the hashtable.\n   * @param values Values to store in the hashtable.\n   */\n  async import(keys: Tensor, values: Tensor): Promise<Tensor> {\n    this.checkKeyAndValueTensor(keys, values);\n\n    // We only store the primitive values of the keys, this allows lookup\n    // to be O(1).\n    const $keys = await keys.data();\n\n    // Clear the hashTable before inserting new values.\n    this.tensorMap.forEach(value => value.dispose());\n    this.tensorMap.clear();\n\n    return tidy(() => {\n      const $values = unstack(values);\n\n      const keysLength = $keys.length;\n      const valuesLength = $values.length;\n\n      util.assert(\n          keysLength === valuesLength,\n          () => `The number of elements doesn't match, keys has ` +\n              `${keysLength} elements, the values has ${valuesLength} ` +\n              `elements.`);\n\n      for (let i = 0; i < keysLength; i++) {\n        const key = $keys[i];\n        const value = $values[i];\n\n        keep(value);\n        this.tensorMap.set(key, value);\n      }\n\n      return this.handle;\n    });\n  }\n\n  /**\n   * Looks up keys in a hash table, outputs the corresponding values.\n   *\n   * Performs batch lookups, for every element in the key tensor, `find`\n   * stacks the corresponding value into the return tensor.\n   *\n   * If an element is not present in the table, the given `defaultValue` is\n   * used.\n   *\n   * @param keys Keys to look up. Must have the same type as the keys of the\n   *     table.\n   * @param defaultValue The scalar `defaultValue` is the value output for keys\n   *     not present in the table. It must also be of the same type as the\n   *     table values.\n   */\n  async find(keys: Tensor, defaultValue: Tensor): Promise<Tensor> {\n    this.checkKeyAndValueTensor(keys, defaultValue);\n\n    const $keys = await keys.data();\n\n    return tidy(() => {\n      const result: Tensor[] = [];\n\n      for (let i = 0; i < $keys.length; i++) {\n        const key = $keys[i];\n\n        const value = this.findWithDefault(key, defaultValue);\n        result.push(value);\n      }\n\n      return stack(result);\n    });\n  }\n\n  // tslint:disable-next-line: no-any\n  private findWithDefault(key: any, defaultValue: Tensor): Tensor {\n    const result = this.tensorMap.get(key);\n\n    return result != null ? result : defaultValue;\n  }\n\n  private checkKeyAndValueTensor(key: Tensor, value: Tensor) {\n    if (key.dtype !== this.keyDType) {\n      throw new Error(\n          `Expect key dtype ${this.keyDType}, but got ` +\n          `${key.dtype}`);\n    }\n\n    if (value.dtype !== this.valueDType) {\n      throw new Error(\n          `Expect value dtype ${this.valueDType}, but got ` +\n          `${value.dtype}`);\n    }\n  }\n}\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {HashTable} from '../../executor/hash_table';\nimport {ResourceManager} from '../../executor/resource_manager';\nimport {InternalOpAsyncExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpAsyncExecutor = async(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n    resourceManager: ResourceManager): Promise<Tensor[]> => {\n  switch (node.op) {\n    case 'HashTable':\n    case 'HashTableV2': {\n      const existingTableHandle =\n          resourceManager.getHashTableHandleByName(node.name);\n      // Table is shared with initializer.\n      if (existingTableHandle != null) {\n        return [existingTableHandle];\n      } else {\n        const keyDType =\n            getParamValue('keyDType', node, tensorMap, context) as DataType;\n        const valueDType =\n            getParamValue('valueDType', node, tensorMap, context) as DataType;\n\n        const hashTable = new HashTable(keyDType, valueDType);\n        resourceManager.addHashTable(node.name, hashTable);\n        return [hashTable.handle];\n      }\n    }\n    case 'InitializeTable':\n    case 'InitializeTableV2':\n    case 'LookupTableImport':\n    case 'LookupTableImportV2': {\n      const handle = getParamValue(\n                         'tableHandle', node, tensorMap, context,\n                         resourceManager) as Tensor;\n      const keys = getParamValue('keys', node, tensorMap, context) as Tensor;\n      const values =\n          getParamValue('values', node, tensorMap, context) as Tensor;\n\n      const hashTable = resourceManager.getHashTableById(handle.id);\n\n      return [await hashTable.import(keys, values)];\n    }\n    case 'LookupTableFind':\n    case 'LookupTableFindV2': {\n      const handle = getParamValue(\n                         'tableHandle', node, tensorMap, context,\n                         resourceManager) as Tensor;\n      const keys = getParamValue('keys', node, tensorMap, context) as Tensor;\n      const defaultValue =\n          getParamValue('defaultValue', node, tensorMap, context) as Tensor;\n\n      const hashTable = resourceManager.getHashTableById(handle.id);\n      return [await hashTable.find(keys, defaultValue)];\n    }\n    case 'LookupTableSize':\n    case 'LookupTableSizeV2': {\n      const handle = getParamValue(\n                         'tableHandle', node, tensorMap, context,\n                         resourceManager) as Tensor;\n\n      const hashTable = resourceManager.getHashTableById(handle.id);\n      return [hashTable.tensorSize()];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'hash_table';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'ResizeBilinear': {\n          const images =\n              getParamValue('images', node, tensorMap, context) as Tensor;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number[];\n          const alignCorners =\n              getParamValue('alignCorners', node, tensorMap, context) as\n              boolean;\n          const halfPixelCenters =\n              getParamValue('halfPixelCenters', node, tensorMap, context) as\n              boolean;\n          return [ops.image.resizeBilinear(\n              images as Tensor3D | Tensor4D, [size[0], size[1]], alignCorners,\n              halfPixelCenters)];\n        }\n        case 'ResizeNearestNeighbor': {\n          const images =\n              getParamValue('images', node, tensorMap, context) as Tensor;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number[];\n          const alignCorners =\n              getParamValue('alignCorners', node, tensorMap, context) as\n              boolean;\n          const halfPixelCenters =\n              getParamValue('halfPixelCenters', node, tensorMap, context) as\n              boolean;\n          return [ops.image.resizeNearestNeighbor(\n              images as Tensor3D | Tensor4D, [size[0], size[1]], alignCorners,\n              halfPixelCenters)];\n        }\n        case 'CropAndResize': {\n          const image =\n              getParamValue('image', node, tensorMap, context) as Tensor;\n          const boxes =\n              getParamValue('boxes', node, tensorMap, context) as Tensor;\n          const boxInd =\n              getParamValue('boxInd', node, tensorMap, context) as Tensor;\n          const cropSize =\n              getParamValue('cropSize', node, tensorMap, context) as number[];\n          const method =\n              getParamValue('method', node, tensorMap, context) as string;\n          const extrapolationValue =\n              getParamValue('extrapolationValue', node, tensorMap, context) as\n              number;\n          return [ops.image.cropAndResize(\n              image as Tensor4D, boxes as Tensor2D, boxInd as Tensor1D,\n              cropSize as [number, number], method as 'bilinear' | 'nearest',\n              extrapolationValue)];\n        }\n        case 'ImageProjectiveTransformV3': {\n          const images =\n              getParamValue('images', node, tensorMap, context) as Tensor;\n          const transforms =\n              getParamValue('transforms', node, tensorMap, context) as Tensor;\n          const outputShape =\n              getParamValue('outputShape', node, tensorMap, context) as\n              number[];\n          const fillValue =\n              getParamValue('fillValue', node, tensorMap, context) as number;\n          const interpolation =\n              getParamValue('interpolation', node, tensorMap, context) as\n              string;\n          const fillMode =\n              getParamValue('fillMode', node, tensorMap, context) as string;\n          return [ops.image.transform(\n              images as Tensor4D,\n              transforms as Tensor2D,\n              interpolation.toLowerCase() as 'bilinear' | 'nearest',\n              fillMode.toLowerCase() as 'constant' | 'reflect' | 'wrap' | 'nearest',\n              fillValue,\n              outputShape as [number, number])];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'image';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Equal': {\n          return [ops.equal(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'NotEqual': {\n          return [ops.notEqual(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Greater': {\n          return [ops.greater(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'GreaterEqual': {\n          return [ops.greaterEqual(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Less': {\n          return [ops.less(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'LessEqual': {\n          return [ops.lessEqual(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogicalAnd': {\n          return [ops.logicalAnd(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogicalNot': {\n          return [ops.logicalNot(\n              getParamValue('a', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogicalOr': {\n          return [ops.logicalOr(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'Select':\n        case 'SelectV2': {\n          return [ops.where(\n              getParamValue('condition', node, tensorMap, context) as Tensor,\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        case 'BitwiseAnd': {\n          return [ops.bitwiseAnd(\n              getParamValue('a', node, tensorMap, context) as Tensor,\n              getParamValue('b', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'logical';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'BatchMatMul':\n        case 'BatchMatMulV2':\n        case 'MatMul':\n          return [ops.matMul(\n              getParamValue('a', node, tensorMap, context) as Tensor2D,\n              getParamValue('b', node, tensorMap, context) as Tensor2D,\n              getParamValue('transposeA', node, tensorMap, context) as boolean,\n              getParamValue('transposeB', node, tensorMap, context) as\n                  boolean)];\n\n        case 'Einsum':\n          return [ops.einsum(\n              getParamValue('equation', node, tensorMap, context) as string,\n              ...getParamValue('tensors', node, tensorMap, context) as\n                  Tensor[])];\n\n        case 'Transpose':\n          return [ops.transpose(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('perm', node, tensorMap, context) as number[])];\n\n        case '_FusedMatMul':\n          const [extraOp, activationFunc] =\n              (getParamValue('fusedOps', node, tensorMap, context) as string[]);\n\n          const isBiasAdd = extraOp === 'biasadd';\n          const isPrelu = activationFunc === 'prelu';\n\n          const numArgs =\n              (getParamValue('numArgs', node, tensorMap, context) as number);\n          const leakyreluAlpha =\n              getParamValue('leakyreluAlpha', node, tensorMap, context) as\n              number;\n\n          if (isBiasAdd) {\n            if (isPrelu && numArgs !== 2) {\n              throw new Error(\n                  'Fused MatMul with BiasAdd and Prelu must have two ' +\n                  'extra arguments: bias and alpha.');\n            }\n            if (!isPrelu && numArgs !== 1) {\n              throw new Error(\n                  'Fused MatMul with BiasAdd must have one extra argument: bias.');\n            }\n          }\n          const [biasArg, preluArg] =\n              getParamValue('args', node, tensorMap, context) as Tensor[];\n          return [ops.fused.matMul({\n            a: getParamValue('a', node, tensorMap, context) as Tensor2D,\n            b: getParamValue('b', node, tensorMap, context) as Tensor2D,\n            transposeA: getParamValue('transposeA', node, tensorMap, context) as\n                boolean,\n            transposeB: getParamValue('transposeB', node, tensorMap, context) as\n                boolean,\n            bias: biasArg,\n            activation: activationFunc as tfOps.fused.Activation,\n            preluActivationWeights: preluArg,\n            leakyreluAlpha\n          })];\n\n        case 'MatrixBandPart':\n          return [ops.linalg.bandPart(\n              getParamValue('a', node, tensorMap, context) as Tensor2D,\n              getParamValue('numLower', node, tensorMap, context) as Scalar,\n              getParamValue('numUpper', node, tensorMap, context) as Scalar)];\n\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'matrices';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor3D, Tensor4D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'EuclideanNorm':\n          return [ops.euclideanNorm(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('axis', node, tensorMap, context) as number[],\n              getParamValue('keepDims', node, tensorMap, context) as boolean)];\n        case 'FusedBatchNorm':\n        case 'FusedBatchNormV2': {\n          return [ops.batchNorm(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('mean', node, tensorMap, context) as Tensor,\n              getParamValue('variance', node, tensorMap, context) as Tensor,\n              getParamValue('offset', node, tensorMap, context) as Tensor,\n              getParamValue('scale', node, tensorMap, context) as Tensor,\n              getParamValue('epsilon', node, tensorMap, context) as number)];\n        }\n        case 'FusedBatchNormV3': {\n          return [ops.batchNorm(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('mean', node, tensorMap, context) as Tensor,\n              getParamValue('variance', node, tensorMap, context) as Tensor,\n              getParamValue('offset', node, tensorMap, context) as Tensor,\n              getParamValue('scale', node, tensorMap, context) as Tensor,\n              getParamValue('epsilon', node, tensorMap, context) as number)];\n        }\n        case 'LRN': {\n          return [ops.localResponseNormalization(\n              getParamValue('x', node, tensorMap, context) as Tensor3D |\n                  Tensor4D,\n              getParamValue('radius', node, tensorMap, context) as number,\n              getParamValue('bias', node, tensorMap, context) as number,\n              getParamValue('alpha', node, tensorMap, context) as number,\n              getParamValue('beta', node, tensorMap, context) as number)];\n        }\n        case 'Softmax': {\n          return [ops.softmax(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        case 'LogSoftmax': {\n          return [ops.logSoftmax(\n              getParamValue('x', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'normalization';\n", "/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'RaggedGather': {\n          const {\n            outputNestedSplits,\n            outputDenseValues,\n          } =\n              ops.raggedGather(\n                  getParamValue(\n                      'paramsNestedSplits', node, tensorMap, context) as\n                      Tensor[],\n                  getParamValue(\n                      'paramsDenseValues', node, tensorMap, context) as Tensor,\n                  getParamValue('indices', node, tensorMap, context) as Tensor,\n                  getParamValue('outputRaggedRank', node, tensorMap, context) as\n                      number);\n          return outputNestedSplits.concat(outputDenseValues);\n        }\n        case 'RaggedRange': {\n          const {rtNestedSplits, rtDenseValues} = ops.raggedRange(\n              getParamValue('starts', node, tensorMap, context) as Tensor,\n              getParamValue('limits', node, tensorMap, context) as Tensor,\n              getParamValue('splits', node, tensorMap, context) as Tensor);\n          return [rtNestedSplits, rtDenseValues];\n        }\n        case 'RaggedTensorToTensor': {\n          return [ops.raggedTensorToTensor(\n              getParamValue('shape', node, tensorMap, context) as Tensor,\n              getParamValue('values', node, tensorMap, context) as Tensor1D,\n              getParamValue('defaultValue', node, tensorMap, context) as Tensor,\n              getParamValue('rowPartitionTensors', node, tensorMap, context) as\n                  Tensor[],\n              getParamValue('rowPartitionTypes', node, tensorMap, context) as\n                  string[])];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'ragged';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor1D, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Max': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.max(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Mean': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.mean(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Min': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.min(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Sum': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.sum(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'All': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.all(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Any': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.any(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'ArgMax': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          return [ops.argMax(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n        case 'ArgMin': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          return [ops.argMin(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n        case 'Prod': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const keepDims =\n              getParamValue('keepDims', node, tensorMap, context) as boolean;\n          return [ops.prod(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              keepDims)];\n        }\n        case 'Cumprod': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const exclusive =\n              getParamValue('exclusive', node, tensorMap, context) as boolean;\n          const reverse =\n              getParamValue('reverse', node, tensorMap, context) as boolean;\n          return [ops.cumprod(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              exclusive, reverse)];\n        }\n        case 'Cumsum': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const exclusive =\n              getParamValue('exclusive', node, tensorMap, context) as boolean;\n          const reverse =\n              getParamValue('reverse', node, tensorMap, context) as boolean;\n          return [ops.cumsum(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis,\n              exclusive, reverse)];\n        }\n        case 'Bincount':\n          const x = getParamValue('x', node, tensorMap, context) as Tensor1D;\n          const weights =\n              getParamValue('weights', node, tensorMap, context) as Tensor1D;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number;\n\n          return [ops.bincount(x, weights, size)];\n        case 'DenseBincount': {\n          const x = getParamValue('x', node, tensorMap, context) as Tensor1D |\n              Tensor2D;\n          const weights =\n              getParamValue('weights', node, tensorMap, context) as Tensor1D |\n              Tensor2D;\n          const size =\n              getParamValue('size', node, tensorMap, context) as number;\n\n          const binaryOutput =\n              getParamValue('binaryOutput', node, tensorMap, context) as\n              boolean;\n\n          return [ops.denseBincount(x, weights, size, binaryOutput)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'reduction';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor1D, tidy, util} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'ConcatV2':\n        case 'Concat': {\n          const n = getParamValue('n', node, tensorMap, context) as number;\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          let inputs =\n              getParamValue('tensors', node, tensorMap, context) as Tensor[];\n          inputs = inputs.slice(0, n);\n          return [ops.concat(inputs, axis)];\n        }\n        case 'Gather': {\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor1D;\n          return [ops.gather(input, ops.cast(indices, 'int32'), 0)];\n        }\n        case 'GatherV2': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const batchDims =\n              getParamValue('batchDims', node, tensorMap, context) as number;\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor1D;\n          return [ops.gather(\n              input, ops.cast(indices, 'int32'), axis, batchDims)];\n        }\n        case 'Reverse': {\n          const dims =\n              getParamValue('dims', node, tensorMap, context) as boolean[];\n          const axis = [];\n          for (let i = 0; i < dims.length; i++) {\n            if (dims[i]) {\n              axis.push(i);\n            }\n          }\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          return [ops.reverse(input, axis)];\n        }\n        case 'ReverseV2': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          const input = getParamValue('x', node, tensorMap, context) as Tensor;\n          return [ops.reverse(input, axis)];\n        }\n        case 'Slice': {\n          // tslint:disable-next-line:no-any\n          const begin = getParamValue('begin', node, tensorMap, context) as any;\n          // tslint:disable-next-line:no-any\n          const size = getParamValue('size', node, tensorMap, context) as any;\n          return [ops.slice(\n              getParamValue('x', node, tensorMap, context) as Tensor, begin,\n              size)];\n        }\n        case 'StridedSlice': {\n          const begin =\n              getParamValue('begin', node, tensorMap, context) as number[];\n          const end =\n              getParamValue('end', node, tensorMap, context) as number[];\n          const strides =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const beginMask =\n              getParamValue('beginMask', node, tensorMap, context) as number;\n          const endMask =\n              getParamValue('endMask', node, tensorMap, context) as number;\n          const ellipsisMask =\n              getParamValue('ellipsisMask', node, tensorMap, context) as number;\n          const newAxisMask =\n              getParamValue('newAxisMask', node, tensorMap, context) as number;\n          const shrinkAxisMask =\n              getParamValue('shrinkAxisMask', node, tensorMap, context) as\n              number;\n          const tensor = getParamValue('x', node, tensorMap, context) as Tensor;\n\n          return [ops.stridedSlice(\n              tensor, begin, end, strides, beginMask, endMask, ellipsisMask,\n              newAxisMask, shrinkAxisMask)];\n        }\n        case 'Pack': {\n          return tidy(() => {\n            const axis =\n                getParamValue('axis', node, tensorMap, context) as number;\n            const tensors =\n                getParamValue('tensors', node, tensorMap, context) as Tensor[];\n            // Reshape the tensors to the first tensor's shape if they don't\n            // match.\n            const shape = tensors[0].shape;\n            const squeezedShape = ops.squeeze(tensors[0]).shape;\n            const mapped = tensors.map(tensor => {\n              const sameShape = util.arraysEqual(tensor.shape, shape);\n              if (!sameShape &&\n                  !util.arraysEqual(ops.squeeze(tensor).shape, squeezedShape)) {\n                throw new Error('the input tensors shape does not match');\n              }\n              return sameShape ? tensor : ops.reshape(tensor, shape);\n            });\n            return [ops.stack(mapped, axis)];\n          });\n        }\n        case 'Unpack': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const tensor =\n              getParamValue('tensor', node, tensorMap, context) as Tensor;\n          return ops.unstack(tensor, axis);\n        }\n        case 'Tile': {\n          const reps =\n              getParamValue('reps', node, tensorMap, context) as number[];\n          return [ops.tile(\n              getParamValue('x', node, tensorMap, context) as Tensor, reps)];\n        }\n        case 'Split':\n        case 'SplitV': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          const numOrSizeSplits =\n              getParamValue('numOrSizeSplits', node, tensorMap, context) as\n                  number |\n              number[];\n          const tensor = getParamValue('x', node, tensorMap, context) as Tensor;\n\n          return ops.split(tensor, numOrSizeSplits, axis);\n        }\n        case 'ScatterNd': {\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor;\n          const values =\n              getParamValue('values', node, tensorMap, context) as Tensor;\n          const shape =\n              getParamValue('shape', node, tensorMap, context) as number[];\n          return [ops.scatterND(indices, values, shape)];\n        }\n        case 'GatherNd': {\n          const x = getParamValue('x', node, tensorMap, context) as Tensor;\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor;\n          return [ops.gatherND(x, indices)];\n        }\n        case 'SparseToDense': {\n          const indices =\n              getParamValue('sparseIndices', node, tensorMap, context) as\n              Tensor;\n          const shape =\n              getParamValue('outputShape', node, tensorMap, context) as\n              number[];\n          const sparseValues =\n              getParamValue('sparseValues', node, tensorMap, context) as Tensor;\n          const defaultValue =\n              getParamValue('defaultValue', node, tensorMap, context) as Scalar;\n          return [ops.sparseToDense(\n              indices, sparseValues, shape,\n              sparseValues.dtype === defaultValue.dtype ?\n                  defaultValue :\n                  ops.cast(defaultValue, sparseValues.dtype))];\n        }\n        case 'TensorScatterUpdate': {\n          const indices =\n              getParamValue('indices', node, tensorMap, context) as Tensor;\n          const values =\n              getParamValue('values', node, tensorMap, context) as Tensor;\n          const tensor =\n              getParamValue('tensor', node, tensorMap, context) as Tensor;\n          return [ops.tensorScatterUpdate(tensor, indices, values)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'slice_join';\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor1D, Tensor2D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'SparseFillEmptyRows': {\n          const {\n            outputIndices,\n            outputValues,\n            emptyRowIndicator,\n            reverseIndexMap\n          } =\n              ops.sparse.sparseFillEmptyRows(\n                  getParamValue('indices', node, tensorMap, context) as\n                      Tensor2D,\n                  getParamValue('values', node, tensorMap, context) as Tensor1D,\n                  getParamValue('denseShape', node, tensorMap, context) as\n                      Tensor1D,\n                  getParamValue('defaultValue', node, tensorMap, context) as\n                      Scalar);\n          return [\n            outputIndices, outputValues, emptyRowIndicator, reverseIndexMap\n          ];\n        }\n        case 'SparseReshape': {\n          const {outputIndices, outputShape} = ops.sparse.sparseReshape(\n              getParamValue('inputIndices', node, tensorMap, context) as\n                  Tensor2D,\n              getParamValue('inputShape', node, tensorMap, context) as Tensor1D,\n              getParamValue('newShape', node, tensorMap, context) as Tensor1D);\n          return [outputIndices, outputShape];\n        }\n        case 'SparseSegmentMean': {\n          const outputData = ops.sparse.sparseSegmentMean(\n              getParamValue('data', node, tensorMap, context) as Tensor,\n              getParamValue('indices', node, tensorMap, context) as Tensor1D,\n              getParamValue('segmentIds', node, tensorMap, context) as\n                  Tensor1D);\n          return [outputData];\n        }\n        case 'SparseSegmentSum': {\n          const outputData = ops.sparse.sparseSegmentSum(\n              getParamValue('data', node, tensorMap, context) as Tensor,\n              getParamValue('indices', node, tensorMap, context) as Tensor1D,\n              getParamValue('segmentIds', node, tensorMap, context) as\n                  Tensor1D);\n          return [outputData];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'sparse';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps): Tensor[] => {\n          switch (node.op) {\n            case 'FFT': {\n              return [ops.fft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            case 'IFFT': {\n              return [ops.ifft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            case 'RFFT': {\n              return [ops.rfft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            case 'IRFFT': {\n              return [ops.irfft(\n                  getParamValue('x', node, tensorMap, context) as Tensor)];\n            }\n            default:\n              throw TypeError(`Node type ${node.op} is not implemented`);\n          }\n        };\n\nexport const CATEGORY = 'spectral';\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Scalar, Tensor, Tensor1D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext, ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'StaticRegexReplace': {\n          return [ops.string.staticRegexReplace(\n            getParamValue('input', node, tensorMap, context) as Tensor,\n            getParamValue('pattern', node, tensorMap, context) as string,\n            getParamValue('rewrite', node, tensorMap, context) as string,\n            getParamValue('replaceGlobal', node, tensorMap, context) as boolean,\n          )];\n        }\n        case 'StringNGrams': {\n          const {nGrams, nGramsSplits} = ops.string.stringNGrams(\n              getParamValue('data', node, tensorMap, context) as Tensor1D,\n              getParamValue('dataSplits', node, tensorMap, context) as Tensor,\n              getParamValue('separator', node, tensorMap, context) as string,\n              getParamValue('nGramWidths', node, tensorMap, context) as\n                  number[],\n              getParamValue('leftPad', node, tensorMap, context) as string,\n              getParamValue('rightPad', node, tensorMap, context) as string,\n              getParamValue('padWidth', node, tensorMap, context) as number,\n              getParamValue(\n                  'preserveShortSequences', node, tensorMap, context) as\n                  boolean);\n          return [nGrams, nGramsSplits];\n        }\n        case 'StringSplit': {\n          const {indices, values, shape} = ops.string.stringSplit(\n              getParamValue('input', node, tensorMap, context) as Tensor1D,\n              getParamValue('delimiter', node, tensorMap, context) as Scalar,\n              getParamValue('skipEmpty', node, tensorMap, context) as boolean);\n          return [indices, values, shape];\n        }\n        case 'StringToHashBucketFast': {\n          const output = ops.string.stringToHashBucketFast(\n              getParamValue('input', node, tensorMap, context) as Tensor,\n              getParamValue('numBuckets', node, tensorMap, context) as number);\n          return [output];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'string';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Tensor, Tensor4D} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport const executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n     ops = tfOps): Tensor[] => {\n      switch (node.op) {\n        case 'Cast': {\n          return [ops.cast(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('dtype', node, tensorMap, context) as 'int32' |\n                  'float32' | 'bool')];\n        }\n        case 'ExpandDims': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number;\n          return [ops.expandDims(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n        case 'Squeeze': {\n          const axis =\n              getParamValue('axis', node, tensorMap, context) as number[];\n          return [ops.squeeze(\n              getParamValue('x', node, tensorMap, context) as Tensor, axis)];\n        }\n\n        case 'Reshape': {\n          return [ops.reshape(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('shape', node, tensorMap, context) as number[])];\n        }\n        case 'EnsureShape': {\n          return [ops.ensureShape(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('shape', node, tensorMap, context) as number[])];\n        }\n        case 'MirrorPad': {\n          return [ops.mirrorPad(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('padding', node, tensorMap, context) as\n                  Array<[number, number]>,\n              getParamValue('mode', node, tensorMap, context) as 'reflect' |\n                  'symmetric')];\n        }\n        case 'PadV2':\n        case 'Pad': {\n          return [ops.pad(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('padding', node, tensorMap, context) as\n                  Array<[number, number]>,\n              getParamValue('constantValue', node, tensorMap, context) as\n                  number)];\n        }\n        case 'SpaceToBatchND': {\n          const blockShape =\n              getParamValue('blockShape', node, tensorMap, context) as number[];\n          const paddings =\n              getParamValue('paddings', node, tensorMap, context) as number[][];\n          return [ops.spaceToBatchND(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              blockShape, paddings)];\n        }\n        case 'BatchToSpaceND': {\n          const blockShape =\n              getParamValue('blockShape', node, tensorMap, context) as number[];\n          const crops =\n              getParamValue('crops', node, tensorMap, context) as number[][];\n          return [ops.batchToSpaceND(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              blockShape, crops)];\n        }\n        case 'DepthToSpace': {\n          const blockSize =\n              getParamValue('blockSize', node, tensorMap, context) as number;\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as\n               string).toUpperCase() as 'NHWC' |\n              'NCHW';\n          return [ops.depthToSpace(\n              getParamValue('x', node, tensorMap, context) as Tensor4D,\n              blockSize, dataFormat)];\n        }\n        case 'BroadcastTo': {\n          return [ops.broadcastTo(\n              getParamValue('x', node, tensorMap, context) as Tensor,\n              getParamValue('shape', node, tensorMap, context) as number[])];\n        }\n        case 'BroadcastArgs': {\n          return [ops.broadcastArgs(\n              getParamValue('s0', node, tensorMap, context) as Tensor,\n              getParamValue('s1', node, tensorMap, context) as Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'transformation';\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {ExecutionContext} from '../executor/execution_context';\nimport {ResourceManager} from '../executor/resource_manager';\n\nimport {NodeValueImpl} from './custom_op/node_value_impl';\nimport {getRegisteredOp} from './custom_op/register';\nimport * as arithmetic from './executors/arithmetic_executor';\nimport * as basicMath from './executors/basic_math_executor';\nimport * as control from './executors/control_executor';\nimport * as convolution from './executors/convolution_executor';\nimport * as creation from './executors/creation_executor';\nimport * as dynamic from './executors/dynamic_executor';\nimport * as evaluation from './executors/evaluation_executor';\nimport * as graph from './executors/graph_executor';\nimport * as hashTable from './executors/hash_table_executor';\nimport * as image from './executors/image_executor';\nimport * as logical from './executors/logical_executor';\nimport * as matrices from './executors/matrices_executor';\nimport * as normalization from './executors/normalization_executor';\nimport * as ragged from './executors/ragged_executor';\nimport * as reduction from './executors/reduction_executor';\nimport * as sliceJoin from './executors/slice_join_executor';\nimport * as sparse from './executors/sparse_executor';\nimport * as spectral from './executors/spectral_executor';\nimport * as string from './executors/string_executor';\nimport * as transformation from './executors/transformation_executor';\nimport {Node} from './types';\n\n/**\n * Executes the op defined by the node object.\n * @param node\n * @param tensorMap contains tensors for executed nodes and weights\n * @param context contains tensors and information for running the current node.\n * @param resourceManager Optional. Contains global resources of the model.\n */\nexport function executeOp(\n    node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n    resourceManager?: ResourceManager, tidy = tfc.tidy): tfc.Tensor[]|\n    Promise<tfc.Tensor[]> {\n  const value =\n      ((node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) => {\n        switch (node.category) {\n          case 'arithmetic':\n            return tidy(() => arithmetic.executeOp(node, tensorMap, context));\n          case 'basic_math':\n            return tidy(() => basicMath.executeOp(node, tensorMap, context));\n          case 'control':\n            return control.executeOp(node, tensorMap, context);\n          case 'convolution':\n            return tidy(() => convolution.executeOp(node, tensorMap, context));\n          case 'creation':\n            return tidy(() => creation.executeOp(node, tensorMap, context));\n          case 'dynamic':\n            return dynamic.executeOp(node, tensorMap, context);\n          case 'evaluation':\n            return tidy(() => evaluation.executeOp(node, tensorMap, context));\n          case 'image':\n            return tidy(() => image.executeOp(node, tensorMap, context));\n          case 'graph':\n            return tidy(() => graph.executeOp(node, tensorMap, context));\n          case 'logical':\n            return tidy(() => logical.executeOp(node, tensorMap, context));\n          case 'matrices':\n            return tidy(() => matrices.executeOp(node, tensorMap, context));\n          case 'normalization':\n            return tidy(\n                () => normalization.executeOp(node, tensorMap, context));\n          case 'ragged':\n            return tidy(() => ragged.executeOp(node, tensorMap, context));\n          case 'reduction':\n            return tidy(() => reduction.executeOp(node, tensorMap, context));\n          case 'slice_join':\n            return tidy(() => sliceJoin.executeOp(node, tensorMap, context));\n          case 'sparse':\n            return tidy(() => sparse.executeOp(node, tensorMap, context));\n          case 'spectral':\n            return tidy(() => spectral.executeOp(node, tensorMap, context));\n          case 'string':\n            return tidy(() => string.executeOp(node, tensorMap, context));\n          case 'transformation':\n            return tidy(\n                () => transformation.executeOp(node, tensorMap, context));\n          case 'hash_table':\n            return hashTable.executeOp(\n                node, tensorMap, context, resourceManager);\n          case 'custom':\n            const opMapper = getRegisteredOp(node.op);\n            if (opMapper && opMapper.customExecutor) {\n              return opMapper.customExecutor(\n                  new NodeValueImpl(node, tensorMap, context));\n            } else {\n              throw TypeError(`Custom op ${node.op} is not registered.`);\n            }\n          default:\n            throw TypeError(\n                `Unknown op '${node.op}'. File an issue at ` +\n                `https://github.com/tensorflow/tfjs/issues so we can add it` +\n                `, or register a custom execution with tf.registerOp()`);\n        }\n      })(node, tensorMap, context);\n  if (tfc.util.isPromise(value)) {\n    return value.then((data) => [].concat(data));\n  }\n  return [].concat(value);\n}\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap, TensorArrayMap, TensorListMap} from '../data/types';\n\nimport {TensorArray} from './tensor_array';\nimport {TensorList} from './tensor_list';\nimport {FunctionExecutor} from './types';\n\nexport interface ExecutionContextInfo {\n  id: number;           // the unique id of the context info\n  frameName: string;    // The frame name of the loop, this comes from\n                        // the TensorFlow NodeDef.\n  iterationId: number;  // The iteration id of the loop\n}\n\n/**\n * ExecutionContext captures the runtime environment of the node. It keeps\n * track of the current frame and iteration for the control flow ops.\n *\n * For example, typical Dynamic RNN model may contain loops, for which\n * TensorFlow will generate graphs with Enter/Exit nodes to control the\n * current execution frame, and NextIteration Nodes for iteration id increment.\n * For model with branch logic, TensorFLow will generate Switch/Merge ops.\n */\nexport class ExecutionContext {\n  private rootContext = {id: 0, frameName: '', iterationId: 0};\n  private contexts: ExecutionContextInfo[] = [this.rootContext];\n  private lastId = 0;\n  private _currentContextIds: string[];\n\n  constructor(\n      readonly weightMap: NamedTensorsMap = {},\n      readonly tensorArrayMap: TensorArrayMap = {},\n      readonly tensorListMap: TensorListMap = {},\n      readonly functionMap: {[key: string]: FunctionExecutor} = {},\n      readonly parseNodeNameCache?: Map<string, [string, number, string?]>) {\n    this.generateCurrentContextIds();\n  }\n\n  private newFrame(id: number, frameName: string) {\n    return {id, frameName, iterationId: 0};\n  }\n\n  /**\n   * Set the current context\n   * @param contexts: ExecutionContextInfo[] the current path of execution\n   * frames\n   */\n  set currentContext(contexts: ExecutionContextInfo[]) {\n    if (this.contexts !== contexts) {\n      this.contexts = contexts;\n      this.generateCurrentContextIds();\n    }\n  }\n\n  get currentContext(): ExecutionContextInfo[] {\n    return this.contexts;\n  }\n\n  /**\n   * Returns the current context in string format.\n   */\n  get currentContextId(): string {\n    return this._currentContextIds[0];\n  }\n\n  /**\n   * Returns the current context and all parent contexts in string format.\n   * This allow access to the nodes in the current and parent frames.\n   */\n  get currentContextIds(): string[] {\n    return this._currentContextIds;\n  }\n\n  private generateCurrentContextIds() {\n    const names = [];\n    for (let i = 0; i < this.contexts.length - 1; i++) {\n      const contexts = this.contexts.slice(0, this.contexts.length - i);\n      names.push(this.contextIdforContexts(contexts));\n    }\n    names.push('');\n    this._currentContextIds = names;\n  }\n\n  private contextIdforContexts(contexts: ExecutionContextInfo[]) {\n    return contexts ?\n        contexts\n            .map(\n                context => (context.id === 0 && context.iterationId === 0) ?\n                    '' :\n                    `${context.frameName}-${context.iterationId}`)\n            .join('/') :\n        '';\n  }\n\n  /**\n   * Enter a new frame, a new context is pushed on the current context list.\n   * @param frameId new frame id\n   */\n  enterFrame(frameId: string) {\n    if (this.contexts) {\n      this.lastId++;\n      this.contexts = this.contexts.slice();\n      this.contexts.push(this.newFrame(this.lastId, frameId));\n      this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));\n    }\n  }\n\n  /**\n   * Exit the current frame, the last context is removed from the current\n   * context list.\n   */\n  exitFrame() {\n    if (this.contexts && this.contexts.length > 1) {\n      this.contexts = this.contexts.slice();\n      this.contexts.splice(-1);\n      this.currentContextIds.shift();\n    } else {\n      throw new Error('Cannot exit frame, the context is empty');\n    }\n  }\n\n  /**\n   * Enter the next iteration of a loop, the iteration id of last context is\n   * increased.\n   */\n  nextIteration() {\n    if (this.contexts && this.contexts.length > 0) {\n      this.contexts = this.contexts.slice();\n      this.lastId++;\n      const context =\n          Object.assign({}, this.contexts[this.contexts.length - 1]);\n      context.iterationId += 1;\n      context.id = this.lastId;\n      this.contexts.splice(-1, 1, context);\n      this._currentContextIds.splice(\n          0, 1, this.contextIdforContexts(this.contexts));\n    } else {\n      throw new Error('Cannot increase frame iteration, the context is empty');\n    }\n  }\n\n  getWeight(name: string): Tensor[] {\n    return this.weightMap[name];\n  }\n\n  addTensorArray(tensorArray: TensorArray) {\n    this.tensorArrayMap[tensorArray.id] = tensorArray;\n  }\n\n  getTensorArray(id: number): TensorArray {\n    return this.tensorArrayMap[id];\n  }\n\n  addTensorList(tensorList: TensorList) {\n    this.tensorListMap[tensorList.id] = tensorList;\n  }\n\n  getTensorList(id: number): TensorList {\n    return this.tensorListMap[id];\n  }\n\n  dispose(keepIds: Set<number>) {\n    for (const key in this.tensorArrayMap) {\n      this.tensorArrayMap[key].clearAndClose(keepIds);\n    }\n\n    for (const key in this.tensorListMap) {\n      this.tensorListMap[key].clearAndClose(keepIds);\n    }\n  }\n}\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NamedTensorMap} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {parseNodeName} from '../operations/executors/utils';\nimport {Graph, Node} from '../operations/types';\n\nexport interface ExecutionInfo {\n  inputs: NamedTensorMap;\n  outputs: Node[];\n  usedNodes: Set<string>;\n  missingInputs: string[];\n  dynamicNode: Node;\n  syncInputs: string[];\n}\n\n/**\n * Given graph inputs and desired outputs, find the minimal set of nodes\n * to execute in order to compute the outputs. In addition return other useful\n * info such:\n * - Missing inputs needed to compute the output.\n * - Whether the subgraph contains dynamic ops (control flow, dynamic shape).\n * - Alternative inputs in order to avoid async (dynamic op) execution.\n */\nexport function getExecutionSubgraph(\n    inputs: NamedTensorMap, outputs: Node[], weightMap: NamedTensorsMap,\n    initNodes?: Node[]): ExecutionInfo {\n  const usedNodes = new Set<string>();\n  const missingInputs: string[] = [];\n  let dynamicNode: Node = null;\n  let syncInputs: string[] = null;\n\n  // Start with the outputs, going backwards and find all the nodes that are\n  // needed to compute those outputs.\n  const seen = new Set<string>();\n  const inputNodeNames =\n      new Set(Object.keys(inputs).map((name) => parseNodeName(name)[0]));\n\n  initNodes = initNodes || [];\n  const initNodeNames =\n      new Set(initNodes.map((node) => parseNodeName(node.name)[0]));\n\n  const frontier = [...outputs];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    if (isControlFlow(node) || isDynamicShape(node) || isHashTable(node)) {\n      if (dynamicNode == null) {\n        dynamicNode = node;\n        syncInputs = dynamicNode.children.map(child => child.name)\n                         .filter(name => usedNodes.has(name));\n      }\n    }\n    usedNodes.add(node.name);\n\n    // Weights are dead end since we already have their values.\n    if (weightMap[node.name] != null) {\n      continue;\n    }\n    // This node is a dead end since it's one of the user-provided inputs.\n    if (inputNodeNames.has(node.name)) {\n      continue;\n    }\n    // This node is a dead end since it doesn't have any inputs.\n    if (initNodeNames.has(node.name)) {\n      continue;\n    }\n    if (node.inputs.length === 0) {\n      missingInputs.push(node.name);\n      continue;\n    }\n    node.inputs.forEach(input => {\n      // Don't add to the frontier if it is already there.\n      if (seen.has(input.name)) {\n        return;\n      }\n      seen.add(input.name);\n      frontier.push(input);\n    });\n  }\n  return {inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs};\n}\n\n/**\n * Given the execution info, return a list of nodes in topological order that\n * need to be executed to compute the output.\n */\nexport function getNodesInTopologicalOrder(\n    graph: Graph, executionInfo: ExecutionInfo): Node[] {\n  const {usedNodes, inputs} = executionInfo;\n  const inputNodes = Object.keys(inputs)\n                         .map(name => parseNodeName(name)[0])\n                         .map(name => graph.nodes[name]);\n  const initNodes = graph.initNodes || [];\n\n  const isUsed = (node: Node|string) =>\n      usedNodes.has(typeof node === 'string' ? node : node.name);\n\n  function unique(nodes: Node[]): Node[] {\n    return [...new Map(nodes.map((node) => [node.name, node])).values()];\n  }\n  const predefinedNodes = unique([\n                            ...inputNodes,\n                            ...graph.weights,\n                            ...initNodes,\n                          ]).filter(isUsed);\n  const allNodes = unique([\n                     ...predefinedNodes,\n                     ...Object.values(graph.nodes),\n                   ]).filter(isUsed);\n  const nameToNode =\n      new Map<string, Node>(allNodes.map((node) => [node.name, node]));\n\n  const inCounts: Record<string, number> = {};\n  for (const node of allNodes) {\n    inCounts[node.name] = inCounts[node.name] || 0;\n    for (const child of node.children) {\n      // When the child is unused, set in counts to infinity so that it will\n      // never be decreased to 0 and added to the execution list.\n      if (!isUsed(child)) {\n        inCounts[child.name] = Number.POSITIVE_INFINITY;\n      }\n      inCounts[child.name] = (inCounts[child.name] || 0) + 1;\n    }\n  }\n\n  // Build execution order for all used nodes regardless whether they are\n  // predefined or not.\n  const frontier = Object.entries(inCounts)\n                       .filter(([, inCount]) => inCount === 0)\n                       .map(([name]) => name);\n  const orderedNodeNames = [...frontier];\n  while (frontier.length > 0) {\n    const nodeName = frontier.pop();\n    const node = nameToNode.get(nodeName)!;\n    for (const child of node.children.filter(isUsed)) {\n      if (--inCounts[child.name] === 0) {\n        orderedNodeNames.push(child.name);\n        frontier.push(child.name);\n      }\n    }\n  }\n\n  const orderedNodes = orderedNodeNames.map((name) => nameToNode.get(name));\n  const filteredOrderedNodes =\n      filterPredefinedReachableNodes(orderedNodes, predefinedNodes);\n\n  // TODO: Turn validation on/off with tf env flag.\n  validateNodesExecutionOrder(filteredOrderedNodes, predefinedNodes);\n\n  return filteredOrderedNodes;\n}\n\n/**\n * This is a helper function of `getNodesInTopologicalOrder`.\n * Returns ordered nodes reachable by at least one predefined node.\n * This can help us filter out redundant nodes from the returned node list.\n * For example:\n * If we have four nodes with dependencies like this:\n *   a --> b --> c --> d\n * when node `c` is predefined (e.g. given as an input tensor), we can\n * skip node `a` and `b` since their outputs will never be used.\n *\n * @param orderedNodes Graph nodes in execution order.\n * @param predefinedNodes Graph inputs, weights, and init nodes. Nodes in this\n *     list must have distinct names.\n */\nfunction filterPredefinedReachableNodes(\n    orderedNodes: Node[], predefinedNodes: Node[]) {\n  const nameToNode =\n      new Map<string, Node>(orderedNodes.map((node) => [node.name, node]));\n\n  // TODO: Filter out more nodes when >=2 nodes are predefined in a path.\n  const stack = predefinedNodes.map((node) => node.name);\n  const predefinedReachableNodeNames = new Set(stack);\n  // Perform a DFS starting from the set of all predefined nodes\n  // to find the set of all nodes reachable from the predefined nodes.\n  while (stack.length > 0) {\n    const nodeName = stack.pop();\n    const node = nameToNode.get(nodeName)!;\n    for (const child of node.children) {\n      if (!nameToNode.has(child.name) ||\n          predefinedReachableNodeNames.has(child.name)) {\n        continue;\n      }\n      predefinedReachableNodeNames.add(child.name);\n      stack.push(child.name);\n    }\n  }\n\n  // Filter out unreachable nodes and build the ordered node list.\n  const filteredOrderedNodes = orderedNodes.filter(\n      (node) => predefinedReachableNodeNames.has(node.name));\n\n  return filteredOrderedNodes;\n}\n\nclass NodesExecutionOrderError extends Error {\n  constructor(message: string) {\n    super(`NodesExecutionOrderError: ${message}`);\n  }\n}\n\n/**\n * This is a helper function of `getNodesInTopologicalOrder`.\n * Validates property: given nodes `a` and `b`, Order(a) > Order(b) if `a`\n * is a child of `b`. This function throws an error if validation fails.\n *\n * @param orderedNodes Graph nodes in execution order.\n * @param predefinedNodes Graph inputs, weights, and init nodes. Nodes in this\n *     list must have distinct names.\n */\nfunction validateNodesExecutionOrder(\n    orderedNodes: Node[], predefinedNodes: Node[]) {\n  const nodeNameToOrder = new Map<string, number>(\n      orderedNodes.map((node, order) => [node.name, order]));\n  const predefinedNodeNames = new Set(predefinedNodes.map((node) => node.name));\n  const isPredefined = (node: Node|string) =>\n      predefinedNodeNames.has(typeof node === 'string' ? node : node.name);\n  const willBeExecutedNodeNames =\n      new Set(orderedNodes.map((node) => node.name));\n  const willBeExecuted = (node: Node|string) =>\n      willBeExecutedNodeNames.has(typeof node === 'string' ? node : node.name);\n\n  for (const node of orderedNodes) {\n    for (const child of node.children.filter(willBeExecuted)) {\n      if (!nodeNameToOrder.has(child.name)) {\n        throw new NodesExecutionOrderError(\n            `Child ${child.name} of node ${node.name} is unreachable.`);\n      }\n      if (nodeNameToOrder.get(node.name) > nodeNameToOrder.get(child.name)) {\n        throw new NodesExecutionOrderError(`Node ${\n            node.name} is scheduled to run after its child ${child.name}.`);\n      }\n    }\n    if (!isPredefined(node)) {\n      for (const input of node.inputs) {\n        if (!nodeNameToOrder.has(input.name)) {\n          throw new NodesExecutionOrderError(\n              `Input ${input.name} of node ${node.name} is unreachable.`);\n        }\n        if (nodeNameToOrder.get(input.name) > nodeNameToOrder.get(node.name)) {\n          throw new NodesExecutionOrderError(`Node ${\n              node.name} is scheduled to run before its input ${input.name}.`);\n        }\n      }\n    }\n  }\n}\n\n/**\n * Given the execution info, return a map from node name to the disposable\n * node name list after its execution.\n *\n * @returns A map from node name to disposable nodes after its\n *     execution. That is, for a node `x`, `nodeLiveUntilMap[x]` indicates\n *     all nodes which their intermediate tensors should be disposed after `x`\n *     being executed.\n */\nexport function getNodeLiveUntilMap(orderedNodes: Node[]): Map<string, Node[]> {\n  const nodeNameToOrder = new Map<string, number>(\n      orderedNodes.map((node, order) => [node.name, order]));\n\n  const INF_LIFE = Number.MAX_SAFE_INTEGER;\n  // Make control flow nodes (and consequently their direct parents)\n  // live forever since they're tricky to track correctly.\n  const selfLifespans = orderedNodes.map(\n      (node, nodeOrder) => isControlFlow(node) ? INF_LIFE : nodeOrder);\n  const getSelfLifeSpan = (node: Node) => {\n    const selfLife = selfLifespans[nodeNameToOrder.get(node.name)!];\n    if (selfLife == null) {\n      // If nodeToOrder does not contain the node, it is unused or\n      // unreachable in graph.\n      return -1;\n    }\n    return selfLife;\n  };\n\n  // `liveUntil[i]` points to the last node in the `orderedNodes` array that\n  // may depend on tensors from node `i`. It indicates that all the\n  // intermediate tensors from `orderedNodes[i]` should be disposed after\n  // `orderedNodes[liveUntil[i]]` is executed.\n  // A node lives long enough to pass on its tensors to its children.\n  // It lives until at least `max(node's position, children's positions)`.\n  const liveUntilOrders = orderedNodes.map((node, nodeOrder) => {\n    return node.children.map(getSelfLifeSpan)\n        .reduce((a, b) => Math.max(a, b), selfLifespans[nodeOrder]);\n  });\n\n  // liveUntilMap:\n  // - Key: Name of a node `x`\n  // - Values: All nodes whose intermediate tensors should be disposed\n  //           after `x` is executed.\n  const liveUntilMap = new Map<string, Node[]>();\n  for (let nodeOrder = 0; nodeOrder < orderedNodes.length; ++nodeOrder) {\n    const liveUntilOrder = liveUntilOrders[nodeOrder];\n    if (liveUntilOrder === INF_LIFE) {\n      continue;\n    }\n    const node = orderedNodes[nodeOrder];\n    const liveUntilNode = orderedNodes[liveUntilOrder];\n    if (!liveUntilMap.has(liveUntilNode.name)) {\n      liveUntilMap.set(liveUntilNode.name, []);\n    }\n    liveUntilMap.get(liveUntilNode.name)!.push(node);\n  }\n  return liveUntilMap;\n}\n\nconst CONTROL_FLOW_OPS = new Set([\n  'Switch', 'Merge', 'Enter', 'Exit', 'NextIteration', 'StatelessIf',\n  'StatelessWhile', 'if', 'While'\n]);\nconst DYNAMIC_SHAPE_OPS = new Set([\n  'NonMaxSuppressionV2', 'NonMaxSuppressionV3', 'NonMaxSuppressionV5', 'Where'\n]);\nconst HASH_TABLE_OPS = new Set([\n  'HashTable', 'HashTableV2', 'LookupTableImport', 'LookupTableImportV2',\n  'LookupTableFind', 'LookupTableFindV2', 'LookupTableSize', 'LookupTableSizeV2'\n]);\n\nexport function isControlFlow(node: Node) {\n  return CONTROL_FLOW_OPS.has(node.op);\n}\n\nexport function isDynamicShape(node: Node) {\n  return DYNAMIC_SHAPE_OPS.has(node.op);\n}\n\nexport function isHashTable(node: Node) {\n  return HASH_TABLE_OPS.has(node.op);\n}\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, env, keep, NamedTensorMap, Tensor, tidy, util} from '@tensorflow/tfjs-core';\n\nimport {ISignatureDef} from '../data/compiled_api';\nimport {NamedTensorsMap, TensorArrayMap, TensorInfo, TensorListMap} from '../data/types';\nimport {getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContext, parseNodeName} from '../operations/executors/utils';\nimport {executeOp} from '../operations/operation_executor';\nimport {Graph, Node} from '../operations/types';\n\nimport {ExecutionContext, ExecutionContextInfo} from './execution_context';\nimport {getExecutionSubgraph, getNodeLiveUntilMap, getNodesInTopologicalOrder, isControlFlow} from './model_analysis';\nimport {ResourceManager} from './resource_manager';\nimport {FunctionExecutor} from './types';\n\ninterface NodeWithContexts {\n  contexts: ExecutionContextInfo[];\n  node: Node;\n}\n\nexport class GraphExecutor implements FunctionExecutor {\n  private compiledMap = new Map<string, ReturnType<typeof this.compile>>();\n  private parseNodeNameCache = new Map<string, [string, number, string?]>();\n  private _weightMap: NamedTensorsMap = {};\n  private _weightIds: number[];\n  private _signature: ISignatureDef;\n  private _inputs: Node[];\n  private _outputs: Node[];\n  private _initNodes: Node[];  // Internal init nodes to start initialization.\n  private SEPARATOR = ',';\n  private _functions: {[key: string]: Graph} = {};\n  private _functionExecutorMap: {[key: string]: FunctionExecutor} = {};\n  private _resourceManager: ResourceManager;\n  private clonedTensorsMap: NamedTensorsMap;\n  private keepIntermediateTensors = false;\n\n  get weightIds(): number[] {\n    return this.parent ? this.parent.weightIds : this._weightIds;\n  }\n\n  get functionExecutorMap(): {[key: string]: FunctionExecutor} {\n    return this.parent ? this.parent.functionExecutorMap :\n                         this._functionExecutorMap;\n  }\n\n  get weightMap(): NamedTensorsMap {\n    return this.parent ? this.parent.weightMap : this._weightMap;\n  }\n\n  set weightMap(weightMap: NamedTensorsMap) {\n    const weightIds = Object.keys(weightMap).map(\n        key => weightMap[key].map(tensor => tensor.id));\n    this._weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n\n  /**\n   * Set `ResourceManager` shared by executors of a model.\n   * @param resourceManager: `ResourceManager` of the `GraphModel`.\n   */\n  set resourceManager(resourceManager: ResourceManager) {\n    this._resourceManager = resourceManager;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get outputs(): TensorInfo[] {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get inputNodes(): string[] {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n\n  get outputNodes(): string[] {\n    return this._outputs.map((node) => {\n      const name = node.signatureKey || node.name;\n      return node.defaultOutput ? (`${name}:${node.defaultOutput}`) : name;\n    });\n  }\n\n  get functions(): {[key: string]: ISignatureDef} {\n    return Object.keys(this._functions).reduce((map, key) => {\n      map[key] = this._functions[key].signature;\n      return map;\n    }, {} as {[key: string]: ISignatureDef});\n  }\n\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  constructor(private graph: Graph, private parent?: GraphExecutor) {\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._initNodes = graph.initNodes;\n    this._signature = graph.signature;\n    this._functions = graph.functions;\n    // create sub-graph executors\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(name => {\n        this._functionExecutorMap[name] =\n            new GraphExecutor(graph.functions[name], this);\n      });\n    }\n  }\n\n  private getCompilationKey(inputs: Node[], outputs: Node[]): string {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPARATOR) + '--' +\n        sortedOutputs.join(this.SEPARATOR);\n  }\n\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   * @returns {Object} compilation The compile result.\n   * @returns {Node[]} compilation.orderedNodes Nodes in the correct execution\n   *     order.\n   * @returns {Map<string, Node[]>} compilation.nodeLiveUntilMap A map from node\n   *     to disposable nodes after its execution. That is, for a node `x`,\n   *     `nodeLiveUntilMap[x]` indicates all nodes whose intermediate\n   *     tensors should be disposed after `x` is executed.\n   */\n  private compile(inputs: NamedTensorMap, outputs: Node[]):\n      {orderedNodes: Node[], nodeLiveUntilMap: Map<string, Node[]>} {\n    const executionInfo =\n        getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n    const {missingInputs, dynamicNode, syncInputs} = executionInfo;\n    if (dynamicNode != null) {\n      throw new Error(\n          `This execution contains the node '${dynamicNode.name}', which has ` +\n          `the dynamic op '${dynamicNode.op}'. Please use ` +\n          `model.executeAsync() instead. Alternatively, to avoid the ` +\n          `dynamic ops, specify the inputs [${syncInputs}]`);\n    }\n\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(\n          `Cannot compute the outputs [${outNames}] from the provided inputs ` +\n          `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n    }\n\n    const orderedNodes = getNodesInTopologicalOrder(this.graph, executionInfo);\n    const nodeLiveUntilMap = getNodeLiveUntilMap(orderedNodes);\n    return {orderedNodes, nodeLiveUntilMap};\n  }\n\n  private cloneAndKeepTensor(tensor: Tensor) {\n    if (tensor == null) {\n      return null;\n    }\n    const clone = tensor.clone();\n    // Keep the clone because`model.execute()` may be called within\n    // a `tidy()`, but the user may inspect these tensors after the\n    // tidy.\n    keep(clone);\n    return clone;\n  }\n\n  private cloneTensorList(tensors: Tensor[]) {\n    if (!tensors) {\n      return null;\n    }\n    const clonedTensor = tensors.map(tensor => {\n      return this.cloneAndKeepTensor(tensor);\n    });\n    return clonedTensor;\n  }\n\n  private cloneTensorMap(tensorsMap: NamedTensorsMap): NamedTensorsMap {\n    return Object.fromEntries(\n        Object.entries(tensorsMap).map(([name, tensorsList]) => {\n          return [name, this.cloneTensorList(tensorsList)];\n        }));\n  }\n\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model, if\n   * no outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   */\n  execute(inputs: NamedTensorMap, outputs?: string[]): Tensor[] {\n    // Dispose any tensors from a prior run to avoid leaking them.\n    this.disposeIntermediateTensors();\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n    const outputNodeNameSet = new Set(outputNodeNames);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n\n    // Do nothing if the compiled graph cache contains the input.\n    let compilation = this.compiledMap.get(compilationKey);\n    if (compilation == null) {\n      compilation = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, compilation);\n    }\n\n    // Keep tensors if KEEP_INTERMEDIATE_TENSORS is on.\n    try {\n      this.keepIntermediateTensors = env().getBool('KEEP_INTERMEDIATE_TENSORS');\n    } catch (e) {\n      this.keepIntermediateTensors = false;\n      console.warn(e.message);\n    }\n    const tensorArrayMap: TensorArrayMap = {};\n    const tensorListMap: TensorListMap = {};\n\n    return tidy(() => {\n      const context = new ExecutionContext(\n          this.weightMap, tensorArrayMap, tensorListMap,\n          this.functionExecutorMap, this.parseNodeNameCache);\n      const tensorsMap: NamedTensorsMap = {...this.weightMap};\n      if (this.keepIntermediateTensors) {\n        this.clonedTensorsMap = this.cloneTensorMap(this.weightMap);\n      }\n\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name, context);\n        const tensors: Tensor[] = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n        if (this.keepIntermediateTensors) {\n          this.clonedTensorsMap[nodeName] = this.cloneTensorList(tensors);\n        }\n      });\n\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const {orderedNodes, nodeLiveUntilMap} = compilation;\n      for (const node of orderedNodes) {\n        if (tensorsMap[node.name]) {\n          continue;\n        }\n        const tensors =\n            executeOp(node, tensorsMap, context, this._resourceManager) as\n            Tensor[];\n        if (util.isPromise(tensors)) {\n          throw new Error(\n              `The execution of the op '${node.op}' returned a promise. ` +\n              `Please use model.executeAsync() instead.`);\n        }\n        tensorsMap[node.name] = tensors;\n        if (this.keepIntermediateTensors) {\n          this.clonedTensorsMap[node.name] = this.cloneTensorList(tensors);\n        }\n        this.checkTensorForDisposalWithNodeLiveUntilInfo(\n            node, tensorsMap, context, tensorsToKeep, outputNodeNameSet,\n            nodeLiveUntilMap.get(node.name));\n      }\n\n      // dispose the context for the root executor\n      if (this.parent == null) {\n        context.dispose(tensorsToKeep);\n      }\n\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n\n  private getFrozenTensorIds(tensorMap: NamedTensorsMap): Set<number> {\n    const ids = [].concat.apply(\n        [],\n        Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n\n  private checkTensorForDisposal(\n      nodeName: string, node: Node, tensorMap: NamedTensorsMap,\n      context: ExecutionContext, tensorsToKeep: Set<number>,\n      outputNodeNameSet: Set<string>,\n      intermediateTensorConsumerCount: {[key: string]: number}) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (isControlFlow(node) || outputNodeNameSet.has(nodeName)) {\n      return;\n    }\n\n    for (const tensor of tensorMap[nodeName]) {\n      if (tensor == null) {\n        continue;\n      }\n      intermediateTensorConsumerCount[tensor.id] =\n          (intermediateTensorConsumerCount[tensor.id] || 0) +\n          node.children.length;\n    }\n\n    for (const input of node.inputs) {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (isControlFlow(input)) {\n        continue;\n      }\n\n      const tensors =\n          getTensorsForCurrentContext(input.name, tensorMap, context);\n      if (tensors == null) {\n        continue;\n      }\n\n      for (const tensor of tensors) {\n        if (!tensor || tensor.kept || tensorsToKeep.has(tensor.id)) {\n          continue;\n        }\n\n        // Only intermediate nodes' tensors have counts set, not marked as\n        // kept, and not in `tensorsToKeep`.\n        // Input and weight nodes' tensors should exist in `tensorsToKeep`.\n        // Output and control flow nodes' tensors should never have count set.\n        const count = intermediateTensorConsumerCount[tensor.id];\n        if (count === 1) {\n          tensor.dispose();\n          delete intermediateTensorConsumerCount[tensor.id];\n        } else if (count != null) {\n          intermediateTensorConsumerCount[tensor.id]--;\n        }\n      }\n    }\n  }\n\n  private checkTensorForDisposalWithNodeLiveUntilInfo(\n      node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n      tensorsToKeep: Set<number>, outputNodeNameSet: Set<string>,\n      liveUntilNodes?: Node[]) {\n    function isNonDisposableNode(node: Node) {\n      // Skip output nodes and any control flow nodes, since its dependency is\n      // tricky to track correctly.\n      return isControlFlow(node) || outputNodeNameSet.has(node.name);\n    }\n\n    if (isControlFlow(node) || liveUntilNodes == null) {\n      return;\n    }\n\n    for (const nodeToDispose of liveUntilNodes) {\n      if (isNonDisposableNode(nodeToDispose)) {\n        continue;\n      }\n      const tensors = getTensorsForCurrentContext(\n          nodeToDispose.name, tensorMap, context);\n      for (const tensor of tensors) {\n        if (!tensor || tensor.kept || tensorsToKeep.has(tensor.id)) {\n          continue;\n        }\n        tensor.dispose();\n      }\n    }\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  async executeAsync(inputs: NamedTensorMap, outputs?: string[]):\n      Promise<Tensor[]> {\n    return this._executeAsync(inputs, outputs);\n  }\n\n  disposeIntermediateTensors() {\n    if (!this.clonedTensorsMap) {\n      return;\n    }\n    Object.values(this.clonedTensorsMap).forEach(tensorsList => {\n      for (const tensor of tensorsList) {\n        if (tensor && !tensor.isDisposed) {\n          tensor.dispose();\n        }\n      }\n    });\n\n    this.clonedTensorsMap = null;\n  }\n\n  getIntermediateTensors(): NamedTensorsMap {\n    return this.clonedTensorsMap;\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to\n   * the outputs array.\n   * @param isFunctionExecution Optional. Flag for executing a function.\n   * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n   * function execution.\n   * @param tensorArrayMap Optional global TensorList map by id. Used for\n   * function execution.\n   */\n  private async _executeAsync(\n      inputs: NamedTensorMap, outputs?: string[], isFunctionExecution = false,\n      tensorArrayMap: TensorArrayMap = {},\n      tensorListMap: TensorListMap = {}): Promise<Tensor[]> {\n    // Dispose any tensors from a prior run to avoid leaking them.\n    this.disposeIntermediateTensors();\n    if (!isFunctionExecution) {\n      inputs = this.mapInputs(inputs);\n      this.checkInputs(inputs);\n      this.checkInputShapeAndType(inputs);\n      outputs = this.mapOutputs(outputs);\n      this.checkOutputs(outputs);\n    }\n\n    // Keep tensors if KEEP_INTERMEDIATE_TENSORS is on.\n    try {\n      this.keepIntermediateTensors = env().getBool('KEEP_INTERMEDIATE_TENSORS');\n    } catch (e) {\n      this.keepIntermediateTensors = false;\n      console.warn(e.message);\n    }\n\n    const context = new ExecutionContext(\n        this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap,\n        this.parseNodeNameCache);\n\n    if (this.keepIntermediateTensors) {\n      this.clonedTensorsMap = this.cloneTensorMap(this.weightMap);\n    }\n\n    // Graph with control flow op requires runtime evaluation of the execution\n    // order, while without control flow the execution order is pre-determined\n    // in the compile method.\n    const tensorsMap = await this.executeWithControlFlow(\n        inputs, context, outputs, isFunctionExecution);\n    const results = outputs.map(name => getTensor(name, tensorsMap, context));\n\n    // dispose all the intermediate tensors\n    const outputIds = results.map(t => t.id);\n    const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n    const keepIds =\n        new Set<number>([...outputIds, ...inputIds, ...this.weightIds]);\n\n    Object.values(tensorsMap).forEach(tensorsList => {\n      tensorsList.forEach(tensor => {\n        if (tensor && !tensor.isDisposed && !keepIds.has(tensor.id)) {\n          tensor.dispose();\n        }\n      });\n    });\n\n    // dispose the context for the root executor\n    if (this.parent == null) {\n      context.dispose(keepIds);\n    }\n\n    return results;\n  }\n\n  async executeFunctionAsync(\n      inputs: Tensor[], tensorArrayMap: TensorArrayMap,\n      tensorListMap: TensorListMap): Promise<Tensor[]> {\n    const mappedInputs = inputs.reduce((map, tensor, index) => {\n      map[this.inputs[index].name] = tensor;\n      return map;\n    }, {} as NamedTensorMap);\n\n    return this._executeAsync(\n        mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n  }\n\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   * @param outputNames Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to\n   * the outputs array.\n   * @param isFunctionExecution Flag for executing a function.\n   */\n  private async executeWithControlFlow(\n      inputs: NamedTensorMap, context: ExecutionContext, outputNames?: string[],\n      isFunctionExecution?: boolean): Promise<NamedTensorsMap> {\n    const names = Object.keys(inputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n    const outputNodeNameSet = new Set(outputNodeNames);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const {usedNodes, missingInputs, dynamicNode, syncInputs} =\n        getExecutionSubgraph(\n            inputs, outputNodes, this.weightMap, this._initNodes);\n\n    // First nodes to execute include inputNodes, weights, and initNodes.\n    const stack: NodeWithContexts[] = [\n      ...inputNodes, ...this.graph.weights, ...(this._initNodes || [])\n    ].map(node => {\n      return {node, contexts: context.currentContext};\n    });\n    const tensorsMap: NamedTensorsMap = {...this.weightMap};\n    Object.keys(inputs).forEach(name => {\n      const [nodeName, index] = parseNodeName(name);\n      const tensors: Tensor[] = [];\n      tensors[index] = inputs[name];\n      tensorsMap[nodeName] = tensors;\n    });\n    const intermediateTensorConsumerCount: {[key: number]: number} = {};\n    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n    const added: {[key: string]: boolean} = {};\n    while (stack.length > 0) {\n      const promises = this.processStack(\n          inputNodes, stack, context, tensorsMap, added, tensorsToKeep,\n          outputNodeNameSet, intermediateTensorConsumerCount, usedNodes);\n      await Promise.all(promises);\n    }\n    if (dynamicNode == null && !isFunctionExecution) {\n      console.warn(\n          `This model execution did not contain any nodes with control flow ` +\n          `or dynamic output shapes. You can use model.execute() instead.`);\n    }\n    const missingOutputs =\n        outputNodes\n            .filter(\n                node => !isControlFlow(node) &&\n                    !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n    if (missingOutputs.length > 0) {\n      let alternativeMsg = '';\n      if (dynamicNode != null) {\n        alternativeMsg =\n            `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n            `and specify the inputs [${syncInputs}]`;\n      }\n      throw new Error(\n          `Cannot compute the outputs [${missingOutputs}] from the provided ` +\n          `inputs [${names}]. Consider providing the following inputs: ` +\n          `[${missingInputs}]. ${alternativeMsg}`);\n    }\n    return tensorsMap;\n  }\n\n  private processStack(\n      inputNodes: Node[], stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      tensorsToKeep: Set<number>, outputNodeNameSet: Set<string>,\n      intermediateTensorConsumerCount: {[key: number]: number},\n      usedNodes: Set<string>) {\n    const promises: Array<Promise<Tensor[]>> = [];\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = '';\n      // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n      if (item.node.op === 'Enter' &&\n          getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      }\n\n      // only process nodes that are not in the tensorMap yet, this include\n      // inputNodes and internal initNodes.\n      if (tensorMap[item.node.name] == null) {\n        const tensors =\n            executeOp(item.node, tensorMap, context, this._resourceManager);\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n        const currentContext = context.currentContext;\n        if (util.isPromise(tensors)) {\n          promises.push(tensors.then(t => {\n            tensorMap[nodeName] = t;\n            if (this.keepIntermediateTensors) {\n              this.clonedTensorsMap[nodeName] = this.cloneTensorList(t);\n            }\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(\n                nodeName, item.node, tensorMap, context, tensorsToKeep,\n                outputNodeNameSet, intermediateTensorConsumerCount);\n            this.processChildNodes(\n                item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors;\n          if (this.keepIntermediateTensors) {\n            this.clonedTensorsMap[nodeName] = this.cloneTensorList(tensors);\n          }\n          this.checkTensorForDisposal(\n              nodeName, item.node, tensorMap, context, tensorsToKeep,\n              outputNodeNameSet, intermediateTensorConsumerCount);\n          this.processChildNodes(\n              item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(\n            item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n    return promises;\n  }\n\n  private processChildNodes(\n      node: Node, stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      usedNodes: Set<string>) {\n    node.children.forEach((childNode) => {\n      const [nodeName, ] = getNodeNameAndIndex(childNode.name, context);\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      }\n      // Merge op can be pushed if any of its inputs has value.\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n              return !!getTensor(name, tensorMap, context);\n            })) {\n          added[nodeName] = true;\n          stack.push({contexts: context.currentContext, node: childNode});\n        }\n      } else  // Otherwise all inputs must to have value.\n          if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n              })) {\n        added[nodeName] = true;\n        stack.push({contexts: context.currentContext, node: childNode});\n      }\n    });\n  }\n\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  dispose() {\n    Object.keys(this.weightMap)\n        .forEach(\n            key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n\n  private checkInputShapeAndType(inputs: NamedTensorMap) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const [nodeName, ] = parseNodeName(name);\n      const node = this.graph.nodes[nodeName];\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value as number[];\n        const match = shape.length === input.shape.length &&\n            input.shape.every(\n                (dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(\n            match,\n            () => `The shape of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be [${shape}], but was ` +\n                `[${input.shape}]`);\n      }\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(\n            input.dtype === node.attrParams['dtype'].value as string,\n            () => `The dtype of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be ` +\n                `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n      }\n    });\n  }\n\n  private mapInputs(inputs: NamedTensorMap) {\n    const result: NamedTensorMap = {};\n    for (const inputName in inputs) {\n      const tensor = this._signature ?.inputs ?.[inputName];\n      if (tensor != null) {\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n    return result;\n  }\n\n  private checkInputs(inputs: NamedTensorMap) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const [nodeName] = parseNodeName(name);\n      return this.graph.nodes[nodeName] == null;\n    });\n    if (notInGraph.length > 0) {\n      throw new Error(\n          `The dict provided in model.execute(dict) has ` +\n          `keys: [${notInGraph}] that are not part of graph`);\n    }\n  }\n\n  private mapOutputs(outputs: string[]) {\n    return outputs.map(name => {\n      const tensor = this._signature ?.outputs ?.[name];\n      if (tensor != null) {\n        return tensor.name;\n      }\n      return name;\n    }, {});\n  }\n\n  private checkOutputs(outputs: string[]): void {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(`The output '${name}' is not found in the graph`);\n      }\n    });\n  }\n}\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {HashTableMap, NamedTensorMap} from '../data/types';\nimport {HashTable} from './hash_table';\n\n/**\n * Contains global resources of a model.\n */\nexport class ResourceManager {\n  constructor(\n      readonly hashTableNameToHandle: NamedTensorMap = {},\n      readonly hashTableMap: HashTableMap = {}) {}\n\n  /**\n   * Register a `HashTable` in the resource manager.\n   *\n   * The `HashTable` can be retrieved by `resourceManager.getHashTableById`,\n   * where id is the table handle tensor's id.\n   *\n   * @param name Op node name that creates the `HashTable`.\n   * @param hashTable The `HashTable` to be added to resource manager.\n   */\n  addHashTable(name: string, hashTable: HashTable) {\n    this.hashTableNameToHandle[name] = hashTable.handle;\n    this.hashTableMap[hashTable.id] = hashTable;\n  }\n\n  /**\n   * Get the table handle by node name.\n   * @param name Op node name that creates the `HashTable`. This name is also\n   *     used in the inputs list of lookup and import `HashTable` ops.\n   */\n  getHashTableHandleByName(name: string) {\n    return this.hashTableNameToHandle[name];\n  }\n\n  /**\n   * Get the actual `HashTable` by its handle tensor's id.\n   * @param id The id of the handle tensor.\n   */\n  getHashTableById(id: number): HashTable {\n    return this.hashTableMap[id];\n  }\n\n  /**\n   * Dispose `ResourceManager`, including its hashTables and tensors in them.\n   */\n  dispose() {\n    for (const key in this.hashTableMap) {\n      this.hashTableMap[key].clearAndClose();\n      delete this.hashTableMap[key];\n    }\n\n    for (const name in this.hashTableNameToHandle) {\n      this.hashTableNameToHandle[name].dispose();\n      delete this.hashTableNameToHandle[name];\n    }\n  }\n}\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {dispose, InferenceModel, io, ModelPredictConfig, NamedTensorMap, Tensor, util} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\nimport {NamedTensorsMap, TensorInfo} from '../data/types';\nimport {OperationMapper} from '../operations/operation_mapper';\n\nimport {GraphExecutor} from './graph_executor';\nimport {ResourceManager} from './resource_manager';\n// tslint:disable-next-line: no-imports-from-dist\nimport {decodeWeightsStream} from '@tensorflow/tfjs-core/dist/io/io_utils';\n\nexport const TFHUB_SEARCH_PARAM = '?tfjs-format=file';\nexport const DEFAULT_MODEL_NAME = 'model.json';\ntype Url = string|io.IOHandler|io.IOHandlerSync;\ntype UrlIOHandler<T extends Url> = T extends string ? io.IOHandler : T;\n\n/**\n * A `tf.GraphModel` is a directed, acyclic graph built from a\n * SavedModel GraphDef and allows inference execution.\n *\n * A `tf.GraphModel` can only be created by loading from a model converted from\n * a [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model) using\n * the command line converter tool and loaded via `tf.loadGraphModel`.\n *\n * @doc {heading: 'Models', subheading: 'Classes'}\n */\nexport class GraphModel<ModelURL extends Url = string | io.IOHandler> implements\n    InferenceModel {\n  private executor: GraphExecutor;\n  private version = 'n/a';\n  private handler: UrlIOHandler<ModelURL>;\n  private artifacts: io.ModelArtifacts;\n  private initializer: GraphExecutor;\n  private resourceIdToCapturedInput: {[key: number]: Tensor};\n  private resourceManager: ResourceManager;\n  private signature: tensorflow.ISignatureDef;\n  private initializerSignature: tensorflow.ISignatureDef;\n  private structuredOutputKeys: string[];\n  private readonly io: typeof io;\n\n  // Returns the version information for the tensorflow model GraphDef.\n  get modelVersion(): string {\n    return this.version;\n  }\n\n  get inputNodes(): string[] {\n    return this.executor.inputNodes;\n  }\n\n  get outputNodes(): string[] {\n    return this.executor.outputNodes;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this.executor.inputs;\n  }\n\n  get outputs(): TensorInfo[] {\n    return this.executor.outputs;\n  }\n\n  get weights(): NamedTensorsMap {\n    return this.executor.weightMap;\n  }\n\n  get metadata(): {} {\n    return this.artifacts.userDefinedMetadata;\n  }\n\n  get modelSignature(): {} {\n    return this.signature;\n  }\n\n  get modelStructuredOutputKeys(): {} {\n    return this.structuredOutputKeys;\n  }\n\n  /**\n   * @param modelUrl url for the model, or an `io.IOHandler`.\n   * @param weightManifestUrl url for the weight file generated by\n   * scripts/convert.py script.\n   * @param requestOption options for Request, which allows to send credentials\n   * and custom headers.\n   * @param onProgress Optional, progress callback function, fired periodically\n   * before the load is completed.\n   */\n  constructor(\n      private modelUrl: ModelURL, private loadOptions: io.LoadOptions = {},\n      tfio = io) {\n    this.io = tfio;\n    if (loadOptions == null) {\n      this.loadOptions = {};\n    }\n    this.resourceManager = new ResourceManager();\n  }\n\n  private findIOHandler() {\n    type IOHandler = UrlIOHandler<ModelURL>;\n    const path = this.modelUrl;\n    if ((path as io.IOHandler).load != null) {\n      // Path is an IO Handler.\n      this.handler = path as IOHandler;\n    } else if (this.loadOptions.requestInit != null) {\n      this.handler = this.io.browserHTTPRequest(\n                         path as string, this.loadOptions) as IOHandler;\n    } else {\n      const handlers =\n          this.io.getLoadHandlers(path as string, this.loadOptions);\n      if (handlers.length === 0) {\n        // For backward compatibility: if no load handler can be found,\n        // assume it is a relative http path.\n        handlers.push(\n            this.io.browserHTTPRequest(path as string, this.loadOptions));\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) load handlers for ` +\n            `URL '${[path]}'`);\n      }\n      this.handler = handlers[0] as IOHandler;\n    }\n  }\n\n  /**\n   * Loads the model and weight files, construct the in memory weight map and\n   * compile the inference graph.\n   */\n  load(): UrlIOHandler<ModelURL> extends io.IOHandlerSync? boolean:\n                                             Promise<boolean> {\n    type IOHandler = UrlIOHandler<ModelURL>;\n    this.findIOHandler();\n    if (this.handler.load == null) {\n      throw new Error(\n          'Cannot proceed with model loading because the IOHandler provided ' +\n          'does not have the `load` method implemented.');\n    }\n\n    type Result =\n        IOHandler extends io.IOHandlerSync ? boolean : Promise<boolean>;\n\n    const loadResult = this.handler.load() as ReturnType<IOHandler['load']>;\n    if (util.isPromise(loadResult)) {\n      return loadResult.then(artifacts => {\n        if (artifacts.getWeightStream == null) {\n          return this.loadSync(artifacts);\n        }\n        return this.loadStreaming(artifacts);\n      }) as Result;\n    }\n\n    return this.loadSync(loadResult) as Result;\n  }\n\n  /**\n   * Synchronously construct the in memory weight map and\n   * compile the inference graph.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n  loadSync(artifacts: io.ModelArtifacts) {\n    const weightMap = this.io.decodeWeights(\n        artifacts.weightData, artifacts.weightSpecs);\n\n    return this.loadWithWeightMap(artifacts, weightMap);\n  }\n\n  private async loadStreaming(artifacts: io.ModelArtifacts): Promise<boolean> {\n    if (artifacts.getWeightStream == null) {\n      throw new Error('Model artifacts missing streamWeights function');\n    }\n\n    const weightMap = await decodeWeightsStream(\n      artifacts.getWeightStream(), artifacts.weightSpecs);\n\n    return this.loadWithWeightMap(artifacts, weightMap);\n  }\n\n  private loadWithWeightMap(artifacts: io.ModelArtifacts,\n                            weightMap: NamedTensorMap) {\n    this.artifacts = artifacts;\n    const graph = this.artifacts.modelTopology as tensorflow.IGraphDef;\n\n    let signature = this.artifacts.signature;\n    if (this.artifacts.userDefinedMetadata != null) {\n      const metadata = this.artifacts.userDefinedMetadata;\n      if (metadata.signature != null) {\n        signature = metadata.signature;\n      }\n\n      if (metadata.structuredOutputKeys != null) {\n        this.structuredOutputKeys = metadata.structuredOutputKeys as string[];\n      }\n    }\n    this.signature = signature;\n\n    this.version = `${graph.versions.producer}.${graph.versions.minConsumer}`;\n    this.executor = new GraphExecutor(\n        OperationMapper.Instance.transformGraph(graph, this.signature));\n    this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);\n    // Attach a model-level resourceManager to each executor to share resources,\n    // such as `HashTable`.\n    this.executor.resourceManager = this.resourceManager;\n\n    if (artifacts.modelInitializer != null &&\n        (artifacts.modelInitializer as tensorflow.IGraphDef).node != null) {\n      const initializer =\n          OperationMapper.Instance.transformGraph(artifacts.modelInitializer);\n      this.initializer = new GraphExecutor(initializer);\n      this.initializer.weightMap = this.executor.weightMap;\n      // Attach a model-level resourceManager to the initializer, the\n      // hashTables created from when executing the initializer will be stored\n      // in the resourceManager.\n      this.initializer.resourceManager = this.resourceManager;\n      this.initializerSignature = artifacts.initializerSignature;\n    }\n\n    return true;\n  }\n\n  /**\n   * Save the configuration and/or weights of the GraphModel.\n   *\n   * An `IOHandler` is an object that has a `save` method of the proper\n   * signature defined. The `save` method manages the storing or\n   * transmission of serialized data (\"artifacts\") that represent the\n   * model's topology and weights onto or via a specific medium, such as\n   * file downloads, local storage, IndexedDB in the web browser and HTTP\n   * requests to a server. TensorFlow.js provides `IOHandler`\n   * implementations for a number of frequently used saving mediums, such as\n   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\n   * for more details.\n   *\n   * This method also allows you to refer to certain types of `IOHandler`s\n   * as URL-like string shortcuts, such as 'localstorage://' and\n   * 'indexeddb://'.\n   *\n   * Example 1: Save `model`'s topology and weights to browser [local\n   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n   * then load it back.\n   *\n   * ```js\n   * const modelUrl =\n   *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n   * const model = await tf.loadGraphModel(modelUrl);\n   * const zeros = tf.zeros([1, 224, 224, 3]);\n   * model.predict(zeros).print();\n   *\n   * const saveResults = await model.save('localstorage://my-model-1');\n   *\n   * const loadedModel = await tf.loadGraphModel('localstorage://my-model-1');\n   * console.log('Prediction from loaded model:');\n   * model.predict(zeros).print();\n   * ```\n   *\n   * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n   * scheme-based string shortcut for `IOHandler`.\n   * @param config Options for saving the model.\n   * @returns A `Promise` of `SaveResult`, which summarizes the result of\n   * the saving, such as byte sizes of the saved artifacts for the model's\n   *   topology and weight values.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n  async save(handlerOrURL: io.IOHandler|string, config?: io.SaveConfig):\n      Promise<io.SaveResult> {\n    if (typeof handlerOrURL === 'string') {\n      const handlers = this.io.getSaveHandlers(handlerOrURL);\n      if (handlers.length === 0) {\n        throw new Error(\n            `Cannot find any save handlers for URL '${handlerOrURL}'`);\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) save handlers for ` +\n            `URL '${handlerOrURL}'`);\n      }\n      handlerOrURL = handlers[0];\n    }\n    if (handlerOrURL.save == null) {\n      throw new Error(\n          'GraphModel.save() cannot proceed because the IOHandler ' +\n          'provided does not have the `save` attribute defined.');\n    }\n\n    return handlerOrURL.save(this.artifacts);\n  }\n\n  private addStructuredOutputNames(outputTensors: Tensor|Tensor[]) {\n    if (this.structuredOutputKeys) {\n      const outputTensorsArray =\n          outputTensors instanceof Tensor ? [outputTensors] : outputTensors;\n      const outputTensorMap: NamedTensorMap = {};\n\n      outputTensorsArray.forEach(\n          (outputTensor, i) => outputTensorMap[this.structuredOutputKeys[i]] =\n              outputTensor);\n\n      return outputTensorMap;\n    }\n    return outputTensors;\n  }\n\n  /**\n   * Execute the inference for the input tensors.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a `tf.Tensor`. For models with multiple inputs,\n   * inputs params should be in either `tf.Tensor`[] if the input order is\n   * fixed, or otherwise NamedTensorMap format.\n   *\n   * For model with multiple inputs, we recommend you use NamedTensorMap as the\n   * input type, if you use `tf.Tensor`[], the order of the array needs to\n   * follow the\n   * order of inputNodes array. @see {@link GraphModel.inputNodes}\n   *\n   * You can also feed any intermediate nodes using the NamedTensorMap as the\n   * input type. For example, given the graph\n   *    InputNode => Intermediate => OutputNode,\n   * you can execute the subgraph Intermediate => OutputNode by calling\n   *    model.execute('IntermediateNode' : tf.tensor(...));\n   *\n   * This is useful for models that uses tf.dynamic_rnn, where the intermediate\n   * state needs to be fed manually.\n   *\n   * For batch inference execution, the tensors for each input need to be\n   * concatenated together. For example with mobilenet, the required input shape\n   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].\n   * If we are provide a batched data of 100 images, the input tensor should be\n   * in the shape of [100, 244, 244, 3].\n   *\n   * @param config Prediction configuration for specifying the batch size.\n   * Currently the batch size option is ignored for graph model.\n   *\n   * @returns Inference result tensors. If the model is converted and it\n   * originally had structured_outputs in tensorflow, then a NamedTensorMap\n   * will be returned matching the structured_outputs. If no structured_outputs\n   * are present, the output will be single `tf.Tensor` if the model has single\n   * output node, otherwise Tensor[].\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  predict(inputs: Tensor|Tensor[]|NamedTensorMap, config?: ModelPredictConfig):\n      Tensor|Tensor[]|NamedTensorMap {\n    const outputTensors = this.execute(inputs, this.outputNodes);\n    return this.addStructuredOutputNames(outputTensors);\n  }\n\n  /**\n   * Execute the inference for the input tensors in async fashion, use this\n   * method when your model contains control flow ops.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,\n   * inputs params should be in either `tf.Tensor`[] if the input order is\n   * fixed, or otherwise NamedTensorMap format.\n   *\n   * For model with multiple inputs, we recommend you use NamedTensorMap as the\n   * input type, if you use `tf.Tensor`[], the order of the array needs to\n   * follow the\n   * order of inputNodes array. @see {@link GraphModel.inputNodes}\n   *\n   * You can also feed any intermediate nodes using the NamedTensorMap as the\n   * input type. For example, given the graph\n   *    InputNode => Intermediate => OutputNode,\n   * you can execute the subgraph Intermediate => OutputNode by calling\n   *    model.execute('IntermediateNode' : tf.tensor(...));\n   *\n   * This is useful for models that uses tf.dynamic_rnn, where the intermediate\n   * state needs to be fed manually.\n   *\n   * For batch inference execution, the tensors for each input need to be\n   * concatenated together. For example with mobilenet, the required input shape\n   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].\n   * If we are provide a batched data of 100 images, the input tensor should be\n   * in the shape of [100, 244, 244, 3].\n   *\n   * @param config Prediction configuration for specifying the batch size.\n   * Currently the batch size option is ignored for graph model.\n   *\n   * @returns A Promise of inference result tensors. If the model is converted\n   * and it originally had structured_outputs in tensorflow, then a\n   * NamedTensorMap will be returned matching the structured_outputs. If no\n   * structured_outputs are present, the output will be single `tf.Tensor` if\n   * the model has single output node, otherwise Tensor[].\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  async predictAsync(\n      inputs: Tensor|Tensor[]|NamedTensorMap,\n      config?: ModelPredictConfig): Promise<Tensor|Tensor[]|NamedTensorMap> {\n    const outputTensors = await this.executeAsync(inputs, this.outputNodes);\n    return this.addStructuredOutputNames(outputTensors);\n  }\n\n  private normalizeInputs(inputs: Tensor|Tensor[]|\n                          NamedTensorMap): NamedTensorMap {\n    if (!(inputs instanceof Tensor) && !Array.isArray(inputs)) {\n      // The input is already a NamedTensorMap.\n      const signatureInputs = this.signature?.inputs;\n      if (signatureInputs != null) {\n        for (const input in signatureInputs) {\n          const tensor = signatureInputs[input];\n          if (tensor.resourceId != null) {\n            inputs[input] = this.resourceIdToCapturedInput[tensor.resourceId];\n          }\n        }\n      }\n      return inputs;\n    }\n    inputs = Array.isArray(inputs) ? inputs : [inputs];\n\n    const numCapturedInputs =\n        Object.keys(this.resourceIdToCapturedInput).length;\n    if (inputs.length + numCapturedInputs !== this.inputNodes.length) {\n      throw new Error(`Input tensor count mismatch, the graph model has ${\n          this.inputNodes.length -\n          numCapturedInputs} non-resource placeholders, while there are ${\n          inputs.length} input tensors provided.`);\n    }\n\n    let inputIndex = 0;\n    return this.inputNodes.reduce((map, inputName) => {\n      const resourceId = this.signature?.inputs?.[inputName]?.resourceId;\n      if (resourceId != null) {\n        map[inputName] = this.resourceIdToCapturedInput[resourceId];\n      } else {\n        map[inputName] = (inputs as Tensor[])[inputIndex++];\n      }\n      return map;\n    }, {} as NamedTensorMap);\n  }\n\n  private normalizeOutputs(outputs: string|string[]): string[] {\n    outputs = outputs || this.outputNodes;\n    return !Array.isArray(outputs) ? [outputs] : outputs;\n  }\n\n  private executeInitializerGraph() {\n    if (this.initializer == null) {\n      return [];\n    }\n    if (this.initializerSignature == null) {\n      return this.initializer.execute({}, []);\n    } else {\n      return this.initializer.execute(\n          {}, Object.keys(this.initializerSignature.outputs));\n    }\n  }\n\n  private async executeInitializerGraphAsync() {\n    if (this.initializer == null) {\n      return [];\n    }\n    if (this.initializerSignature == null) {\n      return this.initializer.executeAsync({}, []);\n    } else {\n      return this.initializer.executeAsync(\n          {}, Object.keys(this.initializerSignature.outputs));\n    }\n  }\n\n  private setResourceIdToCapturedInput(outputs: Tensor[]) {\n    this.resourceIdToCapturedInput = {};\n\n    if (this.initializerSignature) {\n      const signatureOutputs = this.initializerSignature.outputs;\n      const outputNames = Object.keys(signatureOutputs);\n      for (let i = 0; i < outputNames.length; i++) {\n        const outputName = outputNames[i];\n        const tensorInfo = signatureOutputs[outputName];\n        this.resourceIdToCapturedInput[tensorInfo.resourceId] = outputs[i];\n      }\n    }\n  }\n\n  /**\n   * Executes inference for the model for given input tensors.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the TensorFlow model, if no\n   * outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   *\n   * @returns A single tensor if provided with a single output or no outputs\n   * are provided and there is only one default output, otherwise return a\n   * tensor array. The order of the tensor array is the same as the outputs\n   * if provided, otherwise the order of outputNodes attribute of the model.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  execute(inputs: Tensor|Tensor[]|NamedTensorMap, outputs?: string|string[]):\n      Tensor|Tensor[] {\n    if (this.resourceIdToCapturedInput == null) {\n      this.setResourceIdToCapturedInput(this.executeInitializerGraph());\n    }\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = this.executor.execute(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n\n  /**\n   * Executes inference for the model for given input tensors in async\n   * fashion, use this method when your model contains control flow ops.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the TensorFlow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   *\n   * @returns A Promise of single tensor if provided with a single output or\n   * no outputs are provided and there is only one default output, otherwise\n   * return a tensor map.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  async executeAsync(\n      inputs: Tensor|Tensor[]|NamedTensorMap,\n      outputs?: string|string[]): Promise<Tensor|Tensor[]> {\n    if (this.resourceIdToCapturedInput == null) {\n      this.setResourceIdToCapturedInput(\n          await this.executeInitializerGraphAsync());\n    }\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = await this.executor.executeAsync(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n\n  /**\n   * Get intermediate tensors for model debugging mode (flag\n   * KEEP_INTERMEDIATE_TENSORS is true).\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  getIntermediateTensors(): NamedTensorsMap {\n    return this.executor.getIntermediateTensors();\n  }\n\n  /**\n   * Dispose intermediate tensors for model debugging mode (flag\n   * KEEP_INTERMEDIATE_TENSORS is true).\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  disposeIntermediateTensors() {\n    this.executor.disposeIntermediateTensors();\n  }\n\n  private convertTensorMapToTensorsMap(map: NamedTensorMap): NamedTensorsMap {\n    return Object.keys(map).reduce((newMap: NamedTensorsMap, key) => {\n      newMap[key] = [map[key]];\n      return newMap;\n    }, {});\n  }\n\n  /**\n   * Releases the memory used by the weight tensors and resourceManager.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  dispose() {\n    this.executor.dispose();\n\n    if (this.initializer) {\n      this.initializer.dispose();\n      if (this.resourceIdToCapturedInput) {\n        dispose(this.resourceIdToCapturedInput);\n      }\n    }\n\n    this.resourceManager.dispose();\n  }\n}\n\n/**\n * Load a graph model given a URL to the model definition.\n *\n * Example of loading MobileNetV2 from a URL and making a prediction with a\n * zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n * const model = await tf.loadGraphModel(modelUrl);\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n *\n * Example of loading MobileNetV2 from a TF Hub URL and making a prediction\n * with a zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/2';\n * const model = await tf.loadGraphModel(modelUrl, {fromTFHub: true});\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n * @param modelUrl The url or an `io.IOHandler` that loads the model.\n * @param options Options for the HTTP request, which allows to send\n *     credentials\n *    and custom headers.\n *\n * @doc {heading: 'Models', subheading: 'Loading'}\n */\nexport async function loadGraphModel(\n    modelUrl: string|io.IOHandler, options: io.LoadOptions = {},\n    tfio = io): Promise<GraphModel> {\n  if (modelUrl == null) {\n    throw new Error(\n        'modelUrl in loadGraphModel() cannot be null. Please provide a url ' +\n        'or an IOHandler that loads the model');\n  }\n  if (options == null) {\n    options = {};\n  }\n\n  if (options.fromTFHub && typeof modelUrl === 'string') {\n    modelUrl = getTFHubUrl(modelUrl);\n  }\n  const model = new GraphModel(modelUrl, options, tfio);\n  await model.load();\n  return model;\n}\n\n/**\n * Load a graph model given a synchronous IO handler with a 'load' method.\n *\n * @param modelSource The `io.IOHandlerSync` that loads the model, or the\n *     `io.ModelArtifacts` that encode the model, or a tuple of\n *     `[io.ModelJSON, ArrayBuffer]` of which the first element encodes the\n *      model and the second contains the weights.\n *\n * @doc {heading: 'Models', subheading: 'Loading'}\n */\nexport function loadGraphModelSync(\n    modelSource: io.IOHandlerSync|\n    io.ModelArtifacts|[io.ModelJSON, /* Weights */ ArrayBuffer]):\n    GraphModel<io.IOHandlerSync> {\n  if (modelSource == null) {\n    throw new Error(\n        'modelUrl in loadGraphModelSync() cannot be null. Please provide ' +\n        'model artifacts or an IOHandler that loads the model');\n  }\n\n  let ioHandler: io.IOHandlerSync;\n  if (modelSource instanceof Array) {\n    const [modelJSON, weights] = modelSource;\n    if (!modelJSON) {\n      throw new Error('modelJSON must be the first element of the array');\n    }\n    if (!weights || !(weights instanceof ArrayBuffer)) {\n      throw new Error(\n          'An ArrayBuffer of weights must be the second element of' +\n          ' the array');\n    }\n    if (!('modelTopology' in modelJSON)) {\n      throw new Error('Model JSON is missing \\'modelTopology\\'');\n    }\n    if (!('weightsManifest' in modelJSON)) {\n      throw new Error('Model JSON is missing \\'weightsManifest\\'');\n    }\n\n    const weightSpecs = io.getWeightSpecs(modelJSON.weightsManifest);\n    const modelArtifacts =\n        io.getModelArtifactsForJSONSync(modelJSON, weightSpecs, weights);\n    ioHandler = io.fromMemorySync(modelArtifacts);\n  } else if ('load' in modelSource) {\n    // Then modelSource is already an IOHandlerSync.\n    ioHandler = modelSource;\n  } else if (\n      'modelTopology' in modelSource && 'weightSpecs' in modelSource &&\n      'weightData' in modelSource) {\n    // modelSource is of type ModelArtifacts.\n    ioHandler = io.fromMemorySync(modelSource);\n  } else {\n    throw new Error('Unknown model format');\n  }\n\n  const model = new GraphModel(ioHandler);\n  model.load();\n  return model;\n}\n\nfunction getTFHubUrl(modelUrl: string): string {\n  if (!modelUrl.endsWith('/')) {\n    modelUrl = (modelUrl) + '/';\n  }\n  return `${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`;\n}\n", "/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '4.22.0';\nexport {version};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from '@tensorflow/tfjs-core';\n\nconst ENV = env();\n\n/** Whether to keep intermediate tensors. */\nENV.registerFlag('KEEP_INTERMEDIATE_TENSORS', () => false, debugValue => {\n  if (debugValue) {\n    console.warn(\n        'Keep intermediate tensors is ON. This will print the values of all ' +\n        'intermediate tensors during model inference. Not all models ' +\n        'support this mode. For details, check e2e/benchmarks/ ' +\n        'model_config.js. This significantly impacts performance.');\n  }\n});\n", "/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport './flags';\n\nexport {IAttrValue, INameAttrList, INodeDef, ITensor, ITensorShape} from './data/compiled_api';\nexport {GraphModel, loadGraphModel, loadGraphModelSync} from './executor/graph_model';\nexport {deregisterOp, registerOp} from './operations/custom_op/register';\nexport {GraphNode, OpExecutor} from './operations/types';\nexport {version as version_converter} from './version';\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+CM,SAAU,WAAW,MAAc,QAAkB;AACzD,QAAM,WAAqB;IACzB,UAAU;IACV,UAAU;IACV,QAAQ,CAAA;IACR,OAAO,CAAA;IACP,gBAAgB;;AAGlB,aAAW,IAAI,IAAI;AACrB;AASM,SAAU,gBAAgB,MAAY;AAC1C,SAAO,WAAW,IAAI;AACxB;AASM,SAAU,aAAa,MAAY;AACvC,SAAO,WAAW,IAAI;AACxB;AA9EA,IAmBM;AAnBN;;AAmBA,IAAM,aAAwC,CAAA;;;;;ACpB9C,IA8BY,UAuTK;AArVjB;;AA8BA,KAAA,SAAYA,WAAQ;AAOlB,MAAAA,UAAAA,UAAA,YAAA,IAAA,CAAA,IAAA;AAIA,MAAAA,UAAAA,UAAA,UAAA,IAAA,CAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,WAAA,IAAA,CAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,UAAA,IAAA,CAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,UAAA,IAAA,CAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,UAAA,IAAA,CAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,SAAA,IAAA,CAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,WAAA,IAAA,CAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,cAAA,IAAA,CAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,UAAA,IAAA,CAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,SAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,UAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,WAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,WAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,aAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,WAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,YAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,WAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,eAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,SAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,aAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,YAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,WAAA,IAAA,EAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,WAAA,IAAA,EAAA,IAAA;AAIA,MAAAA,UAAAA,UAAA,cAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,eAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,cAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,cAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,cAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,aAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,eAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,kBAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,cAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,aAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,cAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,eAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,eAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,iBAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,eAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,gBAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,eAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,mBAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,aAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,iBAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,gBAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,eAAA,IAAA,GAAA,IAAA;AACA,MAAAA,UAAAA,UAAA,eAAA,IAAA,GAAA,IAAA;IACF,GA5DY,aAAA,WAAQ,CAAA,EAAA;AAuTpB,KAAA,SAAiBC,WAAQ;AAEvB,UAAY;AAAZ,OAAA,SAAYC,0BAAuB;AAAE,QAAAA,yBAAAA,yBAAA,QAAA,IAAA,CAAA,IAAA;AAAc,QAAAA,yBAAAA,yBAAA,IAAA,IAAA,CAAA,IAAA;AAAU,QAAAA,yBAAAA,yBAAA,IAAA,IAAA,CAAA,IAAA;MAAQ,GAAzD,0BAAAD,UAAA,4BAAAA,UAAA,0BAAuB,CAAA,EAAA;IACrC,GAHiB,aAAA,WAAQ,CAAA,EAAA;;;;;AC7TnB,SAAU,cACZ,WAAmB,MAAY,WAC/B,SAA2B,iBAAiC;AAC9D,QAAM,aAAa,KAAK,YAAY,SAAS;AAC7C,MAAI,cAAc,WAAW,oBAAoB,QAAW;AAC1D,UAAM,QAAQ,WAAW;AACzB,UAAM,MAAM,WAAW,kBAAkB,IACrC,SACC,WAAW,kBAAkB,SAAY,QAAQ,IACR,WAAW;AACzD,UAAM,eAAe,QAAQ,IAAI,KAAK,WAAW,SAAS,QAAQ;AAClE,QAAI,WAAW,SAAS,UAAU;AAChC,aAAO,UACH,KAAK,WAAW,YAAY,GAAG,WAAW,SAAS,eAAe;;AAExE,QAAI,WAAW,SAAS,WAAW;AAMjC,YAAM,SAAS,KAAK,OAAO,MAAM,OAAO,GAAG;AAC3C,YAAM,aAAa,KAAK,WAAW,MAAM,OAAO,GAAG,EAChD,OAAO,CAAC,OAAO,UAAS;AAAA,YAAA;AAAC,iBAAA,KAAA,OAAO,KAAK,OAAC,QAAA,OAAA,SAAA,SAAA,GAAE,QAAO;MAAM,CAAA;AAExD,aAAO,WAAW,IACd,UAAQ,UAAU,MAAM,WAAW,SAAS,eAAe,CAAC;;AAElE,UAAME,UAAS,UACX,KAAK,WAAW,YAAY,GAAG,WAAW,SAAS,eAAe;AACtE,UAAM,OAAOA,QAAO,SAAQ;AAC5B,WAAO,WAAW,SAAS,WACvB,KAAK,CAAC,IACN,aAAK,cAAcA,QAAO,OAAO,IAAI;;AAE3C,QAAM,YAAY,KAAK,WAAW,SAAS;AAC3C,SAAO,aAAa,UAAU;AAChC;AASM,SAAU,UACZ,MAAc,YAA6B,SAC3C,iBAAiC;AACnC,QAAM,CAAC,UAAU,KAAK,IAAI,cAAc,MAAM,OAAO;AAErD,MAAI,mBAAmB,MAAM;AAC3B,UAAMA,UAAS,gBAAgB,yBAAyB,QAAQ;AAChE,QAAIA,WAAU,MAAM;AAClB,aAAOA;;;AAIX,QAAM,YAAY,QAAQ,kBAAkB,KAAK,CAAAC,eAAY;AAC3D,WAAO,CAAC,CAAC,WAAW,yBAAyB,UAAUA,UAAS,CAAC;EACnE,CAAC;AAED,SAAO,cAAc,SACjB,WAAW,yBAAyB,UAAU,SAAS,CAAC,EAAE,KAAK,IAC/D;AACN;AAOM,SAAU,4BACZ,MAAc,YACd,SAAyB;AAC3B,SAAO,WAAW,yBAAyB,MAAM,QAAQ,gBAAgB,CAAC;AAC5E;AAUM,SAAU,oBACZ,WAAmB,SAA0B;AAC/C,QAAM,CAAC,UAAU,OAAO,UAAU,IAAI,cAAc,WAAW,OAAO;AAEtE,SAAO;IACL,yBAAyB,UAAU,WAAW,QAAQ,gBAAgB;IACtE;IAAO;;AAEX;AAEA,SAAS,yBAAyB,MAAc,WAAkB;AAChE,SAAO,CAAC,CAAC,YAAY,GAAG,IAAI,IAAI,SAAS,KAAK;AAChD;AAEM,SAAU,cACZ,MAAc,SAA0B;AAC1C,MAAI,SAAS,IAAI;AACf,WAAO,CAAC,IAAI,GAAG,MAAS;;AAG1B,QAAM,iBAAiB,WAAW,QAAQ,QAAQ,sBAAsB;AACxE,MAAI,gBAAgB;AAClB,UAAM,eAAe,QAAQ,mBAAmB,IAAI,IAAI;AACxD,QAAI,gBAAgB,MAAM;AACxB,aAAO;;;AAGX,QAAM,QAAQ,KAAK,MAAM,GAAG;AAC5B,MAAI;AACJ,MAAI,MAAM,WAAW,GAAG;AACtB,aAAS,CAAC,MAAM,GAAG,MAAS;SACvB;AACL,UAAM,WAAW,MAAM,CAAC;AACxB,UAAM,aAAa,MAAM,WAAW,IAAI,MAAM,CAAC,IAAI;AACnD,UAAM,QAAQ,OAAO,MAAM,MAAM,SAAS,CAAC,CAAC;AAC5C,aAAS,CAAC,UAAU,OAAO,UAAU;;AAEvC,MAAI,gBAAgB;AAClB,YAAQ,mBAAmB,IAAI,MAAM,MAAM;;AAE7C,SAAO;AACT;AASM,SAAU,WACZ,MAAY,WACZ,SAAyB;AAC3B,MAAIC,OAAM,cAAc,OAAO,MAAM,WAAW,OAAO;AACvD,MAAIA,SAAQ,YAAY;AAEtB,IAAAA,OAAM,cAAc,oBAAoB,MAAM,WAAW,OAAO;AAChE,UAAM,kBAEF,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;AACnC,aAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,sBAAgB,CAAC,EAAE,CAAC,IAAKA,KAAiB,IAAI,CAAC;AAC/C,sBAAgB,CAAC,EAAE,CAAC,IAAKA,KAAiB,IAAI,IAAI,CAAC;;AAErD,WAAO;;AAET,SAAOA;AACT;AAWM,SAAU,YAAYF,SAAc;AACxC,SAAOA,QAAO,OAAOA,UAAS,MAAMA,OAAM;AAC5C;AA9LA;;AAiBA;;;;;AChBA;;;;IAmBa;AAnBb;;AAmBO,IAAM,OAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;;;;;;AC1YxB;;cAAAG;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,QAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;;;;;;AC/3BxB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,QAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;;;;;;AC92BhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,QAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB,CAAA;YAChB,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB,CAAA;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB,CAAA;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;cACd;cACA;cACA;cACA;;;UAGJ;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB,CAAA;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB,CAAA;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB,CAAA;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB,CAAA;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;cACd;cACA;cACA;cACA;;;UAGJ;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB,CAAA;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB,CAAA;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;;;;;;AC/rBhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,QAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;QAGpB,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;YAChB,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;YAChB,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;YAChB,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;QAGpB,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;YAChB,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;;;;;;AClahB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,QAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;;;;;;AC1MxB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,QAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;;;;;;AClGhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,QAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;;MAEd;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU,CAAA;;MAEZ;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;;;;;;ACpNhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,QAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU,CAAA;QACV,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU,CAAA;QACV,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;;;;;;AClRhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,SAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;;;;;;AChKhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,SAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;;;;;;AC7ShB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,SAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB,CAAA;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;;;;;;ACxQhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,SAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;;;;;;AC1OhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,SAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;;;;;;AChUhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,SAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;QAGpB,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,OAAO;YACP,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;YAChB,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;YAChB,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;;;;;;ACjbhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,SAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;;;;;;ACjHhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,SAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;;;;;;ACxExB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,SAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACA,SAAS;YACP,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;QAGZ,WAAW;UACT;UACA;;;MAGJ;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;QAGZ,WAAW;UACT;UACA;UACA;;;MAGJ;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;;;;;;AC9IhB;;cAAAC;;AAAA,IAmBaA;AAnBb;;AAmBO,IAAMA,SAAmB;MAC9B;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;UAElB;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;YACR,gBAAgB;;;;MAItB;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,oBAAoB;YACpB,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS;UACP;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;UAEV;YACE,UAAU;YACV,QAAQ;YACR,QAAQ;;;;MAId;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS,CAAA;;MAEX;QACE,YAAY;QACZ,YAAY;QACZ,UAAU;UACR;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;UAEV;YACE,SAAS;YACT,QAAQ;YACR,QAAQ;;;QAGZ,SAAS,CAAA;;;;;;;AC8JP,SAAU,aAAa,MAAY;AACvC,QAAM,SAAS,IAAG,EAAG;AACrB,MAAI,OAAO,OAAO,SAAS,aAAa;AACtC,WAAO,OAAO,KAAK,IAAI;aACd,OAAO,WAAW,aAAa;AACxC,WAAO,IAAI,OAAO,MAAM,QAAQ,EAAE,SAAQ;SACrC;AACL,UAAM,IAAI,MACN,kFACqC;;AAE7C;AAEM,SAAU,iBAAiB,GAAc,UAAiB;AAC9D,QAAM,QACF,MAAM,QAAQ,CAAC,IAAI,OAAO,aAAa,MAAM,MAAM,CAAC,IAAI,aAAa,CAAC;AAC1E,SAAO,WAAW,QAAQ,MAAM,YAAW;AAC7C;AAEM,SAAU,eACZ,OAA+C,MAAc,KAC7D,WAAW,OAAK;AAClB,QAAM,QAAQ,MAAM,IAAI;AACxB,MAAI,SAAS,MAAM;AACjB,WAAO,iBAAiB,MAAM,GAAG,QAAQ;;AAE3C,SAAO;AACT;AAEM,SAAU,aACZ,OAA+C,MAC/C,KAAY;AACd,QAAM,QAAQ,MAAM,IAAI;AACxB,SAAO,QAAQ,MAAM,IAAI;AAC3B;AAEM,SAAU,eACZ,OAA+C,MAC/C,KAAW;AACb,QAAM,QAAQ,MAAM,IAAI,KAAK,CAAA;AAC7B,QAAM,QACF,MAAM,GAAG,KAAK,OAAO,MAAM,GAAG,IAAK,MAAM,GAAG,KAAK,OAAO,MAAM,GAAG,IAAI;AACzE,SAAQ,OAAO,UAAU,WAAY,QAAQ,SAAS,OAAO,EAAE;AACjE;AAEM,SAAU,gBAAgB,OAAiC;AAC/D,MAAI,OAAQ,UAAW,UAAU;AAE/B,YAAmB,SAAS,KAAY;;AAE1C,UAAQ,OAAO;IACb,KAAgB,SAAS;IACzB,KAAgB,SAAS;AACvB,aAAO;IACT,KAAgB,SAAS;IACzB,KAAgB,SAAS;IACzB,KAAgB,SAAS;IACzB,KAAgB,SAAS;AACvB,aAAO;IACT,KAAgB,SAAS;AACvB,aAAO;IACT,KAAgB,SAAS;AACvB,aAAO;IACT,KAAgB,SAAS;AACvB,aAAO;IACT,KAAgB,SAAS;IACzB,KAAgB,SAAS;AACvB,aAAO;IACT;AAGE,aAAO;;AAEb;AAEM,SAAU,aACZ,OAA+C,MAC/C,KAAW;AACb,QAAM,QAAQ,MAAM,IAAI;AACxB,MAAI,SAAS,MAAM,MAAM;AACvB,WAAO,MAAM,KAAK;;AAEpB,SAAO;AACT;AAEM,SAAU,cACZ,OAA+C,MAC/C,KAAa;AACf,QAAM,QAAQ,MAAM,IAAI;AACxB,MAAI,SAAS,MAAM,MAAM;AACvB,WAAO,gBAAgB,MAAM,IAAI;;AAEnC,SAAO;AACT;AAEM,SAAU,mBACZ,OAA+C,MAC/C,KAAe;AACjB,QAAM,QAAQ,MAAM,IAAI;AACxB,MAAI,SAAS,MAAM,QAAQ,MAAM,KAAK,MAAM;AAC1C,WAAO,MAAM,KAAK,KAAK,IAAI,OAAK,gBAAgB,CAAC,CAAC;;AAEpD,SAAO;AACT;AAEM,SAAU,sBAAsB,OAA8B;AAElE,MAAI,MAAM,aAAa;AACrB,WAAO;;AAET,MAAI,MAAM,OAAO,MAAM;AACrB,WAAO,MAAM,IAAI,IACb,SACK,OAAO,IAAI,SAAS,WAAY,IAAI,OAAO,SAAS,IAAI,MAAM,EAAE,CAAC;;AAE5E,SAAO,CAAA;AACT;AAEM,SAAU,oBACZ,OAA+C,MAC/C,KAAc;AAChB,QAAM,QAAQ,MAAM,IAAI;AACxB,MAAI,SAAS,MAAM,OAAO;AACxB,WAAO,sBAAsB,MAAM,KAAK;;AAE1C,SAAO;AACT;AAEM,SAAU,qBACZ,OAA+C,MAC/C,KAAa;AACf,QAAM,QAAQ,MAAM,IAAI;AACxB,MAAI,OAAO;AACT,aAAS,MAAM,KAAK,KAAK,MAAM,KAAK,EAAE,SAAS,MAAM,KAAK,IACX,MAAM,KAAK,MAClD,CAAA,GACH,IAAI,OAAM,OAAO,MAAM,WAAY,IAAI,SAAS,GAAG,EAAE,CAAC;;AAE7D,SAAO;AACT;AAEM,SAAU,oBACZ,OAA+C,MAAc,KAC7D,WAAW,OAAK;AAClB,QAAM,QAAQ,MAAM,IAAI;AACxB,MAAI,SAAS,MAAM,QAAQ,MAAM,KAAK,GAAG;AACvC,WAAO,MAAM,KAAK,EAAE,IAAI,CAAC,MAAK;AAC5B,aAAO,iBAAiB,GAAG,QAAQ;IACrC,CAAC;;AAEH,SAAO;AACT;AAEM,SAAU,yBACZ,OAA+C,MAC/C,KAAe;AACjB,QAAM,QAAQ,MAAM,IAAI;AACxB,MAAI,SAAS,MAAM,QAAQ,MAAM,KAAK,OAAO;AAC3C,WAAO,MAAM,KAAK,MAAM,IAAI,CAAC,MAAK;AAChC,aAAO,sBAAsB,CAAC;IAChC,CAAC;;AAEH,SAAO;AACT;AAEM,SAAU,kBACZ,OAA+C,MAC/C,KAAc;AAChB,QAAM,QAAQ,MAAM,IAAI;AACxB,MAAI,SAAS,MAAM,QAAQ,MAAM,KAAK,GAAG;AACvC,WAAO,MAAM,KAAK;;AAEpB,SAAO;AACT;AAjmBA,IA4Ca;AA5Cb;;AAiBA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGM,IAAO,kBAAP,MAAsB;;MAMnB,WAAW,WAAQ;AACxB,eAAO,KAAK,cAAc,KAAK,YAAY,IAAI,KAAI;MACrD;;MAGA,cAAA;AACE,cAAM,MAAM;UACV;UAAY;UAAW;UAAS;UAAa;UAAU;UACvD;UAAY;UAAO;UAAW;UAAO;UAAS;UAAU;UACxD;UAAW;UAAW;UAAQ;UAAU;UAAQ;;AAElD,cAAM,cAA0B,CAAA,EAAG,OAAO,GAAG,IAAI,IAAI,CAAAC,QAAMA,IAAG,IAAI,CAAC;AAEnE,aAAK,YAAY,YAAY,OACzB,CAAC,KAAK,WAAoB;AACxB,cAAI,OAAO,QAAQ,IAAI;AACvB,iBAAO;QACT,GACA,CAAA,CAAE;MACR;;;MAIA,eACI,OACA,YAAsC,CAAA,GAAE;AAC1C,cAAM,UAAU,MAAM;AACtB,cAAM,eAAuB,CAAA;AAC7B,cAAM,UAAkB,CAAA;AACxB,cAAM,YAAoB,CAAA;AAC1B,cAAM,QAAQ,QAAQ,OAA8B,CAAC,KAAK,SAAQ;AAChE,cAAI,KAAK,IAAI,IAAI,KAAK,QAAQ,IAAI;AAClC,cAAI,KAAK,GAAG,WAAW,aAAa,GAAG;AACrC,yBAAa,KAAK,IAAI,KAAK,IAAI,CAAC;qBACvB,KAAK,OAAO,SAAS;AAC9B,oBAAQ,KAAK,IAAI,KAAK,IAAI,CAAC;qBAClB,KAAK,SAAS,QAAQ,KAAK,MAAM,WAAW,GAAG;AACxD,sBAAU,KAAK,IAAI,KAAK,IAAI,CAAC;;AAE/B,iBAAO;QACT,GAAG,CAAA,CAAE;AAEL,YAAI,SAAiB,CAAA;AACrB,cAAM,UAAkB,CAAA;AACxB,YAAI,qBAA8C,CAAA;AAClD,YAAI,sBAA+C,CAAA;AACnD,YAAI,aAAa,MAAM;AACrB,+BAAqB,KAAK,oBAAoB,UAAU,MAAM;AAC9D,gCAAsB,KAAK,oBAAoB,UAAU,OAAO;;AAElE,cAAM,WAAW,OAAO,KAAK,KAAK;AAClC,iBAAS,QAAQ,SAAM;AACrB,gBAAM,OAAO,MAAM,GAAG;AACtB,eAAK,WAAW,QAAQ,CAAC,MAAM,UAAS;AACtC,kBAAM,CAAC,UAAS,EAAG,UAAU,IAAI,oBAAoB,IAAI;AACzD,kBAAM,YAAY,MAAM,QAAQ;AAChC,gBAAI,UAAU,WAAW,MAAM;AAC7B,oBAAM,cAAc,UAAU,QAAQ,QAAQ,UAAU;AACxD,kBAAI,gBAAgB,IAAI;AACtB,sBAAM,YAAY,GAAG,QAAQ,IAAI,WAAW;AAE5C,qBAAK,WAAW,KAAK,IAAI;;;AAG7B,iBAAK,OAAO,KAAK,SAAS;AAC1B,sBAAU,SAAS,KAAK,IAAI;UAC9B,CAAC;QACH,CAAC;AAID,YAAI,OAAO,KAAK,mBAAmB,EAAE,WAAW,GAAG;AACjD,mBAAS,QAAQ,SAAM;AACrB,kBAAM,OAAO,MAAM,GAAG;AACtB,gBAAI,KAAK,SAAS,WAAW,GAAG;AAC9B,sBAAQ,KAAK,IAAI;;UAErB,CAAC;eACI;AACL,iBAAO,KAAK,mBAAmB,EAAE,QAAQ,UAAO;AAC9C,kBAAM,CAAC,QAAQ,IAAM,oBAAoB,IAAI;AAC7C,kBAAM,OAAO,MAAM,QAAQ;AAC3B,gBAAI,QAAQ,MAAM;AAChB,mBAAK,eAAe,oBAAoB,IAAI;AAC5C,sBAAQ,KAAK,IAAI;;UAErB,CAAC;;AAGH,YAAI,OAAO,KAAK,kBAAkB,EAAE,SAAS,GAAG;AAC9C,iBAAO,KAAK,kBAAkB,EAAE,QAAQ,UAAO;AAC7C,kBAAM,CAAC,QAAQ,IAAM,oBAAoB,IAAI;AAC7C,kBAAM,OAAO,MAAM,QAAQ;AAC3B,gBAAI,MAAM;AACR,mBAAK,eAAe,mBAAmB,IAAI;AAC3C,qBAAO,KAAK,IAAI;;UAEpB,CAAC;eACI;AACL,mBAAS;;AAGX,YAAI,YAAY,CAAA;AAChB,YAAI,MAAM,WAAW,QAAQ,MAAM,QAAQ,YAAY,MAAM;AAC3D,sBAAY,MAAM,QAAQ,SAAS,OAAO,CAACC,YAAW,SAAQ;AAC5D,YAAAA,WAAU,KAAK,UAAU,IAAI,IAAI,KAAK,YAAY,IAAI;AACtD,mBAAOA;UACT,GAAG,CAAA,CAA4B;;AAGjC,cAAM,SACF,EAAC,OAAO,QAAQ,SAAS,SAAS,cAAc,WAAW,UAAS;AAExE,YAAI,UAAU,SAAS,GAAG;AACxB,iBAAO,YAAY;;AAGrB,eAAO;MACT;MAEQ,oBAAoB,SAA8C;AACxE,eAAO,OAAO,KAAK,WAAW,CAAA,CAAE,EAC3B,OAAgC,CAAC,MAAM,SAAQ;AAC9C,eAAK,QAAQ,IAAI,EAAE,IAAI,IAAI;AAC3B,iBAAO;QACT,GAAG,CAAA,CAAE;MACX;MAEQ,QAAQ,MAAyB;AAGvC,cAAM,SACF,gBAAgB,KAAK,EAAE,KAAK,KAAK,UAAU,KAAK,EAAE,KAAK,CAAA;AAC3D,YAAI,KAAK,QAAQ,MAAM;AACrB,eAAK,OAAO,CAAA;;AAGd,cAAM,UAAgB;UACpB,MAAM,KAAK;UACX,IAAI,KAAK;UACT,UAAU,OAAO;UACjB,aACK,KAAK,SACL,CAAA,GAAI,IAAI,WAAS,MAAM,WAAW,GAAG,IAAI,MAAM,MAAM,CAAC,IAAI,KAAK;UACpE,QAAQ,CAAA;UACR,UAAU,CAAA;UACV,aAAa,CAAA;UACb,YAAY,CAAA;UACZ,UAAU,KAAK;UACf,SAAS,OAAO;;AAGlB,YAAI,OAAO,UAAU,MAAM;AACzB,kBAAQ,cACJ,OAAO,OAAO,OACV,CAAC,KAAK,UAAS;AACb,gBAAI,MAAM,IAAI,IAAI;cAChB,MAAM,MAAM;cACZ,iBAAiB,MAAM;cACvB,eAAe,MAAM;;AAEvB,mBAAO;UACT,GACA,CAAA,CAAE;;AAEZ,YAAI,OAAO,SAAS,MAAM;AACxB,kBAAQ,aACJ,OAAO,MAAM,OAAoC,CAAC,KAAK,UAAS;AAC9D,kBAAM,OAAO,MAAM;AACnB,gBAAI,QAAQ;AACZ,oBAAQ,MAAM,MAAM;cAClB,KAAK;AACH,wBAAQ,eACJ,KAAK,MAAM,MAAM,QAAQ,MAAM,YAAsB;AAEzD,oBAAI,UAAU,UAAa,CAAC,CAAC,MAAM,kBAAkB;AACnD,0BAAQ,eACJ,KAAK,MAAM,MAAM,kBACjB,MAAM,YAAsB;;AAElC;cACF,KAAK;AACH,wBAAQ,oBACJ,KAAK,MAAM,MAAM,QAAQ,MAAM,YAAwB;AAE3D,oBAAI,UAAU,UAAa,CAAC,CAAC,MAAM,kBAAkB;AACnD,0BAAQ,oBACJ,KAAK,MAAM,MAAM,kBACjB,MAAM,YAAwB;;AAEpC;cACF,KAAK;AACH,wBAAQ,eACJ,KAAK,MAAM,MAAM,QAChB,MAAM,gBAAgB,CAAY;AACvC,oBAAI,UAAU,UAAa,CAAC,CAAC,MAAM,kBAAkB;AACnD,0BAAQ,eACJ,KAAK,MAAM,MAAM,kBACjB,MAAM,YAAsB;;AAElC;cACF,KAAK;AACH,wBAAQ,qBACJ,KAAK,MAAM,MAAM,QAAQ,MAAM,YAAwB;AAC3D,oBAAI,UAAU,UAAa,CAAC,CAAC,MAAM,kBAAkB;AACnD,0BAAQ,qBACJ,KAAK,MAAM,MAAM,kBACjB,MAAM,YAAwB;;AAEpC;cACF,KAAK;AACH,wBAAQ,aACJ,KAAK,MAAM,MAAM,QAAQ,MAAM,YAAuB;AAC1D,oBAAI,UAAU,UAAa,CAAC,CAAC,MAAM,kBAAkB;AACnD,0BAAQ,aACJ,KAAK,MAAM,MAAM,kBACjB,MAAM,YAAuB;;AAEnC;cACF,KAAK;AACH,wBAAQ,kBACJ,KAAK,MAAM,MAAM,QAAQ,MAAM,YAAyB;AAC5D,oBAAI,UAAU,UAAa,CAAC,CAAC,MAAM,kBAAkB;AACnD,0BAAQ,kBACJ,KAAK,MAAM,MAAM,kBACjB,MAAM,YAAyB;;AAErC;cACF,KAAK;AACH,wBAAQ,oBACJ,KAAK,MAAM,MAAM,QAAQ,MAAM,YAAwB;AAC3D,oBAAI,UAAU,UAAa,CAAC,CAAC,MAAM,kBAAkB;AACnD,0BAAQ,oBACJ,KAAK,MAAM,MAAM,kBACjB,MAAM,YAAwB;;AAEpC;cACF,KAAK;AACH,wBAAQ,yBACJ,KAAK,MAAM,MAAM,QAAQ,MAAM,YAA0B;AAC7D,oBAAI,UAAU,UAAa,CAAC,CAAC,MAAM,kBAAkB;AACnD,0BAAQ,yBACJ,KAAK,MAAM,MAAM,kBACjB,MAAM,YAA0B;;AAEtC;cACF,KAAK;AACH,wBAAQ,cACJ,KAAK,MAAM,MAAM,QAAQ,MAAM,YAAwB;AAC3D,oBAAI,UAAU,UAAa,CAAC,CAAC,MAAM,kBAAkB;AACnD,0BAAQ,cACJ,KAAK,MAAM,MAAM,kBACjB,MAAM,YAAwB;;AAEpC;cACF,KAAK;AACH,wBAAQ,mBACJ,KAAK,MAAM,MAAM,QAAQ,MAAM,YAA0B;AAC7D,oBAAI,UAAU,UAAa,CAAC,CAAC,MAAM,kBAAkB;AACnD,0BAAQ,mBACJ,KAAK,MAAM,MAAM,kBACjB,MAAM,YAA0B;;AAEtC;cACF,KAAK;AACH,wBAAQ,aACJ,KAAK,MAAM,MAAM,QAAQ,MAAM,YAAsB;AACzD,oBAAI,UAAU,UAAa,CAAC,CAAC,MAAM,kBAAkB;AACnD,0BAAQ,aACJ,KAAK,MAAM,MAAM,kBACjB,MAAM,YAAsB;;AAElC;cACF,KAAK;cACL,KAAK;AACH;cACF;AACE,sBAAM,IAAI,MACN,2BAA2B,MAAM,IAAI,YAAY,KAAK,EAAE,EAAE;;AAElE,gBAAI,MAAM,IAAI,IAAI,EAAC,OAAO,KAAI;AAC9B,mBAAO;UACT,GAAG,CAAA,CAAE;;AAEX,eAAO;MACT;;MAGQ,YAAY,aAAoC;AACtD,cAAM,UAAU,YAAY;AAC5B,cAAM,eAAuB,CAAA;AAC7B,cAAM,UAAkB,CAAA;AACxB,YAAI,QAA+B,CAAA;AACnC,YAAI,WAAW,MAAM;AACnB,kBAAQ,QAAQ,OAA8B,CAAC,KAAK,SAAQ;AAC1D,gBAAI,KAAK,IAAI,IAAI,KAAK,QAAQ,IAAI;AAClC,gBAAI,KAAK,OAAO,SAAS;AACvB,sBAAQ,KAAK,IAAI,KAAK,IAAI,CAAC;;AAE7B,mBAAO;UACT,GAAG,CAAA,CAAE;;AAEP,cAAM,SAAiB,CAAA;AACvB,cAAM,UAAkB,CAAA;AAExB,oBAAY,UAAU,SAAS,QAAQ,SAAM;AAC3C,gBAAM,CAAC,QAAQ,IAAM,oBAAoB,IAAI,IAAI;AACjD,gBAAM,OAAa;YACjB,MAAM;YACN,IAAI;YACJ,QAAQ,CAAA;YACR,YAAY,CAAA;YACZ,UAAU;YACV,aAAa,CAAA;YACb,YAAY,EAAC,OAAO,EAAC,OAAO,gBAAgB,IAAI,IAAI,GAAG,MAAM,QAAO,EAAC;YACrE,UAAU,CAAA;;AAEZ,eAAK,eAAe,IAAI;AACxB,iBAAO,KAAK,IAAI;AAChB,gBAAM,QAAQ,IAAI;QACpB,CAAC;AAED,cAAM,WAAW,OAAO,KAAK,KAAK;AAClC,iBAAS,QAAQ,SAAM;AACrB,gBAAM,OAAO,MAAM,GAAG;AACtB,eAAK,WAAW,QAAQ,CAAC,MAAM,UAAS;AACtC,kBAAM,CAAC,UAAS,EAAG,UAAU,IAAI,oBAAoB,IAAI;AACzD,kBAAM,YAAY,MAAM,QAAQ;AAChC,gBAAI,UAAU,WAAW,MAAM;AAC7B,oBAAM,cAAc,UAAU,QAAQ,QAAQ,UAAU;AACxD,kBAAI,gBAAgB,IAAI;AACtB,sBAAM,YAAY,GAAG,QAAQ,IAAI,WAAW;AAE5C,qBAAK,WAAW,KAAK,IAAI;;;AAG7B,iBAAK,OAAO,KAAK,SAAS;AAC1B,sBAAU,SAAS,KAAK,IAAI;UAC9B,CAAC;QACH,CAAC;AAED,cAAM,gBAAgB,YAAY;AAElC,oBAAY,UAAU,UAAU,QAAQ,YAAS;AAC/C,gBAAM,CAAC,UAAU,KAAK,IAAI,oBAAoB,cAAc,OAAO,IAAI,CAAC;AACxE,gBAAM,OAAO,MAAM,QAAQ;AAC3B,cAAI,QAAQ,MAAM;AAChB,iBAAK,gBAAgB;AACrB,oBAAQ,KAAK,IAAI;;QAErB,CAAC;AAED,cAAM,YAAY,KAAK,mBAAmB,WAAW;AACrD,eAAO,EAAC,OAAO,QAAQ,SAAS,SAAS,cAAc,UAAS;MAClE;MAEQ,mBAAmB,aAAoC;AAE7D,eAAO;UACL,YAAY,YAAY,UAAU;UAClC,QAAQ,YAAY,UAAU,SAAS,OACnC,CAAC,KAAK,QAAO;AACX,gBAAI,IAAI,IAAI,IAAI,KAAK,mBAAmB,GAAG;AAC3C,mBAAO;UACT,GACA,CAAA,CAA6C;UACjD,SAAS,YAAY,UAAU,UAAU,OACrC,CAAC,KAAK,QAAO;AACX,gBAAI,IAAI,IAAI,IAAI,KAAK,mBAAmB,KAAK,YAAY,GAAG;AAC5D,mBAAO;UACT,GACA,CAAA,CAA6C;;MAErD;MAEQ,mBACJ,KACA,SAAiC;AACnC,YAAI,OAAO,IAAI;AACf,YAAI,WAAW,MAAM;AACnB,iBAAO,QAAQ,IAAI;;AAErB,eAAO,EAAC,MAAM,OAAO,IAAI,KAAI;MAC/B;;;;;;ACjbF,IA4Ba;AA5Bb;;AAqBA;AACA;AAMM,IAAO,gBAAP,MAAoB;MAGxB,YACY,MAAoB,WACpB,SAAyB;AADzB,aAAA,OAAA;AAAoB,aAAA,YAAA;AACpB,aAAA,UAAA;AAJI,aAAA,SAAmB,CAAA;AACnB,aAAA,QAAoC,CAAA;AAIlD,aAAK,SAAS,KAAK,WAAW,IAAI,UAAQ,KAAK,SAAS,IAAI,CAAC;AAC7D,YAAI,KAAK,YAAY,MAAM;AACzB,eAAK,QAAQ,OAAO,KAAK,KAAK,QAAQ,EACpB,OAAO,CAAC,OAAmC,QAAO;AACjD,kBAAM,GAAG,IAAI,KAAK,QAAQ,GAAG;AAC7B,mBAAO;UACT,GAAG,CAAA,CAAE;;MAE1B;;;;;MAMQ,SAAS,MAAY;AAC3B,eAAO,UAAU,MAAM,KAAK,WAAW,KAAK,OAAO;MACrD;;;;;MAMQ,QAAQ,MAAc,cAAwB;AACpD,cAAM,QAAQ,KAAK,KAAK,SAAS,IAAI;AACrC,YAAI,MAAM,UAAU,MAAM;AACxB,iBAAO,UAAU,MAAM,KAAK,WAAW,KAAK,OAAO;;AAErD,YAAI,MAAM,KAAK,QAAQ,MAAM,KAAK,MAAM;AACtC,iBAAO,eAAe,KAAK,KAAK,UAAU,MAAM,YAAsB;;AAExE,YAAI,MAAM,KAAK,MAAM;AACnB,iBAAO,eAAe,KAAK,KAAK,UAAU,MAAM,YAAsB;;AAExE,YAAI,MAAM,KAAK,MAAM;AACnB,iBAAO,aAAa,KAAK,KAAK,UAAU,MAAM,YAAuB;;AAEvE,YAAI,MAAM,SAAS,MAAM;AACvB,iBAAO,oBACH,KAAK,KAAK,UAAU,MAAM,YAAwB;;AAExD,YAAI,MAAM,QAAQ,MAAM;AACtB,iBAAO,cAAc,KAAK,KAAK,UAAU,MAAM,YAAwB;;AAEzE,YAAI,MAAM,QAAQ,MAAM;AACtB,cAAI,MAAM,KAAK,KAAK,QAAQ,MAAM,KAAK,KAAK,MAAM;AAChD,mBAAO,qBACH,KAAK,KAAK,UAAU,MAAM,YAAwB;;AAExD,cAAI,MAAM,KAAK,KAAK,MAAM;AACxB,mBAAO,oBACH,KAAK,KAAK,UAAU,MAAM,YAAwB;;AAExD,cAAI,MAAM,KAAK,SAAS,MAAM;AAC5B,mBAAO,yBACH,KAAK,KAAK,UAAU,MAAM,YAA0B;;AAE1D,cAAI,MAAM,KAAK,KAAK,MAAM;AACxB,mBAAO,kBACH,KAAK,KAAK,UAAU,MAAM,YAAyB;;AAEzD,cAAI,MAAM,KAAK,QAAQ,MAAM;AAC3B,mBAAO,mBACH,KAAK,KAAK,UAAU,MAAM,YAA0B;;;AAI5D,eAAO;MACT;;;;;;ACrGF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAsBA;;;;;ACtBA,IA2Ba;AA3Bb;;AAmBA;AAMA;AAEO,IAAM,YACT,CAAC,MAAY,WACZ,SAA2B,MAAM,8BAAmB;AACnD,cAAQ,KAAK,IAAI;QACf,KAAK;QACL,KAAK;QACL,KAAK,OAAO;AACV,iBAAO,CAAC,IAAI,IACP,cAAc,KAAK,MAAM,WAAW,OAAO,GAC5C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,QAAQ;AACX,iBAAO,CAAC,IAAI,KACR,cAAc,WAAW,MAAM,WAAW,OAAO,CAAc,CAAC;;QAEtE,KAAK;QACL,KAAK;AACH,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;QACL,KAAK,OAAO;AACV,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,YAAY;AACf,iBAAO,CAAC,IAAI,SACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,YAAY;AACf,iBAAO,CAAC,IAAI,SACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,OAAO;AACV,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,WAAW;AACd,iBAAO,CAAC,IAAI,QACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,WAAW;AACd,iBAAO,CAAC,IAAI,QACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,OAAO;AACV,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,qBAAqB;AACxB,iBAAO,CAAC,IAAI,kBACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AC/FJ,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,aACT,CAAC,MAAY,WAA4B,SACxC,MAAM,8BAAmB;AACxB,cAAQ,KAAK,IAAI;QACf,KAAK;QACL,KAAK;AACH,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,QACR,cAAc,QAAQ,MAAM,WAAW,OAAO,GAC9C,cAAc,QAAQ,MAAM,WAAW,OAAO,CAAW,CAAC;QAChE,KAAK;AACH,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK,SAAS;AACZ,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK;AACH,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK,SAAS;AACZ,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK;AACH,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAE7D,KAAK;AACH,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK,cAAc;AACjB,iBAAO,CAAC,IAAI,WACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK;AACH,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK,SAAS;AACZ,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK;AACH,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,QACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK,QAAQ;AACX,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,QAAQ;AACX,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,YAAY;AACf,iBAAO,CAAC,IAAI,SACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,QAAQ;AACX,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,UAAU;AACb,iBAAO,CAAC,IAAI,OACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,QAAQ;AACX,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK;AACH,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,YACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,gBAAgB,MAAM,WAAW,OAAO,GACtD,cAAc,gBAAgB,MAAM,WAAW,OAAO,CAC5C,CAAC;QACjB,KAAK;AACH,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;QAC7D,KAAK;AACH,iBAAO,CAAC,IAAI,MAAM,UAAU,KAAK,WAAW,CAAC,GAAG,WAAW,OAAO,CAAC,CAAC;QACtE,KAAK;AACH,iBAAO,CAAC,IAAI,UACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,SAAS,MAAM,WAAW,OAAO,CAAW,CAAC;QACjE,KAAK;AACH,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,SAAS,MAAM,WAAW,OAAO,CAAW,CAAC;QACjE,KAAK;AACH,iBAAO,CAAC,IAAI,MAAM,UAAU,KAAK,WAAW,CAAC,GAAG,WAAW,OAAO,CAAC,CAAC;QACtE,KAAK;AACH,iBAAO,CAAC,IAAI,MAAM,UAAU,KAAK,WAAW,CAAC,GAAG,WAAW,OAAO,CAAC,CAAC;QACtE,KAAK;AACH,iBAAO,CAAC,IAAI,SACR,UAAU,KAAK,WAAW,CAAC,GAAG,WAAW,OAAO,CAAC,CAAC;QACxD;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;ACnJE,SAAU,oCACZ,QAAyB,QACzB,qBAAqB,IAAE;AAEzB,MAAI,OAAO,WAAW,YAAY,OAAO,WAAW,UAAU;AAC5D;;AAEF,eAAK,OACD,OAAO,WAAW,OAAO,QACzB,MAAM,qBAAqB,WAAW,MAAM,QAAQ,MAAM,aAAa;AAC3E,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,UAAM,OAAO,OAAO,CAAC;AACrB,UAAM,OAAO,OAAO,CAAC;AACrB,iBAAK,OACD,OAAO,KAAK,OAAO,KAAK,SAAS,MACjC,MACI,qBAAqB,WAAW,MAAM,QAAQ,MAAM,aAAa;;AAE7E;AAEM,SAAU,iBAAiB,cAA6B;AAC5D,MAAI,OAAO,iBAAiB,YAAY,aAAa,KAAK,SAAO,MAAM,CAAC,GAAG;AACzE,WAAO;;AAET,SAAO;AACT;AAQM,SAAU,kBACZ,kBAAmC,SACnC,cAA6B;AAC/B,MAAI,eAAe,kBAAkB,kBAAkB,YAAY;AACnE,QAAM,sBAAsB,CAAC,iBAAiB,YAAY;AAC1D,MAAI,uBAAuB,QAAQ,WAAW,GAAG;AAC/C,UAAM,IAAI,MACN,qFACyC,YAAY,EAAE;;AAE7D,MAAI,qBAAqB;AACvB,YAAQ,QAAQ,CAAAC,YAAS;AACvB,qBAAe,kBAAkBA,QAAO,OAAO,YAAY;IAC7D,CAAC;;AAEH,MAAI,CAAC,iBAAiB,YAAY,GAAG;AACnC,UAAM,IAAI,MAAM,mCAAmC,YAAY,EAAE;;AAEnE,SAAO;AACT;AAEM,SAAU,kBACZ,eAAgC,eAA8B;AAEhE,MAAI,OAAO,kBAAkB,UAAU;AACrC,WAAO;;AAET,MAAI,OAAO,kBAAkB,UAAU;AACrC,WAAO;;AAGT,MAAI,cAAc,WAAW,cAAc,QAAQ;AACjD,UAAM,IAAI,MAAM,oCAAoC,aAAa,QAC7D,aAAa,EAAE;;AAGrB,QAAM,SAAmB,CAAA;AACzB,WAAS,IAAI,GAAG,IAAI,cAAc,QAAQ,EAAE,GAAG;AAC7C,UAAM,OAAO,cAAc,CAAC;AAC5B,UAAM,OAAO,cAAc,CAAC;AAC5B,QAAI,QAAQ,KAAK,QAAQ,KAAK,SAAS,MAAM;AAC3C,YAAM,IAAI,MAAM,oCAAoC,aAAa,QAC7D,aAAa,EAAE;;AAErB,WAAO,CAAC,IAAI,QAAQ,IAAI,OAAO;;AAEjC,SAAO;AACT;AA/GA;;AAsBA;;;;;ACvBA,IA+Ba;AA/Bb;;AAiBA;AAEA;AAYM,IAAO,cAAP,MAAkB;MAItB,YACa,MAAuB,OAAyB,SACjD,cAAiC,wBAChC,aAA+B,gBAAuB;AAFtD,aAAA,OAAA;AAAuB,aAAA,QAAA;AAAyB,aAAA,UAAA;AACjD,aAAA,eAAA;AAAiC,aAAA,yBAAA;AAChC,aAAA,cAAA;AAA+B,aAAA,iBAAA;AANpC,aAAA,UAA6B,CAAA;AAC7B,aAAA,UAAU;AAMhB,aAAK,WAAW,OAAO,CAAC;AACxB,aAAK,KAAK,QAAQ;MACpB;MAEA,IAAI,KAAE;AACJ,eAAO,KAAK,SAAS;MACvB;MAEA,IAAI,SAAM;AACR,eAAO,KAAK;MACd;;;;MAKA,cAAc,SAAqB;AACjC,aAAK,QAAQ,QAAQ,CAAAC,YAAS;AAC5B,cAAI,WAAW,QAAQ,CAAC,QAAQ,IAAIA,QAAO,OAAO,EAAE,GAAG;AACrD,YAAAA,QAAO,OAAO,QAAO;;QAEzB,CAAC;AACD,aAAK,UAAU,CAAA;AACf,aAAK,UAAU;AACf,aAAK,SAAS,QAAO;MACvB;MAEA,OAAI;AACF,eAAO,KAAK,QAAQ;MACtB;;;;;MAMA,KAAK,OAAa;AAChB,YAAI,KAAK,SAAS;AAChB,gBAAM,IAAI,MAAM,eAAe,KAAK,IAAI,2BAA2B;;AAGrE,YAAI,QAAQ,KAAK,SAAS,KAAK,KAAI,GAAI;AACrC,gBAAM,IAAI,MAAM,4BAA4B,KAAK,wBAC7C,KAAK,KAAI,CAAE,EAAE;;AAGnB,cAAM,kBAAkB,KAAK,QAAQ,KAAK;AAC1C,YAAI,gBAAgB,SAAS;AAC3B,gBAAM,IAAI,MACN,eAAe,KAAK,IAAI,0BACpB,KAAK,sGACyC;;AAGxD,YAAI,KAAK,gBAAgB;AACvB,0BAAgB,UAAU;;AAG5B,wBAAgB,OAAO;AACvB,eAAO,gBAAgB;MACzB;;;;MAKA,SAAS,SAAiB;AACxB,eAAO,QAAQ,IAAI,WAAS,KAAK,KAAK,KAAK,CAAC;MAC9C;;;;;;MAOA,MAAM,OAAeA,SAAc;AACjC,YAAI,KAAK,SAAS;AAChB,gBAAM,IAAI,MAAM,eAAe,KAAK,IAAI,2BAA2B;;AAGrE,YAAI,QAAQ,KAAK,CAAC,KAAK,eAAe,SAAS,KAAK,SAAS;AAC3D,gBAAM,IAAI,MAAM,2BACZ,KAAK,8CAA8C,KAAK,OAAO,EAAE;;AAGvE,cAAM,IAAI,KAAK,QAAQ,KAAK,KAAK,CAAA;AAEjC,YAAIA,QAAO,UAAU,KAAK,OAAO;AAC/B,gBAAM,IAAI,MAAM,eACZ,KAAK,IAAI,0CAA0C,KAAK;uCAExDA,QAAO,KAAK,8BAA8B,KAAK,KAAK,GAAG;;AAI7D,YAAI,KAAK,KAAI,MAAO,MACf,KAAK,gBAAgB,QAAQ,KAAK,aAAa,WAAW,IAAI;AACjE,eAAK,eAAeA,QAAO;;AAG7B,4CACI,KAAK,cAAcA,QAAO,OAC1B,eAAe,KAAK,IAAI,0CACpB,KAAK,GAAG;AAEhB,YAAI,EAAE,MAAM;AACV,gBAAM,IAAI,MACN,eAAe,KAAK,IAAI,0CACpB,KAAK,qCAAqC;;AAGpD,YAAI,EAAE,SAAS;AACb,gBAAM,IAAI,MACN,eAAe,KAAK,IAAI,0CACpB,KAAK,wCAAwC;;AAGvD,UAAE,SAASA;AACX,aAAKA,OAAM;AACX,UAAE,UAAU;AAEZ,aAAK,QAAQ,KAAK,IAAI;MACxB;;;;MAKA,UAAU,SAAmB,SAAiB;AAC5C,YAAI,QAAQ,WAAW,QAAQ,QAAQ;AACrC,gBAAM,IAAI,MACN,eAAe,KAAK,IAAI,8DAEpB,QAAQ,MAAM,qCACd,QAAQ,MAAM,GAAG;;AAG3B,gBAAQ,QAAQ,CAAC,GAAG,UAAU,KAAK,MAAM,GAAG,QAAQ,KAAK,CAAC,CAAC;MAC7D;;;;;;;;;MAUA,OAAO,SAAoB,OAAgB;AACzC,YAAI,CAAC,CAAC,SAAS,UAAU,KAAK,OAAO;AACnC,gBAAM,IAAI,MAAM,wBACZ,KAAK,KAAK,+BAA+B,KAAK,EAAE;;AAGtD,YAAI,CAAC,SAAS;AACZ,oBAAU,CAAA;AACV,mBAAS,IAAI,GAAG,IAAI,KAAK,KAAI,GAAI,KAAK;AACpC,oBAAQ,KAAK,CAAC;;eAEX;AACL,oBAAU,QAAQ,MAAM,GAAG,KAAK,KAAI,CAAE;;AAGxC,YAAI,QAAQ,WAAW,GAAG;AACxB,iBAAO,OAAO,CAAA,GAAI,CAAC,CAAC,EAAE,OAAO,KAAK,YAAY,CAAC;;AAKjD,cAAM,UAAU,KAAK,SAAS,OAAO;AAErC,4CACI,KAAK,cAAc,QAAQ,CAAC,EAAE,OAAO,8BAA8B;AAEvE,eAAO,MAAM,SAAS,CAAC;MACzB;;;;MAKA,OAAO,OAAgB;AACrB,YAAI,CAAC,CAAC,SAAS,UAAU,KAAK,OAAO;AACnC,gBAAM,IAAI,MAAM,wBACZ,KAAK,KAAK,+BAA+B,KAAK,EAAE;;AAGtD,YAAI,KAAK,KAAI,MAAO,GAAG;AACrB,iBAAO,OAAO,CAAA,GAAI,CAAC,CAAC,EAAE,OAAO,KAAK,YAAY,CAAC;;AAGjD,cAAM,UAAU,CAAA;AAChB,iBAAS,IAAI,GAAG,IAAI,KAAK,KAAI,GAAI,KAAK;AACpC,kBAAQ,KAAK,CAAC;;AAGhB,cAAM,UAAU,KAAK,SAAS,OAAO;AAErC,4CACI,KAAK,cAAc,QAAQ,CAAC,EAAE,OAC9B,mDACI,KAAK,YAAY,4BAA4B,QAAQ,CAAC,EAAE,KAAK,GAAG;AAExE,eAAO,OAAO,SAAS,CAAC;MAC1B;;;;;;;MAQA,QAAQ,SAAmBA,SAAc;AACvC,YAAIA,QAAO,UAAU,KAAK,OAAO;AAC/B,gBAAM,IAAI,MAAM,wBACZ,KAAK,KAAK,yBAAyBA,QAAO,KAAK,EAAE;;AAGvD,YAAI,QAAQ,WAAWA,QAAO,MAAM,CAAC,GAAG;AACtC,gBAAM,IAAI,MAAM,sDACZ,QAAQ,MAAM,QAAQA,QAAO,MAAM,CAAC,CAAC,EAAE;;AAG7C,cAAM,WAAW,KAAK,IAAI,GAAG,OAAO;AAEpC,YAAI,CAAC,KAAK,eAAe,YAAY,KAAK,SAAS;AACjD,gBAAM,IAAI,MACN,mCAAmC,QAAQ,SAAS,KAAK,OAAO,GAAG;;AAGzE,aAAK,UAAU,SAAS,QAAQA,SAAQ,CAAC,CAAC;MAC5C;;;;;;;MAQA,MAAM,QAAkBA,SAAc;AACpC,YAAIA,QAAO,UAAU,KAAK,OAAO;AAC/B,gBAAM,IAAI,MAAM,wBACZ,KAAK,KAAK,yBAAyBA,QAAO,KAAK,EAAE;;AAEvD,YAAI,cAAc;AAClB,cAAM,oBAAoB,OAAO,IAAI,SAAM;AACzC,yBAAe;AACf,iBAAO;QACT,CAAC;AAED,YAAI,gBAAgBA,QAAO,MAAM,CAAC,GAAG;AACnC,gBAAM,IAAI,MAAM;;UAEZ,WAAW,4BAA4BA,QAAO,KAAK,EAAE;;AAG3D,YAAI,CAAC,KAAK,eAAe,OAAO,WAAW,KAAK,SAAS;AACvD,gBAAM,IAAI,MACN,2DACI,KAAK,OAAO,QAAQ,OAAO,MAAM,gEACwB;;AAGnE,cAAM,gBAAgB,gBAAgB,IAAI,IAAIA,QAAO,OAAO;AAC5D,cAAM,UAAoB,CAAA;AAC1B,aAAK,MAAK;AACR,UAAAA,UAAS,QAAQA,SAAQ,CAAC,GAAG,aAAa,aAAa,CAAC;AACxD,mBAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,EAAE,GAAG;AACtC,kBAAM,iBAAkB,MAAM,IAAK,IAAI,kBAAkB,IAAI,CAAC;AAC9D,kBAAMC,WAAU,CAAC,GAAG,gBAAgB,CAAC;AACrC,kBAAM,QAAQ,CAAC,GAAG,OAAO,CAAC,GAAG,aAAa;AAC1C,oBAAQ,CAAC,IAAI,QAAQ,MAAMD,SAAQC,UAAS,KAAK,GAAG,KAAK,YAAY;;AAEvE,iBAAO;QACT,CAAC;AACD,cAAM,UAAU,CAAA;AAChB,iBAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,kBAAQ,CAAC,IAAI;;AAEf,aAAK,UAAU,SAAS,OAAO;MACjC;;;;;;ACKI,SAAU,WACZC,SAAgB,cAAwB,cAAsB;AAChE,QAAM,QAAQA,QAAO;AACrB,MAAIA,QAAO,MAAM,SAAS,GAAG;AAC3B,UAAM,IAAI,MACN,oDAAoDA,QAAO,KAAK,EAAE;;AAExE,MAAIA,QAAO,UAAU,cAAc;AACjC,UAAM,IAAI,MAAM,mCACZA,QAAO,KAAK,uBAAuB,YAAY,EAAE;;AAEvD,QAAM,qBAAqBA,QAAO,MAAM,MAAM,CAAC;AAC/C,sCACI,oBAAoB,cAAc,6BAA6B;AACnE,QAAM,aAAuB,QAAQA,OAAM;AAC3C,SAAO,IAAI,WAAW,YAAY,cAAc,KAAK;AACvD;AASM,SAAU,QACZ,cAAwB,cAAwB,aAChD,gBAAsB;AACxB,SAAO,IAAI,WAAW,CAAA,GAAI,cAAc,cAAc,cAAc;AACtE;AASM,SAAU,QACZA,SAAgB,SAAmB,cACnC,aAAoB;AACtB,MAAI,QAAQ,WAAWA,QAAO,MAAM,CAAC,GAAG;AACtC,UAAM,IAAI,MAAM,sDACZ,QAAQ,MAAM,QAAQA,QAAO,MAAM,CAAC,CAAC,EAAE;;AAG7C,QAAM,WAAW,KAAK,IAAI,GAAG,OAAO;AAEpC,MAAI,eAAe,QAAQ,gBAAgB,MAAM,YAAY,aAAa;AACxE,UAAM,IAAI,MACN,mCAAmC,QAAQ,SAAS,WAAW,GAAG;;AAGxE,QAAM,OAAO,IAAI,WAAW,CAAA,GAAI,cAAcA,QAAO,OAAO,WAAW;AACvE,QAAM,UAAU,QAAQA,SAAQ,CAAC;AACjC,UAAQ,QAAQ,CAAC,OAAO,UAAS;AAC/B,SAAK,QAAQ,OAAO,QAAQ,KAAK,CAAC;EACpC,CAAC;AACD,SAAO;AACT;AASM,SAAUC,OACZD,SAAgB,QAAkB,cAAsB;AAC1D,MAAI,cAAc;AAClB,QAAM,oBAAoB,OAAO,IAAI,SAAM;AACzC,mBAAe;AACf,WAAO;EACT,CAAC;AAED,MAAI,gBAAgBA,QAAO,MAAM,CAAC,GAAG;AACnC,UAAM,IAAI,MAAM;;UAEV,WAAW,4BAA4BA,QAAO,KAAK,EAAE;;AAG7D,QAAM,uBAAuBA,QAAO,MAAM,MAAM,CAAC;AACjD,QAAM,qBACF,kBAAkB,sBAAsB,YAAY;AACxD,QAAM,gBAAgB,gBAAgB,IAAI,IAAIA,QAAO,OAAO;AAC5D,QAAM,UAAoB,KAAK,MAAK;AAClC,UAAME,WAAU,CAAA;AAChB,IAAAF,UAAS,QAAQA,SAAQ,CAAC,GAAG,aAAa,aAAa,CAAC;AACxD,aAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,EAAE,GAAG;AACtC,YAAM,iBAAkB,MAAM,IAAK,IAAI,kBAAkB,IAAI,CAAC;AAC9D,YAAM,UAAU,CAAC,GAAG,gBAAgB,CAAC;AACrC,YAAM,QAAQ,CAAC,GAAG,OAAO,CAAC,GAAG,aAAa;AAC1C,MAAAE,SAAQ,CAAC,IAAI,QACT,MAAMF,SAAQ,SAAS,KAAK,GAAG,kBAA8B;;AAEnE,IAAAA,QAAO,QAAO;AACd,WAAOE;EACT,CAAC;AAED,QAAM,OAAO,IAAI,WAAW,CAAA,GAAI,cAAcF,QAAO,OAAO,OAAO,MAAM;AAEzE,WAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,SAAK,QAAQ,GAAG,QAAQ,CAAC,CAAC;;AAE5B,SAAO;AACT;AAzaA,IAoCa;AApCb;;AAiBA;AAEA;AAiBM,IAAO,aAAP,MAAO,YAAU;MAIrB,IAAI,KAAE;AACJ,eAAO,KAAK,SAAS;MACvB;;;;;;;;;;MAUA,YACa,SAA4B,cAC5B,cAAwB,iBAAiB,IAAE;AAD3C,aAAA,UAAA;AAA4B,aAAA,eAAA;AAC5B,aAAA,eAAA;AACX,YAAI,WAAW,MAAM;AACnB,kBAAQ,QAAQ,CAAAA,YAAS;AACvB,gBAAI,iBAAiBA,QAAO,OAAO;AACjC,oBAAM,IAAI,MAAM,mCACZ,YAAY,uBAAuBA,QAAO,KAAK,EAAE;;AAEvD,gDACI,cAAcA,QAAO,OAAO,6BAA6B;AAE7D,iBAAKA,OAAM;UACb,CAAC;;AAEH,aAAK,WAAW,OAAO,CAAC;AACxB,aAAK,iBAAiB;AACtB,aAAK,KAAK,QAAQ;MACpB;;;;MAKA,OAAI;AACF,eAAO,IAAI,YACP,CAAC,GAAG,KAAK,OAAO,GAAG,KAAK,cAAc,KAAK,YAAY;MAC7D;;;;MAKA,cAAc,SAAqB;AACjC,aAAK,QAAQ,QAAQ,CAAAA,YAAS;AAC5B,cAAI,WAAW,QAAQ,CAAC,QAAQ,IAAIA,QAAO,EAAE,GAAG;AAC9C,YAAAA,QAAO,QAAO;;QAElB,CAAC;AACD,aAAK,QAAQ,SAAS;AACtB,aAAK,SAAS,QAAO;MACvB;;;;MAIA,OAAI;AACF,eAAO,KAAK,QAAQ;MACtB;;;;;;;;MASA,MAAM,cAAwB,cAAwB,cAAc,IAAE;AAEpE,YAAI,iBAAiB,KAAK,cAAc;AACtC,gBAAM,IAAI,MAAM,mCACZ,YAAY,uBAAuB,KAAK,YAAY,EAAE;;AAE5D,YAAI,gBAAgB,MAAM,KAAK,QAAQ,WAAW,aAAa;AAC7D,gBAAM,IAAI,MAAM,kCACZ,WAAW,iCACX,KAAK,QAAQ,MAAM,YAAY;;AAErC,4CACI,cAAc,KAAK,cAAc,6BAA6B;AAClE,cAAM,qBACF,kBAAkB,KAAK,cAAc,KAAK,SAAS,YAAY;AACnE,eAAO,KAAK,MAAK;AACf,gBAAM,kBACF,KAAK,QAAQ,IAAI,CAAAA,YAAU,QAAQA,SAAQ,kBAAkB,CAAC;AAClE,iBAAO,MAAM,iBAAiB,CAAC;QACjC,CAAC;MACH;;;;;;MAOA,QAAQ,cAAwB,cAAsB;AACpD,YAAI,iBAAiB,KAAK,cAAc;AACtC,gBAAM,IAAI,MAAM,mCACZ,YAAY,uBAAuB,KAAK,YAAY,EAAE;;AAG5D,YAAI,KAAK,KAAI,MAAO,GAAG;AACrB,gBAAM,IAAI,MAAM,mCAAmC;;AAErD,cAAM,qBACF,kBAAkB,KAAK,cAAc,KAAK,SAAS,YAAY;AACnE,cAAMA,UAAS,KAAK,QAAQ,IAAG;AAC/B,QAAAA,QAAO,OAAO;AAEd,4CACIA,QAAO,OAAO,cAAc,6BAA6B;AAE7D,eAAO,QAAQA,SAAQ,kBAAkB;MAC3C;;;;;MAMA,SAASA,SAAc;AACrB,YAAIA,QAAO,UAAU,KAAK,cAAc;AACtC,gBAAM,IAAI,MAAM,mCACZA,QAAO,KAAK,uBAAuB,KAAK,YAAY,EAAE;;AAG5D,4CACIA,QAAO,OAAO,KAAK,cAAc,6BAA6B;AAElE,YAAI,KAAK,mBAAmB,KAAK,KAAI,GAAI;AACvC,gBAAM,IAAI,MAAM,0CAA0C;;AAE5D,aAAKA,OAAM;AACX,aAAK,QAAQ,KAAKA,OAAM;MAC1B;;;;;MAMA,OAAO,MAAY;AACjB,YAAI,OAAO,GAAG;AACZ,gBAAM,IAAI,MACN,0DAA0D,IAAI,EAAE;;AAGtE,YAAI,KAAK,mBAAmB,MAAM,OAAO,KAAK,gBAAgB;AAC5D,gBAAM,IAAI,MAAM,+BACZ,IAAI,6BAA6B,KAAK,cAAc,GAAG;;AAG7D,cAAM,iBAA6B,IAAI,YACnC,CAAA,GAAI,KAAK,cAAc,KAAK,cAAc,KAAK,cAAc;AACjE,uBAAe,QAAQ,SAAS;AAChC,iBAAS,IAAI,GAAG,IAAI,KAAK,IAAI,KAAK,QAAQ,QAAQ,IAAI,GAAG,EAAE,GAAG;AAC5D,yBAAe,QAAQ,CAAC,IAAI,KAAK,QAAQ,CAAC;;AAE5C,eAAO;MACT;;;;;;;MAQA,QAAQ,cAAsB,cAAwB,cAAsB;AAE1E,YAAI,iBAAiB,KAAK,cAAc;AACtC,gBAAM,IAAI,MAAM,mCACZ,YAAY,uBAAuB,KAAK,YAAY,EAAE;;AAE5D,YAAI,eAAe,KAAK,eAAe,KAAK,QAAQ,QAAQ;AAC1D,gBAAM,IAAI,MAAM,4BACZ,YAAY,mBAAmB,KAAK,QAAQ,MAAM,YAAY;;AAGpE,YAAI,KAAK,QAAQ,YAAY,KAAK,MAAM;AACtC,gBAAM,IAAI,MAAM,oBAAoB,YAAY,WAAW;;AAG7D,4CACI,KAAK,QAAQ,YAAY,EAAE,OAAO,cAClC,6BAA6B;AACjC,cAAM,qBACF,kBAAkB,KAAK,cAAc,KAAK,SAAS,YAAY;AACnE,eAAO,QAAQ,KAAK,QAAQ,YAAY,GAAG,kBAAkB;MAC/D;;;;;;MAOA,QAAQ,cAAsBA,SAAc;AAC1C,YAAIA,QAAO,UAAU,KAAK,cAAc;AACtC,gBAAM,IAAI,MAAM,mCACZA,QAAO,KAAK,uBAAuB,KAAK,YAAY,EAAE;;AAG5D,YAAI,eAAe,KACf,KAAK,mBAAmB,MAAM,gBAAgB,KAAK,gBAAgB;AACrE,gBAAM,IAAI,MAAM,yBACZ,YAAY,uBAAuB,KAAK,cAAc,YAAY;;AAGxE,4CACI,KAAK,cAAcA,QAAO,OAAO,6BAA6B;AAClE,aAAKA,OAAM;AAGX,YAAI,KAAK,QAAQ,YAAY,KAAK,MAAM;AACtC,eAAK,QAAQ,YAAY,EAAE,OAAO;;AAGpC,aAAK,QAAQ,YAAY,IAAIA;MAC/B;;;;;;;;MASA,OAAO,SAAmB,cAAwB,cAAsB;AAEtE,YAAI,iBAAiB,KAAK,cAAc;AACtC,gBAAM,IAAI,MAAM,mCACZ,YAAY,uBAAuB,KAAK,YAAY,EAAE;;AAG5D,4CACI,KAAK,cAAc,cAAc,6BAA6B;AAIlE,kBAAU,QAAQ,MAAM,GAAG,KAAK,KAAI,CAAE;AACtC,cAAM,qBACF,kBAAkB,KAAK,cAAc,KAAK,SAAS,YAAY;AACnE,YAAI,QAAQ,WAAW,GAAG;AACxB,iBAAO,OAAO,CAAA,GAAI,CAAC,CAAC,EAAE,OAAO,kBAAkB,CAAC;;AAGlD,eAAO,KAAK,MAAK;AACf,gBAAM,UACF,QAAQ,IAAI,OAAK,QAAQ,KAAK,QAAQ,CAAC,GAAG,kBAAkB,CAAC;AACjE,iBAAO,MAAM,SAAS,CAAC;QACzB,CAAC;MACH;;;;;;MAOA,OAAO,cAAwB,cAAsB;AACnD,YAAI,CAAC,CAAC,gBAAgB,iBAAiB,KAAK,cAAc;AACxD,gBAAM,IAAI,MAAM,uBACZ,KAAK,YAAY,+BAA+B,YAAY,EAAE;;AAGpE,4CACI,KAAK,cAAc,cAAc,6BAA6B;AAClE,cAAM,qBACF,kBAAkB,KAAK,cAAc,KAAK,SAAS,YAAY;AAEnE,YAAI,KAAK,KAAI,MAAO,GAAG;AACrB,iBAAO,OAAO,CAAA,GAAI,CAAC,CAAC,EAAE,OAAO,kBAAkB,CAAC;;AAElD,eAAO,KAAK,MAAK;AACf,gBAAM,UAAU,KAAK,QAAQ,IAAI,OAAK,QAAQ,GAAG,kBAAkB,CAAC;AACpE,iBAAO,OAAO,SAAS,CAAC;QAC1B,CAAC;MACH;;;;;;ACvTF,IA2BaG;AA3Bb;;AAiBA;AAIA;AACA;AAGA;AAEO,IAAMA,aAAqC,OAC9C,MAAY,WACZ,YAAgD;AAClD,cAAQ,KAAK,IAAI;QACf,KAAK;QACL,KAAK,eAAe;AAClB,gBAAM,WACF,cAAc,cAAc,MAAM,WAAW,OAAO;AACxD,gBAAM,WACF,cAAc,cAAc,MAAM,WAAW,OAAO;AACxD,gBAAM,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AAC3D,gBAAM,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AAC3D,gBAAM,YAAY,MAAM,KAAK,KAAI;AACjC,cAAI,UAAU,CAAC,GAAG;AAChB,mBAAO,QAAQ,YAAY,QAAQ,EAAE,qBACjC,MAAM,QAAQ,gBAAgB,QAAQ,aAAa;iBAClD;AACL,mBAAO,QAAQ,YAAY,QAAQ,EAAE,qBACjC,MAAM,QAAQ,gBAAgB,QAAQ,aAAa;;;QAG3D,KAAK;QACL,KAAK,kBAAkB;AACrB,gBAAM,WACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,WACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AAG3D,gBAAM,aACD,MAAM,QAAQ,YAAY,QAAQ,EAAE,qBACjC,MAAM,QAAQ,gBAAgB,QAAQ,aAAa;AAC3D,gBAAM,SAAS,KAAK,IAAI,CAAAC,YAAUA,QAAO,EAAE;AAC3C,cAAI,YAAY,MAAM,WAAW,CAAC,EAAE,KAAI;AAExC,qBAAW,QAAQ,CAAAA,YAAS;AAC1B,gBAAI,CAACA,QAAO,QAAQ,OAAO,QAAQA,QAAO,EAAE,MAAM,IAAI;AACpD,cAAAA,QAAO,QAAO;;UAElB,CAAC;AAED,cAAI,SAAmB;AAEvB,iBAAO,UAAU,CAAC,GAAG;AAEnB,kBAAM,aAAa;AAEnB,qBAAS,MAAM,QAAQ,YAAY,QAAQ,EAAE,qBACzC,QAAQ,QAAQ,gBAAgB,QAAQ,aAAa;AACzD,kBAAM,YAAY,OAAO,IAAI,CAAAA,YAAUA,QAAO,EAAE;AAIhD,uBAAW,QAAQ,CAAAA,YAAS;AAC1B,kBAAI,CAACA,QAAO,QAAQ,OAAO,QAAQA,QAAO,EAAE,MAAM,MAC9C,UAAU,QAAQA,QAAO,EAAE,MAAM,IAAI;AACvC,gBAAAA,QAAO,QAAO;;YAElB,CAAC;AAGD,kBAAMC,cACD,MAAM,QAAQ,YAAY,QAAQ,EAAE,qBACjC,QAAQ,QAAQ,gBAAgB,QAAQ,aAAa;AAC7D,wBAAY,MAAMA,YAAW,CAAC,EAAE,KAAI;AAEpC,YAAAA,YAAW,QAAQ,CAAAD,YAAS;AAC1B,kBAAI,CAACA,QAAO,QAAQ,OAAO,QAAQA,QAAO,EAAE,MAAM,MAC9C,UAAU,QAAQA,QAAO,EAAE,MAAM,IAAI;AACvC,gBAAAA,QAAO,QAAO;;YAElB,CAAC;;AAEH,iBAAO;;QAET,KAAK,YAAY;AACf,gBAAM,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AAC3D,iBAAO,CAAC,YAAY,IAAI,CAAC;;QAE3B,KAAK,UAAU;AACb,gBAAM,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AAC3D,cAAI,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AACzD,cAAI,CAAC,KAAK,MAAM;AACd,mBAAO,YAAY,IAAI;;AAGzB,kBAAQ,MAAM,KAAK,KAAI,GAAI,CAAC,IAAI,CAAC,QAAW,IAAI,IAAI,CAAC,MAAM,MAAS;;QAEtE,KAAK,SAAS;AACZ,gBAAM,YAAY,KAAK,WAAW,KAC9B,UAAQ,UAAU,MAAM,WAAW,OAAO,MAAM,MAAS;AAC7D,cAAI,WAAW;AACb,kBAAM,OAAO,UAAU,WAAW,WAAW,OAAO;AACpD,mBAAO,CAAC,YAAY,IAAI,CAAC;;AAE3B,iBAAO;;QAET,KAAK,SAAS;AACZ,gBAAM,UACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,gBAAM,OAAO,cAAc,UAAU,MAAM,WAAW,OAAO;AAC7D,kBAAQ,WAAW,OAAO;AAC1B,iBAAO,CAAC,YAAY,IAAI,CAAC;;QAE3B,KAAK,QAAQ;AACX,gBAAM,OAAO,cAAc,UAAU,MAAM,WAAW,OAAO;AAC7D,kBAAQ,UAAS;AACjB,iBAAO,CAAC,YAAY,IAAI,CAAC;;QAE3B,KAAK,iBAAiB;AACpB,gBAAM,OAAO,cAAc,UAAU,MAAM,WAAW,OAAO;AAC7D,kBAAQ,cAAa;AACrB,iBAAO,CAAC,YAAY,IAAI,CAAC;;QAE3B,KAAK,iBAAiB;AACpB,gBAAM,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AAC3D,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,cACF,cAAc,eAAe,MAAM,WAAW,OAAO;AACzD,gBAAM,iBACF,cAAc,kBAAkB,MAAM,WAAW,OAAO;AAC5D,gBAAM,yBACF,cAAc,0BAA0B,MAAM,WAAW,OAAO;AAEpE,gBAAM,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AAC3D,gBAAM,cAAc,IAAI,YACpB,MAAM,OAAO,MAAM,cAAc,wBAAwB,aACzD,cAAc;AAClB,kBAAQ,eAAe,WAAW;AAClC,iBAAO,CAAC,YAAY,UAAU,OAAO,CAAG,CAAC;;QAE3C,KAAK,sBAAsB;AACzB,gBAAM,KACF,cAAc,iBAAiB,MAAM,WAAW,OAAO;AAC3D,gBAAM,QAAQ,cAAc,SAAS,MAAM,WAAW,OAAO;AAC7D,gBAAM,cACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,mBAAmB,QAAQ,eAAe,GAAG,EAAE;AACrD,2BAAiB,MAAM,OAAO,WAAW;AACzC,iBAAO,CAAC,iBAAiB,QAAQ;;QAEnC,KAAK,qBAAqB;AACxB,gBAAM,SACF,cAAc,iBAAiB,MAAM,WAAW,OAAO;AAC3D,gBAAM,YACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,kBAAkB,QAAQ,eAAe,OAAO,EAAE;AACxD,iBAAO,CAAC,gBAAgB,KAAK,SAAS,CAAC;;QAEzC,KAAK,uBAAuB;AAC1B,gBAAM,WACF,cAAc,iBAAiB,MAAM,WAAW,OAAO;AAC3D,gBAAM,gBACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,cACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,oBAAoB,QAAQ,eAAe,SAAS,EAAE;AAC5D,iBAAO,CAAC,kBAAkB,OAAO,eAAe,WAAW,CAAC;;QAE9D,KAAK,wBAAwB;AAC3B,gBAAM,YACF,cAAc,iBAAiB,MAAM,WAAW,OAAO;AAC3D,gBAAM,iBACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,gBACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,qBAAqB,QAAQ,eAAe,UAAU,EAAE;AAC9D,6BAAmB,QAAQ,gBAAgB,aAAa;AACxD,iBAAO,CAAC,mBAAmB,QAAQ;;QAErC,KAAK,uBAAuB;AAC1B,gBAAM,WACF,cAAc,iBAAiB,MAAM,WAAW,OAAO;AAC3D,gBAAM,oBAAoB,QAAQ,eAAe,SAAS,EAAE;AAC5D,gBAAM,cACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,iBAAO,CAAC,kBAAkB,OAAO,WAAW,CAAC;;QAE/C,KAAK,sBAAsB;AACzB,gBAAM,UACF,cAAc,iBAAiB,MAAM,WAAW,OAAO;AAC3D,gBAAM,cACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,mBAAmB,QAAQ,eAAe,QAAQ,EAAE;AAC1D,2BAAiB,MAAM,SAAS,WAAW;AAC3C,iBAAO,CAAC,iBAAiB,QAAQ;;QAEnC,KAAK,qBAAqB;AACxB,gBAAM,SACF,cAAc,iBAAiB,MAAM,WAAW,OAAO;AAC3D,gBAAM,kBAAkB,QAAQ,eAAe,OAAO,EAAE;AACxD,iBAAO,CAAC,OAAO,gBAAgB,KAAI,GAAI,OAAO,CAAC;;QAEjD,KAAK,sBAAsB;AACzB,gBAAM,UACF,cAAc,iBAAiB,MAAM,WAAW,OAAO;AAC3D,gBAAM,mBAAmB,QAAQ,eAAe,QAAQ,EAAE;AAC1D,2BAAiB,cAAa;AAC9B,iBAAO,CAAC,iBAAiB,QAAQ;;QAEnC,KAAK,qBAAqB;AACxB,gBAAM,WACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,QAAQ,cAAc,SAAS,MAAM,WAAW,OAAO;AAC7D,gBAAM,cACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,aAAa,QAAQ,cAAc,SAAS,EAAE;AACpD,qBAAW,QAAQ,OAAO,WAAW;AACrC,iBAAO,CAAC,WAAW,QAAQ;;QAE7B,KAAK,qBAAqB;AACxB,gBAAM,WACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,YACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAE1D,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,aAAa,QAAQ,cAAc,SAAS,EAAE;AACpD,iBAAO,CAAC,WAAW,QAAQ,WAAW,cAAc,YAAY,CAAC;;QAEnE,KAAK;QACL,KAAK,qBAAqB;AACxB,gBAAM,iBACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,gBACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,cACF,cAAc,eAAe,MAAM,WAAW,OAAO;AACzD,gBAAM,aACF,QAAQ,eAAe,gBAAgB,cAAc,WAAW;AACpE,kBAAQ,cAAc,UAAU;AAChC,iBAAO,CAAC,WAAW,QAAQ;;QAE7B,KAAK;QACL,KAAK,mBAAmB;AACtB,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,cAAI;AAEJ,cAAI,KAAK,OAAO,qBAAqB;AACnC,+BAAmB;iBACd;AACL,+BAAmB;;AAGrB,gBAAM,cACF,cAAc,kBAAkB,MAAM,WAAW,OAAO;AAC5D,gBAAM,iBAAiB,KAAK,OAAO,sBAAsB,KAAK;AAC9D,gBAAM,aACF,QAAQ,cAAc,cAAc,aAAa,cAAc;AACnE,kBAAQ,cAAc,UAAU;AAChC,iBAAO,CAAC,WAAW,QAAQ;;QAE7B,KAAK,oBAAoB;AACvB,gBAAM,WACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,gBACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,aAAa,QAAQ,cAAc,SAAS,EAAE;AACpD,iBAAO,CAAC,WAAW,OAAO,eAAe,cAAc,YAAY,CAAC;;QAEtE,KAAK,mBAAmB;AACtB,gBAAM,WACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,cACF,cAAc,eAAe,MAAM,WAAW,OAAO;AACzD,gBAAM,aAAa,QAAQ,cAAc,SAAS,EAAE;AACpD,iBAAO,CAAC,WAAW,MAAM,cAAc,cAAc,WAAW,CAAC;;QAEnE,KAAK,wBAAwB;AAC3B,gBAAMA,UACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,aAAa,WAAWA,SAAQ,cAAc,YAAY;AAChE,kBAAQ,cAAc,UAAU;AAChC,iBAAO,CAAC,WAAW,QAAQ;;QAE7B,KAAK;QACL,KAAK,sBAAsB;AACzB,gBAAM,WACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,aAAa,QAAQ,cAAc,SAAS,EAAE;AACpD,gBAAM,cACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,iBAAO,CAAC,WAAW,OAAO,aAAa,YAAY,CAAC;;QAEtD,KAAK,sBAAsB;AACzB,gBAAM,WACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,cACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,aAAa,QAAQ,cAAc,SAAS,EAAE;AACpD,qBAAW,SAAS,WAAW;AAC/B,iBAAO,CAAC,WAAW,QAAQ;;QAE7B,KAAK,qBAAqB;AACxB,gBAAM,WACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,aAAa,QAAQ,cAAc,SAAS,EAAE;AACpD,iBAAO,CAAC,WAAW,QAAQ,cAAc,YAAY,CAAC;;QAExD,KAAK,mBAAmB;AACtB,gBAAM,cACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AAErD,gBAAM,aAAaE,OAAM,aAAa,SAAS,YAAY;AAC3D,kBAAQ,cAAc,UAAU;AAChC,iBAAO,CAAC,WAAW,QAAQ;;QAE7B,KAAK,oBAAoB;AACvB,gBAAM,WACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,aAAa,QAAQ,cAAc,SAAS,EAAE;AACpD,iBAAO,CAAC,OAAO,WAAW,KAAI,GAAI,OAAO,CAAC;;QAE5C,KAAK,oBAAoB;AACvB,gBAAM,WACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AAE3D,gBAAM,gBAAgB,QAAQ,cAAc,SAAS,EAAE;AACvD,gBAAM,iBAAiB,cAAc,OAAO,IAAI;AAChD,kBAAQ,cAAc,cAAc;AACpC,iBAAO,CAAC,eAAe,QAAQ;;QAEjC;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AC1WA,SAAS,4BACL,MAAY,WAA4B,SAAyB;AACnE,QAAM,CAAC,SAAS,cAAc,IACzB,cAAc,YAAY,MAAM,WAAW,OAAO;AAEvD,QAAM,YAAY,YAAY;AAC9B,QAAM,YAAY,CAAC;AACnB,QAAM,UAAU,mBAAmB;AACnC,QAAM,cAAc,YAAY;AAEhC,QAAM,UACD,cAAc,WAAW,MAAM,WAAW,OAAO;AACtD,MAAI,WAAW;AACb,QAAI,WAAW,YAAY,GAAG;AAC5B,YAAM,IAAI,MACN,uGACgD;;AAEtD,QAAI,CAAC,WAAW,aAAa,YAAY,GAAG;AAC1C,YAAM,IAAI,MACN,kFAC2B;;;AAGnC,MAAI,aAAa;AACf,UAAM,IAAI,MACN,sEAAsE;;AAE5E,QAAM,SAAS,cAAc,WAAW,MAAM,WAAW,OAAO;AAChE,QAAMC,OAAM,WAAW,MAAM,WAAW,OAAO;AAC/C,QAAM,aACD,cAAc,cAAc,MAAM,WAAW,OAAO,EAChD,YAAW;AACpB,QAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,MAAI,CAAC,SAAS,QAAQ,IAClB,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,MAAI,WAAW;AACb,eAAW;AACX,cAAU;;AAEZ,QAAM,iBACF,cAAc,kBAAkB,MAAM,WAAW,OAAO;AAE5D,SAAO;IACL;IACA,KAAAA;IACA;IACA;IACA;IACA;IACA;IACA;;AAEJ;AAjFA,IAmFaC;AAnFb;;AAmBA;AAMA;AA0DO,IAAMA,aACT,CAAC,MAAY,WACZ,SAA2B,MAAM,8BAAmB;AACnD,cAAQ,KAAK,IAAI;QACf,KAAK,UAAU;AACb,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAMD,OAAM,cAAc,OAAO,MAAM,WAAW,OAAO;AACzD,gBAAM,aACD,cAAc,cAAc,MAAM,WAAW,OAAO,EAChD,YAAW;AACpB,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,iBAAO,CAAC,IAAI,OACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,QAAQA,MAAyB,YACjC,QAAQ,CAAC;;QAEf,KAAK,UAAU;AACb,gBAAM,SACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAMA,OAAM,WAAW,MAAM,WAAW,OAAO;AAC/C,gBAAM,aACD,cAAc,cAAc,MAAM,WAAW,OAAO,EAChD,YAAW;AACpB,gBAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,iBAAO,CAAC,IAAI,OACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAE3C,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC,GAAGA,MACxB,YAA+B,CAAC,UAAU,CAAC,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;;QAElE,KAAK,gBAAgB;AACnB,gBAAM,EACJ,QACA,KAAAA,MACA,YACA,WACA,SACA,UACA,gBACA,eAAc,IACZ,4BAA4B,MAAM,WAAW,OAAO;AAExD,iBAAO,CAAC,IAAI,MAAM,OAAO;YACvB,GAAG,cAAc,KAAK,MAAM,WAAW,OAAO;YAE9C,QAAQ,cAAc,UAAU,MAAM,WAAW,OAAO;YAExD,SAAS,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC;YAC9B,KAAKA;YACL;YACA,WAAW,CAAC,UAAU,CAAC,GAAG,UAAU,CAAC,CAAC;YACtC,MAAM;YACN,YAAY;YACZ,wBAAwB;YACxB;WACD,CAAC;;QAGJ,KAAK,8BAA8B;AACjC,gBAAM,EACJ,QACA,KAAAA,MACA,YACA,WACA,SACA,UACA,gBACA,eAAc,IACZ,4BAA4B,MAAM,WAAW,OAAO;AAExD,iBAAO,CAAC,IAAI,MAAM,gBAAgB;YAChC,GAAG,cAAc,KAAK,MAAM,WAAW,OAAO;YAE9C,QAAQ,cAAc,UAAU,MAAM,WAAW,OAAO;YAExD,SAAS,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC;YAC9B,KAAKA;YACL;YACA,WAAW,CAAC,UAAU,CAAC,GAAG,UAAU,CAAC,CAAC;YACtC,MAAM;YACN,YAAY;YACZ,wBAAwB;YACxB;WACD,CAAC;;QAEJ,KAAK;QACL,KAAK,mBAAmB;AACtB,gBAAM,QAAQ,cACI,eAAe,MAAM,WACrB,OAAO;AAEzB,gBAAM,SACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAMA,OAAM,WAAW,MAAM,WAAW,OAAO;AAC/C,iBAAO,CAAC,IAAI,gBACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAE3C,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,OAAO,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC,GAAGA,IAAuB,CAAC;;QAE7D,KAAK;QACL,KAAK,mBAAmB;AACtB,gBAAM,SACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAMA,OAAM,WAAW,MAAM,WAAW,OAAO;AAC/C,gBAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,gBAAM,aACD,cAAc,cAAc,MAAM,WAAW,OAAO,EAChD,YAAW;AAEpB,iBAAO,CAAC,IAAI,gBACR,cAAc,SAAS,MAAM,WAAW,OAAO,GAE/C,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC,GAAGA,MACxB,YAA+B,CAAC,UAAU,CAAC,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;;QAElE,KAAK,UAAU;AACb,gBAAM,SACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAMA,OAAM,cAAc,OAAO,MAAM,WAAW,OAAO;AACzD,gBAAM,aACD,cAAc,cAAc,MAAM,WAAW,OAAO,EAChD,YAAW;AACpB,gBAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,iBAAO,CAAC,IAAI,OACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAE3C,cAAc,UAAU,MAAM,WAAW,OAAO,GAEhD,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC,GAAGA,MACnC,YACA,CAAC,UAAU,CAAC,GAAG,UAAU,CAAC,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;;QAEjD,KAAK,WAAW;AACd,gBAAM,SACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAMA,OAAM,cAAc,OAAO,MAAM,WAAW,OAAO;AACzD,gBAAM,aACF,cAAc,cAAc,MAAM,WAAW,OAAO;AAExD,iBAAO,CAAC,IAAI,QACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAE3C,CAAC,WAAW,CAAC,GAAG,WAAW,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC,GACrDA,IAAuB,CAAC;;QAE9B,KAAK,WAAW;AACd,gBAAM,SACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAMA,OAAM,cAAc,OAAO,MAAM,WAAW,OAAO;AACzD,gBAAM,aACF,cAAc,cAAc,MAAM,WAAW,OAAO;AAExD,iBAAO,CAAC,IAAI,QACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAE3C,CAAC,WAAW,CAAC,GAAG,WAAW,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC,GACrDA,IAAuB,CAAC;;QAE9B,KAAK,qBAAqB;AACxB,gBAAM,SACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAMA,OAAM,cAAc,OAAO,MAAM,WAAW,OAAO;AACzD,gBAAM,aACF,cAAc,cAAc,MAAM,WAAW,OAAO;AACxD,gBAAM,sBACF,cAAc,uBAAuB,MAAM,WAAW,OAAO;AAEjE,gBAAM,EAAC,QAAQ,QAAO,IAAI,IAAI,kBAC1B,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,CAAC,WAAW,CAAC,GAAG,WAAW,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC,GACrDA,MAAyB,mBAAmB;AAChD,iBAAO,CAAC,QAAQ,OAAO;;QAEzB,KAAK,aAAa;AAChB,gBAAM,SACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAMA,OAAM,cAAc,OAAO,MAAM,WAAW,OAAO;AACzD,gBAAM,aACF,cAAc,cAAc,MAAM,WAAW,OAAO;AAExD,iBAAO,CAAC,IAAI,UACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,CAAC,WAAW,CAAC,GAAG,WAAW,CAAC,GAAG,WAAW,CAAC,CAAC,GAC5C,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC,GAAGA,IAAuB,CAAC;;QAGjE,KAAK,aAAa;AAChB,gBAAM,SACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAMA,OAAM,cAAc,OAAO,MAAM,WAAW,OAAO;AACzD,gBAAM,aACF,cAAc,cAAc,MAAM,WAAW,OAAO;AAExD,iBAAO,CAAC,IAAI,UACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,CAAC,WAAW,CAAC,GAAG,WAAW,CAAC,GAAG,WAAW,CAAC,CAAC,GAC5C,CAAC,OAAO,CAAC,GAAG,OAAO,CAAC,GAAG,OAAO,CAAC,CAAC,GAAGA,IAAuB,CAAC;;QAGjE,KAAK,cAAc;AACjB,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAMA,OAAM,cAAc,OAAO,MAAM,WAAW,OAAO;AACzD,gBAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AAGvD,gBAAM,eAAe,QAAQ,CAAC;AAC9B,gBAAM,cAAc,QAAQ,CAAC;AAG7B,gBAAM,iBAAiB,UAAU,CAAC;AAClC,gBAAM,gBAAgB,UAAU,CAAC;AAEjC,iBAAO,CAAC,IAAI;YACR,cAAc,KAAK,MAAM,WAAW,OAAO;YAE3C,cAAc,UAAU,MAAM,WAAW,OAAO;YAChD,CAAC,cAAc,WAAW;YAAGA;YAC7B,CAAC,gBAAgB,aAAa;YAAG;;UAAuB,CAAC;;QAG/D;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AC7TJ,IA2BaE;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,aACT,CAAC,MAAY,WAA4B,SACxC,MAAM,8BAAmB;AACxB,cAAQ,KAAK,IAAI;QACf,KAAK,QAAQ;AACX,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,iBAAO,CAAC,IAAI,KAAK,OAAO,OAAO,KAAK,CAAC;;QAEvC,KAAK,YAAY;AACf,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,MAAM,cAAc,OAAO,MAAM,WAAW,OAAO;AACzD,iBAAO,CAAC,IAAI,SAAS,OAAO,MAAM,GAAG,CAAC;;QAExC,KAAK,eAAe;AAClB,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,aACF,cAAc,cAAc,MAAM,WAAW,OAAO;AACxD,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,iBAAO,CAAC,IAAI,YAAY,QAAQ,YAAY,IAAI,CAAC;;QAEnD,KAAK,UAAU;AACb,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,iBAAO,CAAC,IAAI,OAAO,SAAS,OAAO,SAAS,UAAU,KAAK,CAAC;;QAE9D,KAAK,QAAQ;AACX,iBAAO,CAAC,IAAI,KACR,cAAc,SAAS,MAAM,WAAW,OAAO,GAC/C,cAAc,SAAS,MAAM,WAAW,OAAO,CAAa,CAAC;;QAEnE,KAAK,YAAY;AACf,iBAAO,CAAC,IAAI,SACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,wBAAwB;AAC3B,iBAAO,CAAC,IAAI,qBACR,cAAc,SAAS,MAAM,WAAW,OAAO,GAC/C,cAAc,SAAS,MAAM,WAAW,OAAO,GAE/C,cAAc,QAAQ,MAAM,WAAW,OAAO,CAAW,CAAC;;QAEhE,KAAK,iBAAiB;AACpB,iBAAO,CAAC,IAAI;;YAER,cAAc,SAAS,MAAM,WAAW,OAAO;YAC/C,cAAc,UAAU,MAAM,WAAW,OAAO;YAChD,cAAc,UAAU,MAAM,WAAW,OAAO;YAChD,cAAc,SAAS,MAAM,WAAW,OAAO;UAAa,CAAC;;QAEnE,KAAK,oBAAoB;AACvB,iBAAO,CAAC,IAAI,iBACR,cAAc,SAAS,MAAM,WAAW,OAAO,GAC/C,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,cAAc,QAAQ,MAAM,WAAW,OAAO,CAAW,CAAC;;QAEhE,KAAK,SAAS;AACZ,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAMC,QACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,iBAAO,CAAC,IAAI,MACR,OAAO,MAAMA,OACb,cAAc,SAAS,MAAM,WAAW,OAAO,CACpC,CAAC;;QAElB,KAAK,mBAAmB;AACtB,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAMC,QACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,iBAAO,CAAC,IAAI,gBACR,OAAOA,OAAM,QACb,cAAc,SAAS,MAAM,WAAW,OAAO,GAE/C,IAAI,CAAC;;QAEX,KAAK,SAAS;AACZ,iBAAO,CAAC,IAAI,MACR,cAAc,SAAS,MAAM,WAAW,OAAO,GAC/C,cAAc,SAAS,MAAM,WAAW,OAAO,CAAa,CAAC;;QAEnE,KAAK,aAAa;AAChB,iBAAO,CAAC,IAAI,UACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AChHJ,SAAS,UACL,MAAY,WAA4B,SAAyB;AACnE,QAAM,QAAQ,cAAc,SAAS,MAAM,WAAW,OAAO;AAC7D,QAAM,SAAS,cAAc,UAAU,MAAM,WAAW,OAAO;AAC/D,QAAM,gBACF,cAAc,iBAAiB,MAAM,WAAW,OAAO;AAC3D,QAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,QAAM,iBACF,cAAc,kBAAkB,MAAM,WAAW,OAAO;AAC5D,QAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAE1D,SAAO;IACL;IACA;IACA;IACA;IACA;IACA;;AAEJ;AAjDA,IAmDaC;AAnDb;;AAmBA;AAOA;AAyBO,IAAMA,aAAqC,OAC9C,MAAY,WACZ,SAA2B,iBAC3B,MAAM,8BAA4B;AACpC,cAAQ,KAAK,IAAI;QACf,KAAK,uBAAuB;AAC1B,gBAAM,EACJ,OACA,QACA,eACA,cACA,gBACA,aAAY,IACV,UAAU,MAAM,WAAW,OAAO;AAEtC,gBAAM,SAAS,MAAM,IAAI,MAAM,gCAC3B,OAAmB,QAAoB,eAAe,cACtD,gBAAgB,YAAY;AAEhC,iBAAO,CAAC,OAAO,iBAAiB,OAAO,cAAc;;QAEvD,KAAK,uBAAuB;AAC1B,gBAAM,EAAC,OAAO,QAAQ,eAAe,cAAc,eAAc,IAC7D,UAAU,MAAM,WAAW,OAAO;AAEtC,gBAAM,qBACF,cAAc,sBAAsB,MAAM,WAAW,OAAO;AAGhE,gBAAM,SAAS,MAAM,IAAI,MAAM,6BAC3B,OAAmB,QAAoB,eAAe,cACtD,gBAAgB,kBAAkB;AAEtC,iBAAO,CAAC,OAAO,iBAAiB,OAAO,YAAY;;QAErD,KAAK;QACL,KAAK,uBAAuB;AAC1B,gBAAM,EAAC,OAAO,QAAQ,eAAe,cAAc,eAAc,IAC7D,UAAU,MAAM,WAAW,OAAO;AAEtC,iBAAO,CAAC,MAAM,IAAI,MAAM,uBACpB,OAAmB,QAAoB,eAAe,cACtD,cAAc,CAAC;;QAErB,KAAK,SAAS;AACZ,gBAAM,YAAY,IAAI,KACjB,cAAc,aAAa,MAAM,WAAW,OAAO,GACpD,MAAM;AACV,gBAAM,SAAS,CAAC,MAAM,IAAI,WAAW,SAAS,CAAC;AAC/C,oBAAU,QAAO;AACjB,iBAAO;;QAET,KAAK,YAAY;AACf,iBAAO,IAAI,eACP,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW;;QAE5D;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AC/GA,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,aACT,CAAC,MAAY,WAA4B,SACxC,MAAM,8BACQ;AACT,cAAQ,KAAK,IAAI;QACf,KAAK,cAAc;AACjB,gBAAM,iBACF,cAAc,kBAAkB,MAAM,WAAW,OAAO;AAE5D,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,iBAAO,CAAC,IAAI,WAAW,gBAAgB,MAAM,CAAC;;QAEhD,KAAK,UAAU;AACb,gBAAM,IAAI,cAAc,KAAK,MAAM,WAAW,OAAO;AACrD,gBAAM,IAAI,cAAc,KAAK,MAAM,WAAW,OAAO;AACrD,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,SAAS,IAAI,KAAK,GAAG,GAAG,MAAM;AACpC,iBAAO,CAAC,OAAO,QAAQ,OAAO,OAAO;;QAEvC,KAAK,cAAc;AACjB,gBAAM,iBACF,cAAc,kBAAkB,MAAM,WAAW,OAAO;AAE5D,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,iBAAO,CAAC,IAAI,WAAW,gBAAgB,MAAM,CAAC;;QAEhD,KAAK,UAAU;AACb,gBAAM,IAAI,cAAc,KAAK,MAAM,WAAW,OAAO;AACrD,gBAAM,SAAS,IAAI,OAAO,CAAC;AAC3B,iBAAO,CAAC,OAAO,QAAQ,OAAO,OAAO;;QAEvC,KAAK,YAAY;AACf,gBAAM,IAAI,cAAc,KAAK,MAAM,WAAW,OAAO;AACrD,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,SAAS,IAAI,OAAO,GAAG,IAAI;AACjC,iBAAO,CAAC,OAAO,QAAQ,OAAO,OAAO;;QAEvC;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;ACvER,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,aACT,CAAC,MAAY,WACZ,SAA2B,MAAM,8BAAmB;AACnD,cAAQ,KAAK,IAAI;QACf,KAAK,SAAS;AACZ,iBAAO,UAAU,KAAK,IAAI;;QAE5B,KAAK;AACH,gBAAM,MACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,iBAAO,CAAC,UAAU,KAAK,MAAM,WAAW,OAAO,KAAK,GAAG;QACzD,KAAK;AACH,iBAAO,CAAC,UAAU,KAAK,MAAM,WAAW,OAAO,CAAC;QAClD,KAAK;QACL,KAAK;QACL,KAAK,2BAA2B;AAC9B,gBAAMC,QAAO,cAAc,KAAK,MAAM,WAAW,OAAO;AACxD,iBAAO,CAAC,YAAYA,KAAI,CAAC;;QAE3B,KAAK;AACH,iBAAQ,cAAc,KAAK,MAAM,WAAW,OAAO,EAC9C,IAAI,CAAC,MAAc,YAAY,CAAC,CAAC;QACxC,KAAK;AACH,gBAAM,WACD,cAAc,KAAK,MAAM,WAAW,OAAO;AAChD,iBAAO,CAAC,YAAY,QAAQ,CAAC;QAC/B,KAAK;AACH,iBAAO,CAAC,IAAI,SACP,cAAc,KAAK,MAAM,WAAW,OAAO,EAAa,OACzD,OAAO,CAAC;QACd,KAAK;AACH,iBAAQ,cAAc,KAAK,MAAM,WAAW,OAAO,EAC9C,IAAI,CAAC,MAAc,IAAI,SAAS,EAAE,KAAK,CAAC;QAC/C,KAAK;AACH,iBAAO,CAAC,IAAI,OACP,cAAc,KAAK,MAAM,WAAW,OAAO,EAAa,MACzD,OAAO,CAAC;QACd,KAAK;AACH,iBAAO,CAAC,IAAI,OACP,cAAc,KAAK,MAAM,WAAW,OAAO,EAAa,MACzD,OAAO,CAAC;QACd,KAAK;AACH,iBAAO,CAAC,IAAI,OAAO,CAAC,CAAC;QACvB,KAAK;AACH,gBAAM,QAAQ,cAAc,KAAK,MAAM,WAAW,OAAO;AACzD,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,kBAAQ,KACJ,gGAC2D;AAC/D,kBAAQ,IAAI,OAAO;AACnB,mBAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,oBAAQ,IAAI,MAAM,UAAU,MAAM,KAAK,KAAK,CAAC,EAAE,SAAQ,CAAE,EACxC,MAAM,GAAG,SAAS,CAAC;;AAEtC,iBAAO,CAAC,KAAK;QAEf;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AC3FJ,IAuBa;AAvBb,IAAAC,mBAAA;;AAgBA;AAEA;AAKM,IAAO,YAAP,MAAgB;MAMpB,IAAI,KAAE;AACJ,eAAO,KAAK,OAAO;MACrB;;;;;;;MAQA,YAAqB,UAA6B,YAAoB;AAAjD,aAAA,WAAA;AAA6B,aAAA,aAAA;AAChD,aAAK,SAAS,OAAO,CAAC;AAEtB,aAAK,YAAY,oBAAI,IAAG;AAExB,aAAK,KAAK,MAAM;MAClB;;;;MAKA,gBAAa;AACX,aAAK,UAAU,QAAQ,WAAS,MAAM,QAAO,CAAE;AAC/C,aAAK,UAAU,MAAK;AACpB,aAAK,OAAO,QAAO;MACrB;;;;MAKA,OAAI;AACF,eAAO,KAAK,UAAU;MACxB;;;;MAKA,aAAU;AACR,eAAa,OAAO,KAAK,KAAI,GAAI,OAAO;MAC1C;;;;;;MAOA,MAAM,OAAO,MAAc,QAAc;AACvC,aAAK,uBAAuB,MAAM,MAAM;AAIxC,cAAM,QAAQ,MAAM,KAAK,KAAI;AAG7B,aAAK,UAAU,QAAQ,WAAS,MAAM,QAAO,CAAE;AAC/C,aAAK,UAAU,MAAK;AAEpB,eAAO,KAAK,MAAK;AACf,gBAAM,UAAU,QAAQ,MAAM;AAE9B,gBAAM,aAAa,MAAM;AACzB,gBAAM,eAAe,QAAQ;AAE7B,uBAAK,OACD,eAAe,cACf,MAAM,kDACC,UAAU,6BAA6B,YAAY,YAC3C;AAEnB,mBAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,kBAAM,MAAM,MAAM,CAAC;AACnB,kBAAM,QAAQ,QAAQ,CAAC;AAEvB,iBAAK,KAAK;AACV,iBAAK,UAAU,IAAI,KAAK,KAAK;;AAG/B,iBAAO,KAAK;QACd,CAAC;MACH;;;;;;;;;;;;;;;;MAiBA,MAAM,KAAK,MAAc,cAAoB;AAC3C,aAAK,uBAAuB,MAAM,YAAY;AAE9C,cAAM,QAAQ,MAAM,KAAK,KAAI;AAE7B,eAAO,KAAK,MAAK;AACf,gBAAM,SAAmB,CAAA;AAEzB,mBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,kBAAM,MAAM,MAAM,CAAC;AAEnB,kBAAM,QAAQ,KAAK,gBAAgB,KAAK,YAAY;AACpD,mBAAO,KAAK,KAAK;;AAGnB,iBAAO,MAAM,MAAM;QACrB,CAAC;MACH;;MAGQ,gBAAgB,KAAU,cAAoB;AACpD,cAAM,SAAS,KAAK,UAAU,IAAI,GAAG;AAErC,eAAO,UAAU,OAAO,SAAS;MACnC;MAEQ,uBAAuB,KAAa,OAAa;AACvD,YAAI,IAAI,UAAU,KAAK,UAAU;AAC/B,gBAAM,IAAI,MACN,oBAAoB,KAAK,QAAQ,aAC9B,IAAI,KAAK,EAAE;;AAGpB,YAAI,MAAM,UAAU,KAAK,YAAY;AACnC,gBAAM,IAAI,MACN,sBAAsB,KAAK,UAAU,aAClC,MAAM,KAAK,EAAE;;MAExB;;;;;;ACnKF,IA2BaC;AA3Bb;;AAqBA,IAAAC;AAIA;AAEO,IAAMD,aAAqC,OAC9C,MAAY,WAA4B,SACxC,oBAAuD;AACzD,cAAQ,KAAK,IAAI;QACf,KAAK;QACL,KAAK,eAAe;AAClB,gBAAM,sBACF,gBAAgB,yBAAyB,KAAK,IAAI;AAEtD,cAAI,uBAAuB,MAAM;AAC/B,mBAAO,CAAC,mBAAmB;iBACtB;AACL,kBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,kBAAM,aACF,cAAc,cAAc,MAAM,WAAW,OAAO;AAExD,kBAAM,YAAY,IAAI,UAAU,UAAU,UAAU;AACpD,4BAAgB,aAAa,KAAK,MAAM,SAAS;AACjD,mBAAO,CAAC,UAAU,MAAM;;;QAG5B,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK,uBAAuB;AAC1B,gBAAM,SAAS,cACI,eAAe,MAAM,WAAW,SAChC,eAAe;AAClC,gBAAM,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AAC3D,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AAEpD,gBAAM,YAAY,gBAAgB,iBAAiB,OAAO,EAAE;AAE5D,iBAAO,CAAC,MAAM,UAAU,OAAO,MAAM,MAAM,CAAC;;QAE9C,KAAK;QACL,KAAK,qBAAqB;AACxB,gBAAM,SAAS,cACI,eAAe,MAAM,WAAW,SAChC,eAAe;AAClC,gBAAM,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AAC3D,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAE1D,gBAAM,YAAY,gBAAgB,iBAAiB,OAAO,EAAE;AAC5D,iBAAO,CAAC,MAAM,UAAU,KAAK,MAAM,YAAY,CAAC;;QAElD,KAAK;QACL,KAAK,qBAAqB;AACxB,gBAAM,SAAS,cACI,eAAe,MAAM,WAAW,SAChC,eAAe;AAElC,gBAAM,YAAY,gBAAgB,iBAAiB,OAAO,EAAE;AAC5D,iBAAO,CAAC,UAAU,WAAU,CAAE;;QAEhC;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;ACxFA,IA2BaE;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,cACT,CAAC,MAAY,WACZ,SAA2B,MAAM,8BAAmB;AACnD,cAAQ,KAAK,IAAI;QACf,KAAK,kBAAkB;AACrB,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAE1D,gBAAM,mBACF,cAAc,oBAAoB,MAAM,WAAW,OAAO;AAE9D,iBAAO,CAAC,IAAI,MAAM,eACd,QAA+B,CAAC,KAAK,CAAC,GAAG,KAAK,CAAC,CAAC,GAAG,cACnD,gBAAgB,CAAC;;QAEvB,KAAK,yBAAyB;AAC5B,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAE1D,gBAAM,mBACF,cAAc,oBAAoB,MAAM,WAAW,OAAO;AAE9D,iBAAO,CAAC,IAAI,MAAM,sBACd,QAA+B,CAAC,KAAK,CAAC,GAAG,KAAK,CAAC,CAAC,GAAG,cACnD,gBAAgB,CAAC;;QAEvB,KAAK,iBAAiB;AACpB,gBAAMC,SACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,qBACF,cAAc,sBAAsB,MAAM,WAAW,OAAO;AAEhE,iBAAO,CAAC,IAAI,MAAM,cACdA,QAAmB,OAAmB,QACtC,UAA8B,QAC9B,kBAAkB,CAAC;;QAEzB,KAAK,8BAA8B;AACjC,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,aACF,cAAc,cAAc,MAAM,WAAW,OAAO;AACxD,gBAAM,cACF,cAAc,eAAe,MAAM,WAAW,OAAO;AAEzD,gBAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,gBAAM,gBACF,cAAc,iBAAiB,MAAM,WAAW,OAAO;AAE3D,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,iBAAO,CAAC,IAAI,MAAM,UACd,QACA,YACA,cAAc,YAAW,GACzB,SAAS,YAAW,GACpB,WACA,WAA+B,CAAC;;QAEtC;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AC1GJ,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,cACT,CAAC,MAAY,WAA4B,SACxC,MAAM,8BAAmB;AACxB,cAAQ,KAAK,IAAI;QACf,KAAK,SAAS;AACZ,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,YAAY;AACf,iBAAO,CAAC,IAAI,SACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,WAAW;AACd,iBAAO,CAAC,IAAI,QACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,gBAAgB;AACnB,iBAAO,CAAC,IAAI,aACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,QAAQ;AACX,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,aAAa;AAChB,iBAAO,CAAC,IAAI,UACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,cAAc;AACjB,iBAAO,CAAC,IAAI,WACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,cAAc;AACjB,iBAAO,CAAC,IAAI,WACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,aAAa;AAChB,iBAAO,CAAC,IAAI,UACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK;QACL,KAAK,YAAY;AACf,iBAAO,CAAC,IAAI,MACR,cAAc,aAAa,MAAM,WAAW,OAAO,GACnD,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,cAAc;AACjB,iBAAO,CAAC,IAAI,WACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AC1FJ,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,cACT,CAAC,MAAY,WAA4B,SACxC,MAAM,8BAAmB;AACxB,cAAQ,KAAK,IAAI;QACf,KAAK;QACL,KAAK;QACL,KAAK;AACH,iBAAO,CAAC,IAAI,OACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,cAAc,MAAM,WAAW,OAAO,GACpD,cAAc,cAAc,MAAM,WAAW,OAAO,CACzC,CAAC;QAElB,KAAK;AACH,iBAAO,CAAC,IAAI,OACR,cAAc,YAAY,MAAM,WAAW,OAAO,GAClD,GAAG,cAAc,WAAW,MAAM,WAAW,OAAO,CACxC,CAAC;QAEnB,KAAK;AACH,iBAAO,CAAC,IAAI,UACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,QAAQ,MAAM,WAAW,OAAO,CAAa,CAAC;QAElE,KAAK;AACH,gBAAM,CAAC,SAAS,cAAc,IACzB,cAAc,YAAY,MAAM,WAAW,OAAO;AAEvD,gBAAM,YAAY,YAAY;AAC9B,gBAAM,UAAU,mBAAmB;AAEnC,gBAAM,UACD,cAAc,WAAW,MAAM,WAAW,OAAO;AACtD,gBAAM,iBACF,cAAc,kBAAkB,MAAM,WAAW,OAAO;AAG5D,cAAI,WAAW;AACb,gBAAI,WAAW,YAAY,GAAG;AAC5B,oBAAM,IAAI,MACN,oFACkC;;AAExC,gBAAI,CAAC,WAAW,YAAY,GAAG;AAC7B,oBAAM,IAAI,MACN,+DAA+D;;;AAGvE,gBAAM,CAAC,SAAS,QAAQ,IACpB,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,iBAAO,CAAC,IAAI,MAAM,OAAO;YACvB,GAAG,cAAc,KAAK,MAAM,WAAW,OAAO;YAC9C,GAAG,cAAc,KAAK,MAAM,WAAW,OAAO;YAC9C,YAAY,cAAc,cAAc,MAAM,WAAW,OAAO;YAEhE,YAAY,cAAc,cAAc,MAAM,WAAW,OAAO;YAEhE,MAAM;YACN,YAAY;YACZ,wBAAwB;YACxB;WACD,CAAC;QAEJ,KAAK;AACH,iBAAO,CAAC,IAAI,OAAO,SACf,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,YAAY,MAAM,WAAW,OAAO,GAClD,cAAc,YAAY,MAAM,WAAW,OAAO,CAAW,CAAC;QAEpE;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;ACpGJ,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,cACT,CAAC,MAAY,WACZ,SAA2B,MAAM,8BAAmB;AACnD,cAAQ,KAAK,IAAI;QACf,KAAK;AACH,iBAAO,CAAC,IAAI,cACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,QAAQ,MAAM,WAAW,OAAO,GAC9C,cAAc,YAAY,MAAM,WAAW,OAAO,CAAY,CAAC;QACrE,KAAK;QACL,KAAK,oBAAoB;AACvB,iBAAO,CAAC,IAAI,UACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,QAAQ,MAAM,WAAW,OAAO,GAC9C,cAAc,YAAY,MAAM,WAAW,OAAO,GAClD,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,cAAc,SAAS,MAAM,WAAW,OAAO,GAC/C,cAAc,WAAW,MAAM,WAAW,OAAO,CAAW,CAAC;;QAEnE,KAAK,oBAAoB;AACvB,iBAAO,CAAC,IAAI,UACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,QAAQ,MAAM,WAAW,OAAO,GAC9C,cAAc,YAAY,MAAM,WAAW,OAAO,GAClD,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,cAAc,SAAS,MAAM,WAAW,OAAO,GAC/C,cAAc,WAAW,MAAM,WAAW,OAAO,CAAW,CAAC;;QAEnE,KAAK,OAAO;AACV,iBAAO,CAAC,IAAI,2BACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAE3C,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,cAAc,QAAQ,MAAM,WAAW,OAAO,GAC9C,cAAc,SAAS,MAAM,WAAW,OAAO,GAC/C,cAAc,QAAQ,MAAM,WAAW,OAAO,CAAW,CAAC;;QAEhE,KAAK,WAAW;AACd,iBAAO,CAAC,IAAI,QACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,cAAc;AACjB,iBAAO,CAAC,IAAI,WACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AC3EJ,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,cACT,CAAC,MAAY,WAA4B,SACxC,MAAM,8BAAmB;AACxB,cAAQ,KAAK,IAAI;QACf,KAAK,gBAAgB;AACnB,gBAAM,EACJ,oBACA,kBAAiB,IAEf,IAAI,aACA,cACI,sBAAsB,MAAM,WAAW,OAAO,GAElD,cACI,qBAAqB,MAAM,WAAW,OAAO,GACjD,cAAc,WAAW,MAAM,WAAW,OAAO,GACjD,cAAc,oBAAoB,MAAM,WAAW,OAAO,CAChD;AAClB,iBAAO,mBAAmB,OAAO,iBAAiB;;QAEpD,KAAK,eAAe;AAClB,gBAAM,EAAC,gBAAgB,cAAa,IAAI,IAAI,YACxC,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,cAAc,UAAU,MAAM,WAAW,OAAO,CAAW;AAC/D,iBAAO,CAAC,gBAAgB,aAAa;;QAEvC,KAAK,wBAAwB;AAC3B,iBAAO,CAAC,IAAI,qBACR,cAAc,SAAS,MAAM,WAAW,OAAO,GAC/C,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,cAAc,gBAAgB,MAAM,WAAW,OAAO,GACtD,cAAc,uBAAuB,MAAM,WAAW,OAAO,GAE7D,cAAc,qBAAqB,MAAM,WAAW,OAAO,CAC/C,CAAC;;QAEnB;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;ACnEJ,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,cACT,CAAC,MAAY,WACZ,SAA2B,MAAM,8BAAmB;AACnD,cAAQ,KAAK,IAAI;QACf,KAAK,OAAO;AACV,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,MACxD,QAAQ,CAAC;;QAEf,KAAK,QAAQ;AACX,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,MACxD,QAAQ,CAAC;;QAEf,KAAK,OAAO;AACV,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,MACxD,QAAQ,CAAC;;QAEf,KAAK,OAAO;AACV,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,MACxD,QAAQ,CAAC;;QAEf,KAAK,OAAO;AACV,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,MACxD,QAAQ,CAAC;;QAEf,KAAK,OAAO;AACV,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,MACxD,QAAQ,CAAC;;QAEf,KAAK,UAAU;AACb,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,iBAAO,CAAC,IAAI,OACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,IAAI,CAAC;;QAEnE,KAAK,UAAU;AACb,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,iBAAO,CAAC,IAAI,OACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,IAAI,CAAC;;QAEnE,KAAK,QAAQ;AACX,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,MACxD,QAAQ,CAAC;;QAEf,KAAK,WAAW;AACd,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,gBAAMC,WACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,iBAAO,CAAC,IAAI,QACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,MACxD,WAAWA,QAAO,CAAC;;QAEzB,KAAK,UAAU;AACb,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,gBAAMA,WACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,iBAAO,CAAC,IAAI,OACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,MACxD,WAAWA,QAAO,CAAC;;QAEzB,KAAK;AACH,gBAAM,IAAI,cAAc,KAAK,MAAM,WAAW,OAAO;AACrD,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAElD,iBAAO,CAAC,IAAI,SAAS,GAAG,SAAS,IAAI,CAAC;QACxC,KAAK,iBAAiB;AACpB,gBAAMC,KAAI,cAAc,KAAK,MAAM,WAAW,OAAO;AAErD,gBAAMC,WACF,cAAc,WAAW,MAAM,WAAW,OAAO;AAErD,gBAAMC,QACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAElD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAG1D,iBAAO,CAAC,IAAI,cAAcF,IAAGC,UAASC,OAAM,YAAY,CAAC;;QAE3D;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AC1JJ,IA2BaC;AA3Bb;;AAiBA;AAEA;AAMA;AAEO,IAAMA,cACT,CAAC,MAAY,WAA4B,SACxC,MAAM,8BAAmB;AACxB,cAAQ,KAAK,IAAI;QACf,KAAK;QACL,KAAK,UAAU;AACb,gBAAM,IAAI,cAAc,KAAK,MAAM,WAAW,OAAO;AACrD,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,cAAI,SACA,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,mBAAS,OAAO,MAAM,GAAG,CAAC;AAC1B,iBAAO,CAAC,IAAI,OAAO,QAAQ,IAAI,CAAC;;QAElC,KAAK,UAAU;AACb,gBAAM,QAAQ,cAAc,KAAK,MAAM,WAAW,OAAO;AACzD,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,iBAAO,CAAC,IAAI,OAAO,OAAO,IAAI,KAAK,SAAS,OAAO,GAAG,CAAC,CAAC;;QAE1D,KAAK,YAAY;AACf,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,gBAAM,QAAQ,cAAc,KAAK,MAAM,WAAW,OAAO;AACzD,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,iBAAO,CAAC,IAAI,OACR,OAAO,IAAI,KAAK,SAAS,OAAO,GAAG,MAAM,SAAS,CAAC;;QAEzD,KAAK,WAAW;AACd,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,OAAO,CAAA;AACb,mBAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,gBAAI,KAAK,CAAC,GAAG;AACX,mBAAK,KAAK,CAAC;;;AAGf,gBAAM,QAAQ,cAAc,KAAK,MAAM,WAAW,OAAO;AACzD,iBAAO,CAAC,IAAI,QAAQ,OAAO,IAAI,CAAC;;QAElC,KAAK,aAAa;AAChB,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,QAAQ,cAAc,KAAK,MAAM,WAAW,OAAO;AACzD,iBAAO,CAAC,IAAI,QAAQ,OAAO,IAAI,CAAC;;QAElC,KAAK,SAAS;AAEZ,gBAAM,QAAQ,cAAc,SAAS,MAAM,WAAW,OAAO;AAE7D,gBAAM,OAAO,cAAc,QAAQ,MAAM,WAAW,OAAO;AAC3D,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,OACxD,IAAI,CAAC;;QAEX,KAAK,gBAAgB;AACnB,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,gBAAM,MACF,cAAc,OAAO,MAAM,WAAW,OAAO;AACjD,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,cACF,cAAc,eAAe,MAAM,WAAW,OAAO;AACzD,gBAAM,iBACF,cAAc,kBAAkB,MAAM,WAAW,OAAO;AAE5D,gBAAMC,UAAS,cAAc,KAAK,MAAM,WAAW,OAAO;AAE1D,iBAAO,CAAC,IAAI,aACRA,SAAQ,OAAO,KAAK,SAAS,WAAW,SAAS,cACjD,aAAa,cAAc,CAAC;;QAElC,KAAK,QAAQ;AACX,iBAAO,KAAK,MAAK;AACf,kBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,kBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AAGrD,kBAAM,QAAQ,QAAQ,CAAC,EAAE;AACzB,kBAAM,gBAAgB,IAAI,QAAQ,QAAQ,CAAC,CAAC,EAAE;AAC9C,kBAAM,SAAS,QAAQ,IAAI,CAAAA,YAAS;AAClC,oBAAM,YAAY,aAAK,YAAYA,QAAO,OAAO,KAAK;AACtD,kBAAI,CAAC,aACD,CAAC,aAAK,YAAY,IAAI,QAAQA,OAAM,EAAE,OAAO,aAAa,GAAG;AAC/D,sBAAM,IAAI,MAAM,wCAAwC;;AAE1D,qBAAO,YAAYA,UAAS,IAAI,QAAQA,SAAQ,KAAK;YACvD,CAAC;AACD,mBAAO,CAAC,IAAI,MAAM,QAAQ,IAAI,CAAC;UACjC,CAAC;;QAEH,KAAK,UAAU;AACb,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAMA,UACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,iBAAO,IAAI,QAAQA,SAAQ,IAAI;;QAEjC,KAAK,QAAQ;AACX,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,IAAI,CAAC;;QAEnE,KAAK;QACL,KAAK,UAAU;AACb,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,gBAAM,kBACF,cAAc,mBAAmB,MAAM,WAAW,OAAO;AAG7D,gBAAMA,UAAS,cAAc,KAAK,MAAM,WAAW,OAAO;AAE1D,iBAAO,IAAI,MAAMA,SAAQ,iBAAiB,IAAI;;QAEhD,KAAK,aAAa;AAChB,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,iBAAO,CAAC,IAAI,UAAU,SAAS,QAAQ,KAAK,CAAC;;QAE/C,KAAK,YAAY;AACf,gBAAM,IAAI,cAAc,KAAK,MAAM,WAAW,OAAO;AACrD,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,iBAAO,CAAC,IAAI,SAAS,GAAG,OAAO,CAAC;;QAElC,KAAK,iBAAiB;AACpB,gBAAM,UACF,cAAc,iBAAiB,MAAM,WAAW,OAAO;AAE3D,gBAAM,QACF,cAAc,eAAe,MAAM,WAAW,OAAO;AAEzD,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,gBAAM,eACF,cAAc,gBAAgB,MAAM,WAAW,OAAO;AAC1D,iBAAO,CAAC,IAAI,cACR,SAAS,cAAc,OACvB,aAAa,UAAU,aAAa,QAChC,eACA,IAAI,KAAK,cAAc,aAAa,KAAK,CAAC,CAAC;;QAErD,KAAK,uBAAuB;AAC1B,gBAAM,UACF,cAAc,WAAW,MAAM,WAAW,OAAO;AACrD,gBAAM,SACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,gBAAMA,UACF,cAAc,UAAU,MAAM,WAAW,OAAO;AACpD,iBAAO,CAAC,IAAI,oBAAoBA,SAAQ,SAAS,MAAM,CAAC;;QAE1D;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;ACvMJ,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,cACT,CAAC,MAAY,WACZ,SAA2B,MAAM,8BAAmB;AACnD,cAAQ,KAAK,IAAI;QACf,KAAK,uBAAuB;AAC1B,gBAAM,EACJ,eACA,cACA,mBACA,gBAAe,IAEb,IAAI,OAAO,oBACP,cAAc,WAAW,MAAM,WAAW,OAAO,GAEjD,cAAc,UAAU,MAAM,WAAW,OAAO,GAChD,cAAc,cAAc,MAAM,WAAW,OAAO,GAEpD,cAAc,gBAAgB,MAAM,WAAW,OAAO,CAC5C;AAClB,iBAAO;YACL;YAAe;YAAc;YAAmB;;;QAGpD,KAAK,iBAAiB;AACpB,gBAAM,EAAC,eAAe,YAAW,IAAI,IAAI,OAAO,cAC5C,cAAc,gBAAgB,MAAM,WAAW,OAAO,GAEtD,cAAc,cAAc,MAAM,WAAW,OAAO,GACpD,cAAc,YAAY,MAAM,WAAW,OAAO,CAAa;AACnE,iBAAO,CAAC,eAAe,WAAW;;QAEpC,KAAK,qBAAqB;AACxB,gBAAM,aAAa,IAAI,OAAO,kBAC1B,cAAc,QAAQ,MAAM,WAAW,OAAO,GAC9C,cAAc,WAAW,MAAM,WAAW,OAAO,GACjD,cAAc,cAAc,MAAM,WAAW,OAAO,CACxC;AAChB,iBAAO,CAAC,UAAU;;QAEpB,KAAK,oBAAoB;AACvB,gBAAM,aAAa,IAAI,OAAO,iBAC1B,cAAc,QAAQ,MAAM,WAAW,OAAO,GAC9C,cAAc,WAAW,MAAM,WAAW,OAAO,GACjD,cAAc,cAAc,MAAM,WAAW,OAAO,CACxC;AAChB,iBAAO,CAAC,UAAU;;QAEpB;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AC7EJ,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,cACT,CAAC,MAAY,WAA4B,SACxC,MAAM,8BAAmB;AACpB,cAAQ,KAAK,IAAI;QACf,KAAK,OAAO;AACV,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,QAAQ;AACX,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,QAAQ;AACX,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D,KAAK,SAAS;AACZ,iBAAO,CAAC,IAAI,MACR,cAAc,KAAK,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE7D;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;AClDR,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,cACT,CAAC,MAAY,WACZ,SAA2B,MAAM,8BAAmB;AACnD,cAAQ,KAAK,IAAI;QACf,KAAK,sBAAsB;AACzB,iBAAO,CAAC,IAAI,OAAO,mBACjB,cAAc,SAAS,MAAM,WAAW,OAAO,GAC/C,cAAc,WAAW,MAAM,WAAW,OAAO,GACjD,cAAc,WAAW,MAAM,WAAW,OAAO,GACjD,cAAc,iBAAiB,MAAM,WAAW,OAAO,CAAY,CACpE;;QAEH,KAAK,gBAAgB;AACnB,gBAAM,EAAC,QAAQ,aAAY,IAAI,IAAI,OAAO,aACtC,cAAc,QAAQ,MAAM,WAAW,OAAO,GAC9C,cAAc,cAAc,MAAM,WAAW,OAAO,GACpD,cAAc,aAAa,MAAM,WAAW,OAAO,GACnD,cAAc,eAAe,MAAM,WAAW,OAAO,GAErD,cAAc,WAAW,MAAM,WAAW,OAAO,GACjD,cAAc,YAAY,MAAM,WAAW,OAAO,GAClD,cAAc,YAAY,MAAM,WAAW,OAAO,GAClD,cACI,0BAA0B,MAAM,WAAW,OAAO,CAC3C;AACf,iBAAO,CAAC,QAAQ,YAAY;;QAE9B,KAAK,eAAe;AAClB,gBAAM,EAAC,SAAS,QAAQ,MAAK,IAAI,IAAI,OAAO,YACxC,cAAc,SAAS,MAAM,WAAW,OAAO,GAC/C,cAAc,aAAa,MAAM,WAAW,OAAO,GACnD,cAAc,aAAa,MAAM,WAAW,OAAO,CAAY;AACnE,iBAAO,CAAC,SAAS,QAAQ,KAAK;;QAEhC,KAAK,0BAA0B;AAC7B,gBAAM,SAAS,IAAI,OAAO,uBACtB,cAAc,SAAS,MAAM,WAAW,OAAO,GAC/C,cAAc,cAAc,MAAM,WAAW,OAAO,CAAW;AACnE,iBAAO,CAAC,MAAM;;QAEhB;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;ACtEJ,IA2BaC;AA3Bb;;AAmBA;AAMA;AAEO,IAAMA,cACT,CAAC,MAAY,WAA4B,SACxC,MAAM,8BAAmB;AACxB,cAAQ,KAAK,IAAI;QACf,KAAK,QAAQ;AACX,iBAAO,CAAC,IAAI,KACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,SAAS,MAAM,WAAW,OAAO,CACzB,CAAC;;QAE7B,KAAK,cAAc;AACjB,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,iBAAO,CAAC,IAAI,WACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,IAAI,CAAC;;QAEnE,KAAK,WAAW;AACd,gBAAM,OACF,cAAc,QAAQ,MAAM,WAAW,OAAO;AAClD,iBAAO,CAAC,IAAI,QACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAAa,IAAI,CAAC;;QAGnE,KAAK,WAAW;AACd,iBAAO,CAAC,IAAI,QACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,SAAS,MAAM,WAAW,OAAO,CAAa,CAAC;;QAEnE,KAAK,eAAe;AAClB,iBAAO,CAAC,IAAI,YACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,SAAS,MAAM,WAAW,OAAO,CAAa,CAAC;;QAEnE,KAAK,aAAa;AAChB,iBAAO,CAAC,IAAI,UACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,WAAW,MAAM,WAAW,OAAO,GAEjD,cAAc,QAAQ,MAAM,WAAW,OAAO,CAC/B,CAAC;;QAEtB,KAAK;QACL,KAAK,OAAO;AACV,iBAAO,CAAC,IAAI,IACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,WAAW,MAAM,WAAW,OAAO,GAEjD,cAAc,iBAAiB,MAAM,WAAW,OAAO,CAC7C,CAAC;;QAEjB,KAAK,kBAAkB;AACrB,gBAAM,aACF,cAAc,cAAc,MAAM,WAAW,OAAO;AACxD,gBAAM,WACF,cAAc,YAAY,MAAM,WAAW,OAAO;AACtD,iBAAO,CAAC,IAAI,eACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,YAAY,QAAQ,CAAC;;QAE3B,KAAK,kBAAkB;AACrB,gBAAM,aACF,cAAc,cAAc,MAAM,WAAW,OAAO;AACxD,gBAAM,QACF,cAAc,SAAS,MAAM,WAAW,OAAO;AACnD,iBAAO,CAAC,IAAI,eACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,YAAY,KAAK,CAAC;;QAExB,KAAK,gBAAgB;AACnB,gBAAM,YACF,cAAc,aAAa,MAAM,WAAW,OAAO;AACvD,gBAAM,aACD,cAAc,cAAc,MAAM,WAAW,OAAO,EAC5C,YAAW;AAExB,iBAAO,CAAC,IAAI,aACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,WAAW,UAAU,CAAC;;QAE5B,KAAK,eAAe;AAClB,iBAAO,CAAC,IAAI,YACR,cAAc,KAAK,MAAM,WAAW,OAAO,GAC3C,cAAc,SAAS,MAAM,WAAW,OAAO,CAAa,CAAC;;QAEnE,KAAK,iBAAiB;AACpB,iBAAO,CAAC,IAAI,cACR,cAAc,MAAM,MAAM,WAAW,OAAO,GAC5C,cAAc,MAAM,MAAM,WAAW,OAAO,CAAW,CAAC;;QAE9D;AACE,gBAAM,UAAU,aAAa,KAAK,EAAE,qBAAqB;;IAE/D;;;;;ACjEE,SAAUC,YACZ,MAAY,WAA4B,SACxC,iBAAmCC,QAAW,MAAI;AAEpD,QAAM,SACD,CAACC,OAAYC,YAA4BC,aAA6B;AACrE,YAAQF,MAAK,UAAU;MACrB,KAAK;AACH,eAAOD,MAAK,MAAiB,UAAUC,OAAMC,YAAWC,QAAO,CAAC;MAClE,KAAK;AACH,eAAOH,MAAK,MAAgBD,WAAUE,OAAMC,YAAWC,QAAO,CAAC;MACjE,KAAK;AACH,eAAeJ,WAAUE,OAAMC,YAAWC,QAAO;MACnD,KAAK;AACH,eAAOH,MAAK,MAAkBD,WAAUE,OAAMC,YAAWC,QAAO,CAAC;MACnE,KAAK;AACH,eAAOH,MAAK,MAAeD,WAAUE,OAAMC,YAAWC,QAAO,CAAC;MAChE,KAAK;AACH,eAAeJ,WAAUE,OAAMC,YAAWC,QAAO;MACnD,KAAK;AACH,eAAOH,MAAK,MAAiBD,WAAUE,OAAMC,YAAWC,QAAO,CAAC;MAClE,KAAK;AACH,eAAOH,MAAK,MAAYD,YAAUE,OAAMC,YAAWC,QAAO,CAAC;MAC7D,KAAK;AACH,eAAOH,MAAK,MAAYD,WAAUE,OAAMC,YAAWC,QAAO,CAAC;MAC7D,KAAK;AACH,eAAOH,MAAK,MAAcD,YAAUE,OAAMC,YAAWC,QAAO,CAAC;MAC/D,KAAK;AACH,eAAOH,MAAK,MAAeD,YAAUE,OAAMC,YAAWC,QAAO,CAAC;MAChE,KAAK;AACH,eAAOH,MACH,MAAoBD,YAAUE,OAAMC,YAAWC,QAAO,CAAC;MAC7D,KAAK;AACH,eAAOH,MAAK,MAAaD,YAAUE,OAAMC,YAAWC,QAAO,CAAC;MAC9D,KAAK;AACH,eAAOH,MAAK,MAAgBD,YAAUE,OAAMC,YAAWC,QAAO,CAAC;MACjE,KAAK;AACH,eAAOH,MAAK,MAAgBD,YAAUE,OAAMC,YAAWC,QAAO,CAAC;MACjE,KAAK;AACH,eAAOH,MAAK,MAAaD,YAAUE,OAAMC,YAAWC,QAAO,CAAC;MAC9D,KAAK;AACH,eAAOH,MAAK,MAAeD,YAAUE,OAAMC,YAAWC,QAAO,CAAC;MAChE,KAAK;AACH,eAAOH,MAAK,MAAaD,YAAUE,OAAMC,YAAWC,QAAO,CAAC;MAC9D,KAAK;AACH,eAAOH,MACH,MAAqBD,YAAUE,OAAMC,YAAWC,QAAO,CAAC;MAC9D,KAAK;AACH,eAAiBJ,WACbE,OAAMC,YAAWC,UAAS,eAAe;MAC/C,KAAK;AACH,cAAM,WAAW,gBAAgBF,MAAK,EAAE;AACxC,YAAI,YAAY,SAAS,gBAAgB;AACvC,iBAAO,SAAS,eACZ,IAAI,cAAcA,OAAMC,YAAWC,QAAO,CAAC;eAC1C;AACL,gBAAM,UAAU,aAAaF,MAAK,EAAE,qBAAqB;;MAE7D;AACE,cAAM,UACF,eAAeA,MAAK,EAAE,qIAEiC;;EAEjE,GAAG,MAAM,WAAW,OAAO;AAC/B,MAAQ,aAAK,UAAU,KAAK,GAAG;AAC7B,WAAO,MAAM,KAAK,CAAC,SAAS,CAAA,EAAG,OAAO,IAAI,CAAC;;AAE7C,SAAO,CAAA,EAAG,OAAO,KAAK;AACxB;AA3HA;;AAiBA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACbA,IASa;AATb;;AASM,IAAO,mBAAP,MAAuB;MAM3B,YACa,YAA6B,CAAA,GAC7B,iBAAiC,CAAA,GACjC,gBAA+B,CAAA,GAC/B,cAAiD,CAAA,GACjD,oBAA2D;AAJ3D,aAAA,YAAA;AACA,aAAA,iBAAA;AACA,aAAA,gBAAA;AACA,aAAA,cAAA;AACA,aAAA,qBAAA;AAVL,aAAA,cAAc,EAAC,IAAI,GAAG,WAAW,IAAI,aAAa,EAAC;AACnD,aAAA,WAAmC,CAAC,KAAK,WAAW;AACpD,aAAA,SAAS;AASf,aAAK,0BAAyB;MAChC;MAEQ,SAAS,IAAY,WAAiB;AAC5C,eAAO,EAAC,IAAI,WAAW,aAAa,EAAC;MACvC;;;;;;MAOA,IAAI,eAAe,UAAgC;AACjD,YAAI,KAAK,aAAa,UAAU;AAC9B,eAAK,WAAW;AAChB,eAAK,0BAAyB;;MAElC;MAEA,IAAI,iBAAc;AAChB,eAAO,KAAK;MACd;;;;MAKA,IAAI,mBAAgB;AAClB,eAAO,KAAK,mBAAmB,CAAC;MAClC;;;;;MAMA,IAAI,oBAAiB;AACnB,eAAO,KAAK;MACd;MAEQ,4BAAyB;AAC/B,cAAM,QAAQ,CAAA;AACd,iBAAS,IAAI,GAAG,IAAI,KAAK,SAAS,SAAS,GAAG,KAAK;AACjD,gBAAM,WAAW,KAAK,SAAS,MAAM,GAAG,KAAK,SAAS,SAAS,CAAC;AAChE,gBAAM,KAAK,KAAK,qBAAqB,QAAQ,CAAC;;AAEhD,cAAM,KAAK,EAAE;AACb,aAAK,qBAAqB;MAC5B;MAEQ,qBAAqB,UAAgC;AAC3D,eAAO,WACH,SACK,IACG,aAAY,QAAQ,OAAO,KAAK,QAAQ,gBAAgB,IACpD,KACA,GAAG,QAAQ,SAAS,IAAI,QAAQ,WAAW,EAAE,EACpD,KAAK,GAAG,IACb;MACN;;;;;MAMA,WAAW,SAAe;AACxB,YAAI,KAAK,UAAU;AACjB,eAAK;AACL,eAAK,WAAW,KAAK,SAAS,MAAK;AACnC,eAAK,SAAS,KAAK,KAAK,SAAS,KAAK,QAAQ,OAAO,CAAC;AACtD,eAAK,mBAAmB,QAAQ,KAAK,qBAAqB,KAAK,QAAQ,CAAC;;MAE5E;;;;;MAMA,YAAS;AACP,YAAI,KAAK,YAAY,KAAK,SAAS,SAAS,GAAG;AAC7C,eAAK,WAAW,KAAK,SAAS,MAAK;AACnC,eAAK,SAAS,OAAO,EAAE;AACvB,eAAK,kBAAkB,MAAK;eACvB;AACL,gBAAM,IAAI,MAAM,yCAAyC;;MAE7D;;;;;MAMA,gBAAa;AACX,YAAI,KAAK,YAAY,KAAK,SAAS,SAAS,GAAG;AAC7C,eAAK,WAAW,KAAK,SAAS,MAAK;AACnC,eAAK;AACL,gBAAM,UACF,OAAO,OAAO,CAAA,GAAI,KAAK,SAAS,KAAK,SAAS,SAAS,CAAC,CAAC;AAC7D,kBAAQ,eAAe;AACvB,kBAAQ,KAAK,KAAK;AAClB,eAAK,SAAS,OAAO,IAAI,GAAG,OAAO;AACnC,eAAK,mBAAmB,OACpB,GAAG,GAAG,KAAK,qBAAqB,KAAK,QAAQ,CAAC;eAC7C;AACL,gBAAM,IAAI,MAAM,uDAAuD;;MAE3E;MAEA,UAAU,MAAY;AACpB,eAAO,KAAK,UAAU,IAAI;MAC5B;MAEA,eAAe,aAAwB;AACrC,aAAK,eAAe,YAAY,EAAE,IAAI;MACxC;MAEA,eAAe,IAAU;AACvB,eAAO,KAAK,eAAe,EAAE;MAC/B;MAEA,cAAc,YAAsB;AAClC,aAAK,cAAc,WAAW,EAAE,IAAI;MACtC;MAEA,cAAc,IAAU;AACtB,eAAO,KAAK,cAAc,EAAE;MAC9B;MAEA,QAAQ,SAAoB;AAC1B,mBAAW,OAAO,KAAK,gBAAgB;AACrC,eAAK,eAAe,GAAG,EAAE,cAAc,OAAO;;AAGhD,mBAAW,OAAO,KAAK,eAAe;AACpC,eAAK,cAAc,GAAG,EAAE,cAAc,OAAO;;MAEjD;;;;;;AClJI,SAAU,qBACZ,QAAwB,SAAiB,WACzC,WAAkB;AACpB,QAAM,YAAY,oBAAI,IAAG;AACzB,QAAM,gBAA0B,CAAA;AAChC,MAAI,cAAoB;AACxB,MAAI,aAAuB;AAI3B,QAAM,OAAO,oBAAI,IAAG;AACpB,QAAM,iBACF,IAAI,IAAI,OAAO,KAAK,MAAM,EAAE,IAAI,CAAC,SAAS,cAAc,IAAI,EAAE,CAAC,CAAC,CAAC;AAErE,cAAY,aAAa,CAAA;AACzB,QAAM,gBACF,IAAI,IAAI,UAAU,IAAI,CAAC,SAAS,cAAc,KAAK,IAAI,EAAE,CAAC,CAAC,CAAC;AAEhE,QAAM,WAAW,CAAC,GAAG,OAAO;AAC5B,SAAO,SAAS,SAAS,GAAG;AAC1B,UAAM,OAAO,SAAS,IAAG;AACzB,QAAI,cAAc,IAAI,KAAK,eAAe,IAAI,KAAK,YAAY,IAAI,GAAG;AACpE,UAAI,eAAe,MAAM;AACvB,sBAAc;AACd,qBAAa,YAAY,SAAS,IAAI,WAAS,MAAM,IAAI,EACvC,OAAO,UAAQ,UAAU,IAAI,IAAI,CAAC;;;AAGxD,cAAU,IAAI,KAAK,IAAI;AAGvB,QAAI,UAAU,KAAK,IAAI,KAAK,MAAM;AAChC;;AAGF,QAAI,eAAe,IAAI,KAAK,IAAI,GAAG;AACjC;;AAGF,QAAI,cAAc,IAAI,KAAK,IAAI,GAAG;AAChC;;AAEF,QAAI,KAAK,OAAO,WAAW,GAAG;AAC5B,oBAAc,KAAK,KAAK,IAAI;AAC5B;;AAEF,SAAK,OAAO,QAAQ,WAAQ;AAE1B,UAAI,KAAK,IAAI,MAAM,IAAI,GAAG;AACxB;;AAEF,WAAK,IAAI,MAAM,IAAI;AACnB,eAAS,KAAK,KAAK;IACrB,CAAC;;AAEH,SAAO,EAAC,QAAQ,SAAS,WAAW,eAAe,aAAa,WAAU;AAC5E;AAMM,SAAU,2BACZ,OAAc,eAA4B;AAC5C,QAAM,EAAC,WAAW,OAAM,IAAI;AAC5B,QAAM,aAAa,OAAO,KAAK,MAAM,EACb,IAAI,UAAQ,cAAc,IAAI,EAAE,CAAC,CAAC,EAClC,IAAI,UAAQ,MAAM,MAAM,IAAI,CAAC;AACrD,QAAM,YAAY,MAAM,aAAa,CAAA;AAErC,QAAM,SAAS,CAAC,SACZ,UAAU,IAAI,OAAO,SAAS,WAAW,OAAO,KAAK,IAAI;AAE7D,WAASG,QAAO,OAAa;AAC3B,WAAO,CAAC,GAAG,IAAI,IAAI,MAAM,IAAI,CAAC,SAAS,CAAC,KAAK,MAAM,IAAI,CAAC,CAAC,EAAE,OAAM,CAAE;EACrE;AACA,QAAM,kBAAkBA,QAAO;IACL,GAAG;IACH,GAAG,MAAM;IACT,GAAG;GACJ,EAAE,OAAO,MAAM;AACxC,QAAM,WAAWA,QAAO;IACL,GAAG;IACH,GAAG,OAAO,OAAO,MAAM,KAAK;GAC7B,EAAE,OAAO,MAAM;AACjC,QAAM,aACF,IAAI,IAAkB,SAAS,IAAI,CAAC,SAAS,CAAC,KAAK,MAAM,IAAI,CAAC,CAAC;AAEnE,QAAM,WAAmC,CAAA;AACzC,aAAW,QAAQ,UAAU;AAC3B,aAAS,KAAK,IAAI,IAAI,SAAS,KAAK,IAAI,KAAK;AAC7C,eAAW,SAAS,KAAK,UAAU;AAGjC,UAAI,CAAC,OAAO,KAAK,GAAG;AAClB,iBAAS,MAAM,IAAI,IAAI,OAAO;;AAEhC,eAAS,MAAM,IAAI,KAAK,SAAS,MAAM,IAAI,KAAK,KAAK;;;AAMzD,QAAM,WAAW,OAAO,QAAQ,QAAQ,EAClB,OAAO,CAAC,CAAC,EAAE,OAAO,MAAM,YAAY,CAAC,EACrC,IAAI,CAAC,CAAC,IAAI,MAAM,IAAI;AAC1C,QAAM,mBAAmB,CAAC,GAAG,QAAQ;AACrC,SAAO,SAAS,SAAS,GAAG;AAC1B,UAAM,WAAW,SAAS,IAAG;AAC7B,UAAM,OAAO,WAAW,IAAI,QAAQ;AACpC,eAAW,SAAS,KAAK,SAAS,OAAO,MAAM,GAAG;AAChD,UAAI,EAAE,SAAS,MAAM,IAAI,MAAM,GAAG;AAChC,yBAAiB,KAAK,MAAM,IAAI;AAChC,iBAAS,KAAK,MAAM,IAAI;;;;AAK9B,QAAM,eAAe,iBAAiB,IAAI,CAAC,SAAS,WAAW,IAAI,IAAI,CAAC;AACxE,QAAM,uBACF,+BAA+B,cAAc,eAAe;AAGhE,8BAA4B,sBAAsB,eAAe;AAEjE,SAAO;AACT;AAgBA,SAAS,+BACL,cAAsB,iBAAuB;AAC/C,QAAM,aACF,IAAI,IAAkB,aAAa,IAAI,CAAC,SAAS,CAAC,KAAK,MAAM,IAAI,CAAC,CAAC;AAGvE,QAAMC,SAAQ,gBAAgB,IAAI,CAAC,SAAS,KAAK,IAAI;AACrD,QAAM,+BAA+B,IAAI,IAAIA,MAAK;AAGlD,SAAOA,OAAM,SAAS,GAAG;AACvB,UAAM,WAAWA,OAAM,IAAG;AAC1B,UAAM,OAAO,WAAW,IAAI,QAAQ;AACpC,eAAW,SAAS,KAAK,UAAU;AACjC,UAAI,CAAC,WAAW,IAAI,MAAM,IAAI,KAC1B,6BAA6B,IAAI,MAAM,IAAI,GAAG;AAChD;;AAEF,mCAA6B,IAAI,MAAM,IAAI;AAC3C,MAAAA,OAAM,KAAK,MAAM,IAAI;;;AAKzB,QAAM,uBAAuB,aAAa,OACtC,CAAC,SAAS,6BAA6B,IAAI,KAAK,IAAI,CAAC;AAEzD,SAAO;AACT;AAiBA,SAAS,4BACL,cAAsB,iBAAuB;AAC/C,QAAM,kBAAkB,IAAI,IACxB,aAAa,IAAI,CAAC,MAAM,UAAU,CAAC,KAAK,MAAM,KAAK,CAAC,CAAC;AACzD,QAAM,sBAAsB,IAAI,IAAI,gBAAgB,IAAI,CAAC,SAAS,KAAK,IAAI,CAAC;AAC5E,QAAM,eAAe,CAAC,SAClB,oBAAoB,IAAI,OAAO,SAAS,WAAW,OAAO,KAAK,IAAI;AACvE,QAAM,0BACF,IAAI,IAAI,aAAa,IAAI,CAAC,SAAS,KAAK,IAAI,CAAC;AACjD,QAAM,iBAAiB,CAAC,SACpB,wBAAwB,IAAI,OAAO,SAAS,WAAW,OAAO,KAAK,IAAI;AAE3E,aAAW,QAAQ,cAAc;AAC/B,eAAW,SAAS,KAAK,SAAS,OAAO,cAAc,GAAG;AACxD,UAAI,CAAC,gBAAgB,IAAI,MAAM,IAAI,GAAG;AACpC,cAAM,IAAI,yBACN,SAAS,MAAM,IAAI,YAAY,KAAK,IAAI,kBAAkB;;AAEhE,UAAI,gBAAgB,IAAI,KAAK,IAAI,IAAI,gBAAgB,IAAI,MAAM,IAAI,GAAG;AACpE,cAAM,IAAI,yBAAyB,QAC/B,KAAK,IAAI,wCAAwC,MAAM,IAAI,GAAG;;;AAGtE,QAAI,CAAC,aAAa,IAAI,GAAG;AACvB,iBAAW,SAAS,KAAK,QAAQ;AAC/B,YAAI,CAAC,gBAAgB,IAAI,MAAM,IAAI,GAAG;AACpC,gBAAM,IAAI,yBACN,SAAS,MAAM,IAAI,YAAY,KAAK,IAAI,kBAAkB;;AAEhE,YAAI,gBAAgB,IAAI,MAAM,IAAI,IAAI,gBAAgB,IAAI,KAAK,IAAI,GAAG;AACpE,gBAAM,IAAI,yBAAyB,QAC/B,KAAK,IAAI,yCAAyC,MAAM,IAAI,GAAG;;;;;AAK7E;AAWM,SAAU,oBAAoB,cAAoB;AACtD,QAAM,kBAAkB,IAAI,IACxB,aAAa,IAAI,CAAC,MAAM,UAAU,CAAC,KAAK,MAAM,KAAK,CAAC,CAAC;AAEzD,QAAM,WAAW,OAAO;AAGxB,QAAM,gBAAgB,aAAa,IAC/B,CAAC,MAAM,cAAc,cAAc,IAAI,IAAI,WAAW,SAAS;AACnE,QAAM,kBAAkB,CAAC,SAAc;AACrC,UAAM,WAAW,cAAc,gBAAgB,IAAI,KAAK,IAAI,CAAE;AAC9D,QAAI,YAAY,MAAM;AAGpB,aAAO;;AAET,WAAO;EACT;AAQA,QAAM,kBAAkB,aAAa,IAAI,CAAC,MAAM,cAAa;AAC3D,WAAO,KAAK,SAAS,IAAI,eAAe,EACnC,OAAO,CAAC,GAAG,MAAM,KAAK,IAAI,GAAG,CAAC,GAAG,cAAc,SAAS,CAAC;EAChE,CAAC;AAMD,QAAM,eAAe,oBAAI,IAAG;AAC5B,WAAS,YAAY,GAAG,YAAY,aAAa,QAAQ,EAAE,WAAW;AACpE,UAAM,iBAAiB,gBAAgB,SAAS;AAChD,QAAI,mBAAmB,UAAU;AAC/B;;AAEF,UAAM,OAAO,aAAa,SAAS;AACnC,UAAM,gBAAgB,aAAa,cAAc;AACjD,QAAI,CAAC,aAAa,IAAI,cAAc,IAAI,GAAG;AACzC,mBAAa,IAAI,cAAc,MAAM,CAAA,CAAE;;AAEzC,iBAAa,IAAI,cAAc,IAAI,EAAG,KAAK,IAAI;;AAEjD,SAAO;AACT;AAcM,SAAU,cAAc,MAAU;AACtC,SAAO,iBAAiB,IAAI,KAAK,EAAE;AACrC;AAEM,SAAU,eAAe,MAAU;AACvC,SAAO,kBAAkB,IAAI,KAAK,EAAE;AACtC;AAEM,SAAU,YAAY,MAAU;AACpC,SAAO,eAAe,IAAI,KAAK,EAAE;AACnC;AA1VA,IAoNM,0BAgHA,kBAIA,mBAGA;AA3UN;;AAoBA;AAgMA,IAAM,2BAAN,cAAuC,MAAK;MAC1C,YAAY,SAAe;AACzB,cAAM,6BAA6B,OAAO,EAAE;MAC9C;;AA6GF,IAAM,mBAAmB,oBAAI,IAAI;MAC/B;MAAU;MAAS;MAAS;MAAQ;MAAiB;MACrD;MAAkB;MAAM;KACzB;AACD,IAAM,oBAAoB,oBAAI,IAAI;MAChC;MAAuB;MAAuB;MAAuB;KACtE;AACD,IAAM,iBAAiB,oBAAI,IAAI;MAC7B;MAAa;MAAe;MAAqB;MACjD;MAAmB;MAAqB;MAAmB;KAC5D;;;;;AC9UD,IAmCa;AAnCb,IAAAC,uBAAA;;AAiBA;AAIA;AACA;AAGA;AACA;AASM,IAAO,gBAAP,MAAO,eAAa;MAgBxB,IAAI,YAAS;AACX,eAAO,KAAK,SAAS,KAAK,OAAO,YAAY,KAAK;MACpD;MAEA,IAAI,sBAAmB;AACrB,eAAO,KAAK,SAAS,KAAK,OAAO,sBACZ,KAAK;MAC5B;MAEA,IAAI,YAAS;AACX,eAAO,KAAK,SAAS,KAAK,OAAO,YAAY,KAAK;MACpD;MAEA,IAAI,UAAU,WAA0B;AACtC,cAAM,YAAY,OAAO,KAAK,SAAS,EAAE,IACrC,SAAO,UAAU,GAAG,EAAE,IAAI,CAAAC,YAAUA,QAAO,EAAE,CAAC;AAClD,aAAK,aAAa,CAAA,EAAG,OAAO,GAAG,SAAS;AACxC,aAAK,aAAa;MACpB;;;;;MAMA,IAAI,gBAAgB,iBAAgC;AAClD,aAAK,mBAAmB;MAC1B;MAEA,IAAI,SAAM;AACR,eAAO,KAAK,QAAQ,IAAI,UAAO;AAC7B,iBAAO;YACL,MAAM,KAAK;YACX,OAAO,KAAK,WAAW,OAAO,IAC1B,KAAK,WAAW,OAAO,EAAE,QACzB;YACJ,OAAO,KAAK,WAAW,OAAO,IAC1B,KAAK,WAAW,OAAO,EAAE,QACzB;;QAER,CAAC;MACH;MAEA,IAAI,UAAO;AACT,eAAO,KAAK,SAAS,IAAI,UAAO;AAC9B,iBAAO;YACL,MAAM,KAAK;YACX,OAAO,KAAK,WAAW,OAAO,IAC1B,KAAK,WAAW,OAAO,EAAE,QACzB;YACJ,OAAO,KAAK,WAAW,OAAO,IAC1B,KAAK,WAAW,OAAO,EAAE,QACzB;;QAER,CAAC;MACH;MAEA,IAAI,aAAU;AACZ,eAAO,KAAK,QAAQ,IAAI,UAAQ,KAAK,gBAAgB,KAAK,IAAI;MAChE;MAEA,IAAI,cAAW;AACb,eAAO,KAAK,SAAS,IAAI,CAAC,SAAQ;AAChC,gBAAM,OAAO,KAAK,gBAAgB,KAAK;AACvC,iBAAO,KAAK,gBAAiB,GAAG,IAAI,IAAI,KAAK,aAAa,KAAM;QAClE,CAAC;MACH;MAEA,IAAI,YAAS;AACX,eAAO,OAAO,KAAK,KAAK,UAAU,EAAE,OAAO,CAAC,KAAK,QAAO;AACtD,cAAI,GAAG,IAAI,KAAK,WAAW,GAAG,EAAE;AAChC,iBAAO;QACT,GAAG,CAAA,CAAoC;MACzC;;;;;;;;;MAUA,YAAoB,OAAsB,QAAsB;AAA5C,aAAA,QAAA;AAAsB,aAAA,SAAA;AAjGlC,aAAA,cAAc,oBAAI,IAAG;AACrB,aAAA,qBAAqB,oBAAI,IAAG;AAC5B,aAAA,aAA8B,CAAA;AAM9B,aAAA,YAAY;AACZ,aAAA,aAAqC,CAAA;AACrC,aAAA,uBAA0D,CAAA;AAG1D,aAAA,0BAA0B;AAqFhC,aAAK,WAAW,MAAM;AACtB,aAAK,UAAU,MAAM;AACrB,aAAK,aAAa,MAAM;AACxB,aAAK,aAAa,MAAM;AACxB,aAAK,aAAa,MAAM;AAExB,YAAI,MAAM,aAAa,MAAM;AAC3B,iBAAO,KAAK,MAAM,SAAS,EAAE,QAAQ,UAAO;AAC1C,iBAAK,qBAAqB,IAAI,IAC1B,IAAI,eAAc,MAAM,UAAU,IAAI,GAAG,IAAI;UACnD,CAAC;;MAEL;MAEQ,kBAAkB,QAAgB,SAAe;AACvD,cAAM,eAAe,OAAO,IAAI,UAAQ,KAAK,IAAI,EAAE,KAAI;AACvD,cAAM,gBAAgB,QAAQ,IAAI,UAAQ,KAAK,IAAI,EAAE,KAAI;AACzD,eAAO,aAAa,KAAK,KAAK,SAAS,IAAI,OACvC,cAAc,KAAK,KAAK,SAAS;MACvC;;;;;;;;;;;;MAaQ,QAAQ,QAAwB,SAAe;AAErD,cAAM,gBACF,qBAAqB,QAAQ,SAAS,KAAK,WAAW,KAAK,UAAU;AACzE,cAAM,EAAC,eAAe,aAAa,WAAU,IAAI;AACjD,YAAI,eAAe,MAAM;AACvB,gBAAM,IAAI,MACN,qCAAqC,YAAY,IAAI,gCAClC,YAAY,EAAE,4GAEG,UAAU,GAAG;;AAGvD,YAAI,cAAc,SAAS,GAAG;AAC5B,gBAAM,WAAW,QAAQ,IAAI,OAAK,EAAE,IAAI;AACxC,gBAAM,UAAU,OAAO,KAAK,MAAM;AAClC,gBAAM,IAAI,MACN,+BAA+B,QAAQ,+BACnC,OAAO,qCAAqC,aAAa,GAAG;;AAGtE,cAAM,eAAe,2BAA2B,KAAK,OAAO,aAAa;AACzE,cAAM,mBAAmB,oBAAoB,YAAY;AACzD,eAAO,EAAC,cAAc,iBAAgB;MACxC;MAEQ,mBAAmBA,SAAc;AACvC,YAAIA,WAAU,MAAM;AAClB,iBAAO;;AAET,cAAMC,SAAQD,QAAO,MAAK;AAI1B,aAAKC,MAAK;AACV,eAAOA;MACT;MAEQ,gBAAgB,SAAiB;AACvC,YAAI,CAAC,SAAS;AACZ,iBAAO;;AAET,cAAM,eAAe,QAAQ,IAAI,CAAAD,YAAS;AACxC,iBAAO,KAAK,mBAAmBA,OAAM;QACvC,CAAC;AACD,eAAO;MACT;MAEQ,eAAe,YAA2B;AAChD,eAAO,OAAO,YACV,OAAO,QAAQ,UAAU,EAAE,IAAI,CAAC,CAAC,MAAM,WAAW,MAAK;AACrD,iBAAO,CAAC,MAAM,KAAK,gBAAgB,WAAW,CAAC;QACjD,CAAC,CAAC;MACR;;;;;;;;;;MAWA,QAAQ,QAAwB,SAAkB;AAEhD,aAAK,2BAA0B;AAC/B,iBAAS,KAAK,UAAU,MAAM;AAC9B,cAAM,QAAQ,OAAO,KAAK,MAAM,EAAE,KAAI;AACtC,aAAK,YAAY,MAAM;AACvB,aAAK,uBAAuB,MAAM;AAClC,kBAAU,KAAK,WAAW,OAAO;AACjC,aAAK,aAAa,OAAO;AACzB,cAAM,aACF,MAAM,IAAI,UAAQ,KAAK,MAAM,MAAM,cAAc,IAAI,EAAE,CAAC,CAAC,CAAC;AAC9D,cAAM,kBAAkB,QAAQ,IAAI,UAAQ,cAAc,IAAI,EAAE,CAAC,CAAC;AAClE,cAAM,oBAAoB,IAAI,IAAI,eAAe;AACjD,YAAI,cAAc,gBAAgB,IAAI,UAAQ,KAAK,MAAM,MAAM,IAAI,CAAC;AAEpE,YAAI,YAAY,WAAW,GAAG;AAC5B,wBAAc,KAAK;;AAGrB,cAAM,iBAAiB,KAAK,kBAAkB,YAAY,WAAW;AAGrE,YAAI,cAAc,KAAK,YAAY,IAAI,cAAc;AACrD,YAAI,eAAe,MAAM;AACvB,wBAAc,KAAK,QAAQ,QAAQ,WAAW;AAC9C,eAAK,YAAY,IAAI,gBAAgB,WAAW;;AAIlD,YAAI;AACF,eAAK,0BAA0B,IAAG,EAAG,QAAQ,2BAA2B;iBACjE,GAAG;AACV,eAAK,0BAA0B;AAC/B,kBAAQ,KAAK,EAAE,OAAO;;AAExB,cAAM,iBAAiC,CAAA;AACvC,cAAM,gBAA+B,CAAA;AAErC,eAAO,KAAK,MAAK;AACf,gBAAM,UAAU,IAAI,iBAChB,KAAK,WAAW,gBAAgB,eAChC,KAAK,qBAAqB,KAAK,kBAAkB;AACrD,gBAAM,aAAU,OAAA,OAAA,CAAA,GAAwB,KAAK,SAAS;AACtD,cAAI,KAAK,yBAAyB;AAChC,iBAAK,mBAAmB,KAAK,eAAe,KAAK,SAAS;;AAG5D,iBAAO,KAAK,MAAM,EAAE,QAAQ,UAAO;AACjC,kBAAM,CAAC,UAAU,KAAK,IAAI,cAAc,MAAM,OAAO;AACrD,kBAAM,UAAoB,CAAA;AAC1B,oBAAQ,KAAK,IAAI,OAAO,IAAI;AAC5B,uBAAW,QAAQ,IAAI;AACvB,gBAAI,KAAK,yBAAyB;AAChC,mBAAK,iBAAiB,QAAQ,IAAI,KAAK,gBAAgB,OAAO;;UAElE,CAAC;AAED,gBAAM,gBAAgB,KAAK,mBAAmB,UAAU;AACxD,gBAAM,EAAC,cAAc,iBAAgB,IAAI;AACzC,qBAAW,QAAQ,cAAc;AAC/B,gBAAI,WAAW,KAAK,IAAI,GAAG;AACzB;;AAEF,kBAAM,UACFE,YAAU,MAAM,YAAY,SAAS,KAAK,gBAAgB;AAE9D,gBAAI,aAAK,UAAU,OAAO,GAAG;AAC3B,oBAAM,IAAI,MACN,4BAA4B,KAAK,EAAE,gEACO;;AAEhD,uBAAW,KAAK,IAAI,IAAI;AACxB,gBAAI,KAAK,yBAAyB;AAChC,mBAAK,iBAAiB,KAAK,IAAI,IAAI,KAAK,gBAAgB,OAAO;;AAEjE,iBAAK,4CACD,MAAM,YAAY,SAAS,eAAe,mBAC1C,iBAAiB,IAAI,KAAK,IAAI,CAAC;;AAIrC,cAAI,KAAK,UAAU,MAAM;AACvB,oBAAQ,QAAQ,aAAa;;AAG/B,iBAAO,QAAQ,IAAI,UAAQ,UAAU,MAAM,YAAY,OAAO,CAAC;QACjE,CAAC;MACH;MAEQ,mBAAmB,WAA0B;AACnD,cAAM,MAAM,CAAA,EAAG,OAAO,MAClB,CAAA,GACA,OAAO,KAAK,SAAS,EAChB,IAAI,SAAO,UAAU,GAAG,CAAC,EACzB,IAAI,aAAW,QAAQ,IAAI,CAAAF,YAAUA,QAAO,EAAE,CAAC,CAAC;AACzD,eAAO,IAAI,IAAI,GAAG;MACpB;MAEQ,uBACJ,UAAkB,MAAY,WAC9B,SAA2B,eAC3B,mBACA,iCAAwD;AAG1D,YAAI,cAAc,IAAI,KAAK,kBAAkB,IAAI,QAAQ,GAAG;AAC1D;;AAGF,mBAAWA,WAAU,UAAU,QAAQ,GAAG;AACxC,cAAIA,WAAU,MAAM;AAClB;;AAEF,0CAAgCA,QAAO,EAAE,KACpC,gCAAgCA,QAAO,EAAE,KAAK,KAC/C,KAAK,SAAS;;AAGpB,mBAAW,SAAS,KAAK,QAAQ;AAG/B,cAAI,cAAc,KAAK,GAAG;AACxB;;AAGF,gBAAM,UACF,4BAA4B,MAAM,MAAM,WAAW,OAAO;AAC9D,cAAI,WAAW,MAAM;AACnB;;AAGF,qBAAWA,WAAU,SAAS;AAC5B,gBAAI,CAACA,WAAUA,QAAO,QAAQ,cAAc,IAAIA,QAAO,EAAE,GAAG;AAC1D;;AAOF,kBAAM,QAAQ,gCAAgCA,QAAO,EAAE;AACvD,gBAAI,UAAU,GAAG;AACf,cAAAA,QAAO,QAAO;AACd,qBAAO,gCAAgCA,QAAO,EAAE;uBACvC,SAAS,MAAM;AACxB,8CAAgCA,QAAO,EAAE;;;;MAIjD;MAEQ,4CACJ,MAAY,WAA4B,SACxC,eAA4B,mBAC5B,gBAAuB;AACzB,iBAAS,oBAAoBG,OAAU;AAGrC,iBAAO,cAAcA,KAAI,KAAK,kBAAkB,IAAIA,MAAK,IAAI;QAC/D;AAEA,YAAI,cAAc,IAAI,KAAK,kBAAkB,MAAM;AACjD;;AAGF,mBAAW,iBAAiB,gBAAgB;AAC1C,cAAI,oBAAoB,aAAa,GAAG;AACtC;;AAEF,gBAAM,UAAU,4BACZ,cAAc,MAAM,WAAW,OAAO;AAC1C,qBAAWH,WAAU,SAAS;AAC5B,gBAAI,CAACA,WAAUA,QAAO,QAAQ,cAAc,IAAIA,QAAO,EAAE,GAAG;AAC1D;;AAEF,YAAAA,QAAO,QAAO;;;MAGpB;;;;;;;;;;MAWA,MAAM,aAAa,QAAwB,SAAkB;AAE3D,eAAO,KAAK,cAAc,QAAQ,OAAO;MAC3C;MAEA,6BAA0B;AACxB,YAAI,CAAC,KAAK,kBAAkB;AAC1B;;AAEF,eAAO,OAAO,KAAK,gBAAgB,EAAE,QAAQ,iBAAc;AACzD,qBAAWA,WAAU,aAAa;AAChC,gBAAIA,WAAU,CAACA,QAAO,YAAY;AAChC,cAAAA,QAAO,QAAO;;;QAGpB,CAAC;AAED,aAAK,mBAAmB;MAC1B;MAEA,yBAAsB;AACpB,eAAO,KAAK;MACd;;;;;;;;;;;;;;;MAgBQ,MAAM,cACV,QAAwB,SAAoB,sBAAsB,OAClE,iBAAiC,CAAA,GACjC,gBAA+B,CAAA,GAAE;AAEnC,aAAK,2BAA0B;AAC/B,YAAI,CAAC,qBAAqB;AACxB,mBAAS,KAAK,UAAU,MAAM;AAC9B,eAAK,YAAY,MAAM;AACvB,eAAK,uBAAuB,MAAM;AAClC,oBAAU,KAAK,WAAW,OAAO;AACjC,eAAK,aAAa,OAAO;;AAI3B,YAAI;AACF,eAAK,0BAA0B,IAAG,EAAG,QAAQ,2BAA2B;iBACjE,GAAG;AACV,eAAK,0BAA0B;AAC/B,kBAAQ,KAAK,EAAE,OAAO;;AAGxB,cAAM,UAAU,IAAI,iBAChB,KAAK,WAAW,gBAAgB,eAAe,KAAK,qBACpD,KAAK,kBAAkB;AAE3B,YAAI,KAAK,yBAAyB;AAChC,eAAK,mBAAmB,KAAK,eAAe,KAAK,SAAS;;AAM5D,cAAM,aAAa,MAAM,KAAK,uBAC1B,QAAQ,SAAS,SAAS,mBAAmB;AACjD,cAAM,UAAU,QAAQ,IAAI,UAAQ,UAAU,MAAM,YAAY,OAAO,CAAC;AAGxE,cAAM,YAAY,QAAQ,IAAI,OAAK,EAAE,EAAE;AACvC,cAAM,WAAW,OAAO,KAAK,MAAM,EAAE,IAAI,UAAQ,OAAO,IAAI,EAAE,EAAE;AAChE,cAAM,UACF,oBAAI,IAAY,CAAC,GAAG,WAAW,GAAG,UAAU,GAAG,KAAK,SAAS,CAAC;AAElE,eAAO,OAAO,UAAU,EAAE,QAAQ,iBAAc;AAC9C,sBAAY,QAAQ,CAAAA,YAAS;AAC3B,gBAAIA,WAAU,CAACA,QAAO,cAAc,CAAC,QAAQ,IAAIA,QAAO,EAAE,GAAG;AAC3D,cAAAA,QAAO,QAAO;;UAElB,CAAC;QACH,CAAC;AAGD,YAAI,KAAK,UAAU,MAAM;AACvB,kBAAQ,QAAQ,OAAO;;AAGzB,eAAO;MACT;MAEA,MAAM,qBACF,QAAkB,gBAClB,eAA4B;AAC9B,cAAM,eAAe,OAAO,OAAO,CAAC,KAAKA,SAAQ,UAAS;AACxD,cAAI,KAAK,OAAO,KAAK,EAAE,IAAI,IAAIA;AAC/B,iBAAO;QACT,GAAG,CAAA,CAAoB;AAEvB,eAAO,KAAK,cACR,cAAc,KAAK,aAAa,MAAM,gBAAgB,aAAa;MACzE;;;;;;;;;;;;MAaQ,MAAM,uBACV,QAAwB,SAA2B,aACnD,qBAA6B;AAC/B,cAAM,QAAQ,OAAO,KAAK,MAAM;AAChC,cAAM,aACF,MAAM,IAAI,UAAQ,KAAK,MAAM,MAAM,cAAc,IAAI,EAAE,CAAC,CAAC,CAAC;AAC9D,cAAM,kBAAkB,YAAY,IAAI,UAAQ,cAAc,IAAI,EAAE,CAAC,CAAC;AACtE,cAAM,oBAAoB,IAAI,IAAI,eAAe;AACjD,YAAI,cAAc,gBAAgB,IAAI,UAAQ,KAAK,MAAM,MAAM,IAAI,CAAC;AAGpE,YAAI,YAAY,WAAW,GAAG;AAC5B,wBAAc,KAAK;;AAGrB,cAAM,EAAC,WAAW,eAAe,aAAa,WAAU,IACpD,qBACI,QAAQ,aAAa,KAAK,WAAW,KAAK,UAAU;AAG5D,cAAMI,SAA4B;UAChC,GAAG;UAAY,GAAG,KAAK,MAAM;UAAS,GAAI,KAAK,cAAc,CAAA;UAC7D,IAAI,UAAO;AACX,iBAAO,EAAC,MAAM,UAAU,QAAQ,eAAc;QAChD,CAAC;AACD,cAAM,aAAU,OAAA,OAAA,CAAA,GAAwB,KAAK,SAAS;AACtD,eAAO,KAAK,MAAM,EAAE,QAAQ,UAAO;AACjC,gBAAM,CAAC,UAAU,KAAK,IAAI,cAAc,IAAI;AAC5C,gBAAM,UAAoB,CAAA;AAC1B,kBAAQ,KAAK,IAAI,OAAO,IAAI;AAC5B,qBAAW,QAAQ,IAAI;QACzB,CAAC;AACD,cAAM,kCAA2D,CAAA;AACjE,cAAM,gBAAgB,KAAK,mBAAmB,UAAU;AACxD,cAAM,QAAkC,CAAA;AACxC,eAAOA,OAAM,SAAS,GAAG;AACvB,gBAAM,WAAW,KAAK,aAClB,YAAYA,QAAO,SAAS,YAAY,OAAO,eAC/C,mBAAmB,iCAAiC,SAAS;AACjE,gBAAM,QAAQ,IAAI,QAAQ;;AAE5B,YAAI,eAAe,QAAQ,CAAC,qBAAqB;AAC/C,kBAAQ,KACJ,iIACgE;;AAEtE,cAAM,iBACF,YACK,OACG,UAAQ,CAAC,cAAc,IAAI,KACvB,CAAC,UAAU,KAAK,MAAM,YAAY,OAAO,CAAC,EACjD,IAAI,UAAQ,KAAK,IAAI;AAC9B,YAAI,eAAe,SAAS,GAAG;AAC7B,cAAI,iBAAiB;AACrB,cAAI,eAAe,MAAM;AACvB,6BACI,wFAC2B,UAAU;;AAE3C,gBAAM,IAAI,MACN,+BAA+B,cAAc,+BAClC,KAAK,gDACZ,aAAa,MAAM,cAAc,EAAE;;AAE7C,eAAO;MACT;MAEQ,aACJ,YAAoBA,QAA2B,SAC/C,WAA4B,OAC5B,eAA4B,mBAC5B,iCACA,WAAsB;AACxB,cAAM,WAAqC,CAAA;AAC3C,eAAOA,OAAM,SAAS,GAAG;AACvB,gBAAM,OAAOA,OAAM,IAAG;AACtB,kBAAQ,iBAAiB,KAAK;AAC9B,cAAI,WAAW;AAIf,cAAI,KAAK,KAAK,OAAO,WACjB,cAAc,cAAc,KAAK,MAAM,WAAW,OAAO,GAAG;AAC9D,aAAC,QAAQ,IAAI,oBAAoB,KAAK,KAAK,MAAM,OAAO;;AAK1D,cAAI,UAAU,KAAK,KAAK,IAAI,KAAK,MAAM;AACrC,kBAAM,UACFF,YAAU,KAAK,MAAM,WAAW,SAAS,KAAK,gBAAgB;AAClE,gBAAI,CAAC,UAAU;AACb,eAAC,QAAQ,IAAI,oBAAoB,KAAK,KAAK,MAAM,OAAO;;AAE1D,kBAAM,iBAAiB,QAAQ;AAC/B,gBAAI,aAAK,UAAU,OAAO,GAAG;AAC3B,uBAAS,KAAK,QAAQ,KAAK,OAAI;AAC7B,0BAAU,QAAQ,IAAI;AACtB,oBAAI,KAAK,yBAAyB;AAChC,uBAAK,iBAAiB,QAAQ,IAAI,KAAK,gBAAgB,CAAC;;AAE1D,wBAAQ,iBAAiB;AACzB,qBAAK,uBACD,UAAU,KAAK,MAAM,WAAW,SAAS,eACzC,mBAAmB,+BAA+B;AACtD,qBAAK,kBACD,KAAK,MAAME,QAAO,SAAS,WAAW,OAAO,SAAS;AAC1D,uBAAO;cACT,CAAC,CAAC;mBACG;AACL,wBAAU,QAAQ,IAAI;AACtB,kBAAI,KAAK,yBAAyB;AAChC,qBAAK,iBAAiB,QAAQ,IAAI,KAAK,gBAAgB,OAAO;;AAEhE,mBAAK,uBACD,UAAU,KAAK,MAAM,WAAW,SAAS,eACzC,mBAAmB,+BAA+B;AACtD,mBAAK,kBACD,KAAK,MAAMA,QAAO,SAAS,WAAW,OAAO,SAAS;;iBAEvD;AACL,iBAAK,kBACD,KAAK,MAAMA,QAAO,SAAS,WAAW,OAAO,SAAS;;;AAG9D,eAAO;MACT;MAEQ,kBACJ,MAAYA,QAA2B,SACvC,WAA4B,OAC5B,WAAsB;AACxB,aAAK,SAAS,QAAQ,CAAC,cAAa;AAClC,gBAAM,CAAC,QAAQ,IAAM,oBAAoB,UAAU,MAAM,OAAO;AAChE,cAAI,MAAM,QAAQ,KAAK,CAAC,UAAU,IAAI,UAAU,IAAI,GAAG;AACrD;;AAGF,cAAI,UAAU,OAAO,SAAS;AAC5B,gBAAI,UAAU,WAAW,KAAK,UAAO;AAC/B,qBAAO,CAAC,CAAC,UAAU,MAAM,WAAW,OAAO;YAC7C,CAAC,GAAG;AACN,oBAAM,QAAQ,IAAI;AAClB,cAAAA,OAAM,KAAK,EAAC,UAAU,QAAQ,gBAAgB,MAAM,UAAS,CAAC;;qBAG1D,UAAU,WAAW,MAAM,UAAO;AAChC,mBAAO,CAAC,CAAC,UAAU,MAAM,WAAW,OAAO;UAC7C,CAAC,GAAG;AACV,kBAAM,QAAQ,IAAI;AAClB,YAAAA,OAAM,KAAK,EAAC,UAAU,QAAQ,gBAAgB,MAAM,UAAS,CAAC;;QAElE,CAAC;MACH;;;;MAKA,UAAO;AACL,eAAO,KAAK,KAAK,SAAS,EACrB,QACG,SAAO,KAAK,UAAU,GAAG,EAAE,QAAQ,CAAAJ,YAAUA,QAAO,QAAO,CAAE,CAAC;MACxE;MAEQ,uBAAuB,QAAsB;AACnD,eAAO,KAAK,MAAM,EAAE,QAAQ,UAAO;AACjC,gBAAM,QAAQ,OAAO,IAAI;AACzB,gBAAM,CAAC,QAAQ,IAAM,cAAc,IAAI;AACvC,gBAAM,OAAO,KAAK,MAAM,MAAM,QAAQ;AACtC,cAAI,KAAK,WAAW,OAAO,KAAK,KAAK,WAAW,OAAO,EAAE,OAAO;AAC9D,kBAAM,QAAQ,KAAK,WAAW,OAAO,EAAE;AACvC,kBAAM,QAAQ,MAAM,WAAW,MAAM,MAAM,UACvC,MAAM,MAAM,MACR,CAAC,KAAK,UAAU,MAAM,KAAK,MAAM,MAAM,MAAM,KAAK,MAAM,GAAG;AACnE,yBAAK,OACD,OACA,MAAM,sBAAsB,KAAK,IAAI,+CACD,KAAK,eACjC,MAAM,KAAK,GAAG;;AAE5B,cAAI,KAAK,WAAW,OAAO,KAAK,KAAK,WAAW,OAAO,EAAE,OAAO;AAC9D,yBAAK,OACD,MAAM,UAAU,KAAK,WAAW,OAAO,EAAE,OACzC,MAAM,sBAAsB,KAAK,IAAI,8CAE9B,KAAK,WAAW,OAAO,EAAE,KAAK,aAAa,MAAM,KAAK,EAAE;;QAEvE,CAAC;MACH;MAEQ,UAAU,QAAsB;;AACtC,cAAM,SAAyB,CAAA;AAC/B,mBAAW,aAAa,QAAQ;AAC9B,gBAAMA,WAAS,MAAA,KAAA,KAAK,gBAAU,QAAA,OAAA,SAAA,SAAA,GAAG,YAAM,QAAA,OAAA,SAAA,SAAA,GAAI,SAAS;AACpD,cAAIA,WAAU,MAAM;AAClB,mBAAOA,QAAO,IAAI,IAAI,OAAO,SAAS;iBACjC;AACL,mBAAO,SAAS,IAAI,OAAO,SAAS;;;AAGxC,eAAO;MACT;MAEQ,YAAY,QAAsB;AACxC,cAAM,aAAa,OAAO,KAAK,MAAM,EAAE,OAAO,UAAO;AACnD,gBAAM,CAAC,QAAQ,IAAI,cAAc,IAAI;AACrC,iBAAO,KAAK,MAAM,MAAM,QAAQ,KAAK;QACvC,CAAC;AACD,YAAI,WAAW,SAAS,GAAG;AACzB,gBAAM,IAAI,MACN,uDACU,UAAU,8BAA8B;;MAE1D;MAEQ,WAAW,SAAiB;AAClC,eAAO,QAAQ,IAAI,UAAO;;AACxB,gBAAMA,WAAS,MAAA,KAAA,KAAK,gBAAU,QAAA,OAAA,SAAA,SAAA,GAAG,aAAO,QAAA,OAAA,SAAA,SAAA,GAAI,IAAI;AAChD,cAAIA,WAAU,MAAM;AAClB,mBAAOA,QAAO;;AAEhB,iBAAO;QACT,GAAG,CAAA,CAAE;MACP;MAEQ,aAAa,SAAiB;AACpC,gBAAQ,QAAQ,UAAO;AACrB,gBAAM,CAAC,cAAc,IAAI,cAAc,IAAI;AAC3C,cAAI,CAAC,KAAK,MAAM,MAAM,cAAc,GAAG;AACrC,kBAAM,IAAI,MAAM,eAAe,IAAI,6BAA6B;;QAEpE,CAAC;MACH;;;;;;AChvBF,IAGa;AAHb;;AAGM,IAAO,kBAAP,MAAsB;MAC1B,YACa,wBAAwC,CAAA,GACxC,eAA6B,CAAA,GAAE;AAD/B,aAAA,wBAAA;AACA,aAAA,eAAA;MAAkC;;;;;;;;;;MAW/C,aAAa,MAAc,WAAoB;AAC7C,aAAK,sBAAsB,IAAI,IAAI,UAAU;AAC7C,aAAK,aAAa,UAAU,EAAE,IAAI;MACpC;;;;;;MAOA,yBAAyB,MAAY;AACnC,eAAO,KAAK,sBAAsB,IAAI;MACxC;;;;;MAMA,iBAAiB,IAAU;AACzB,eAAO,KAAK,aAAa,EAAE;MAC7B;;;;MAKA,UAAO;AACL,mBAAW,OAAO,KAAK,cAAc;AACnC,eAAK,aAAa,GAAG,EAAE,cAAa;AACpC,iBAAO,KAAK,aAAa,GAAG;;AAG9B,mBAAW,QAAQ,KAAK,uBAAuB;AAC7C,eAAK,sBAAsB,IAAI,EAAE,QAAO;AACxC,iBAAO,KAAK,sBAAsB,IAAI;;MAE1C;;;;;;ACwiBF,eAAsB,eAClB,UAA+B,UAA0B,CAAA,GACzD,OAAO,YAAE;AACX,MAAI,YAAY,MAAM;AACpB,UAAM,IAAI,MACN,wGACsC;;AAE5C,MAAI,WAAW,MAAM;AACnB,cAAU,CAAA;;AAGZ,MAAI,QAAQ,aAAa,OAAO,aAAa,UAAU;AACrD,eAAW,YAAY,QAAQ;;AAEjC,QAAM,QAAQ,IAAI,WAAW,UAAU,SAAS,IAAI;AACpD,QAAM,MAAM,KAAI;AAChB,SAAO;AACT;AAYM,SAAU,mBACZ,aAC2D;AAE7D,MAAI,eAAe,MAAM;AACvB,UAAM,IAAI,MACN,sHACsD;;AAG5D,MAAI;AACJ,MAAI,uBAAuB,OAAO;AAChC,UAAM,CAAC,WAAW,OAAO,IAAI;AAC7B,QAAI,CAAC,WAAW;AACd,YAAM,IAAI,MAAM,kDAAkD;;AAEpE,QAAI,CAAC,WAAW,EAAE,mBAAmB,cAAc;AACjD,YAAM,IAAI,MACN,mEACY;;AAElB,QAAI,EAAE,mBAAmB,YAAY;AACnC,YAAM,IAAI,MAAM,uCAAyC;;AAE3D,QAAI,EAAE,qBAAqB,YAAY;AACrC,YAAM,IAAI,MAAM,yCAA2C;;AAG7D,UAAM,cAAc,WAAG,eAAe,UAAU,eAAe;AAC/D,UAAM,iBACF,WAAG,6BAA6B,WAAW,aAAa,OAAO;AACnE,gBAAY,WAAG,eAAe,cAAc;aACnC,UAAU,aAAa;AAEhC,gBAAY;aAEV,mBAAmB,eAAe,iBAAiB,eACnD,gBAAgB,aAAa;AAE/B,gBAAY,WAAG,eAAe,WAAW;SACpC;AACL,UAAM,IAAI,MAAM,sBAAsB;;AAGxC,QAAM,QAAQ,IAAI,WAAW,SAAS;AACtC,QAAM,KAAI;AACV,SAAO;AACT;AAEA,SAAS,YAAY,UAAgB;AACnC,MAAI,CAAC,SAAS,SAAS,GAAG,GAAG;AAC3B,eAAY,WAAY;;AAE1B,SAAO,GAAG,QAAQ,GAAG,kBAAkB,GAAG,kBAAkB;AAC9D;AAnsBA,IA4Ba,oBACA,oBAcA;AA3Cb;;AAiBA;AAIA;AAEA,IAAAK;AACA;AAEA;AAEO,IAAM,qBAAqB;AAC3B,IAAM,qBAAqB;AAc5B,IAAO,aAAP,MAAiB;;MAerB,IAAI,eAAY;AACd,eAAO,KAAK;MACd;MAEA,IAAI,aAAU;AACZ,eAAO,KAAK,SAAS;MACvB;MAEA,IAAI,cAAW;AACb,eAAO,KAAK,SAAS;MACvB;MAEA,IAAI,SAAM;AACR,eAAO,KAAK,SAAS;MACvB;MAEA,IAAI,UAAO;AACT,eAAO,KAAK,SAAS;MACvB;MAEA,IAAI,UAAO;AACT,eAAO,KAAK,SAAS;MACvB;MAEA,IAAI,WAAQ;AACV,eAAO,KAAK,UAAU;MACxB;MAEA,IAAI,iBAAc;AAChB,eAAO,KAAK;MACd;MAEA,IAAI,4BAAyB;AAC3B,eAAO,KAAK;MACd;;;;;;;;;;MAWA,YACY,UAA4B,cAA8B,CAAA,GAClE,OAAO,YAAE;AADD,aAAA,WAAA;AAA4B,aAAA,cAAA;AA1DhC,aAAA,UAAU;AA4DhB,aAAK,KAAK;AACV,YAAI,eAAe,MAAM;AACvB,eAAK,cAAc,CAAA;;AAErB,aAAK,kBAAkB,IAAI,gBAAe;MAC5C;MAEQ,gBAAa;AAEnB,cAAM,OAAO,KAAK;AAClB,YAAK,KAAsB,QAAQ,MAAM;AAEvC,eAAK,UAAU;mBACN,KAAK,YAAY,eAAe,MAAM;AAC/C,eAAK,UAAU,KAAK,GAAG,mBACJ,MAAgB,KAAK,WAAW;eAC9C;AACL,gBAAM,WACF,KAAK,GAAG,gBAAgB,MAAgB,KAAK,WAAW;AAC5D,cAAI,SAAS,WAAW,GAAG;AAGzB,qBAAS,KACL,KAAK,GAAG,mBAAmB,MAAgB,KAAK,WAAW,CAAC;qBACvD,SAAS,SAAS,GAAG;AAC9B,kBAAM,IAAI,MACN,wBAAwB,SAAS,MAAM,4BAC/B,CAAC,IAAI,CAAC,GAAG;;AAEvB,eAAK,UAAU,SAAS,CAAC;;MAE7B;;;;;MAMA,OAAI;AAGF,aAAK,cAAa;AAClB,YAAI,KAAK,QAAQ,QAAQ,MAAM;AAC7B,gBAAM,IAAI,MACN,+GAC8C;;AAMpD,cAAM,aAAa,KAAK,QAAQ,KAAI;AACpC,YAAI,aAAK,UAAU,UAAU,GAAG;AAC9B,iBAAO,WAAW,KAAK,eAAY;AACjC,gBAAI,UAAU,mBAAmB,MAAM;AACrC,qBAAO,KAAK,SAAS,SAAS;;AAEhC,mBAAO,KAAK,cAAc,SAAS;UACrC,CAAC;;AAGH,eAAO,KAAK,SAAS,UAAU;MACjC;;;;;;;MAQA,SAAS,WAA4B;AACnC,cAAM,YAAY,KAAK,GAAG,cACtB,UAAU,YAAY,UAAU,WAAW;AAE/C,eAAO,KAAK,kBAAkB,WAAW,SAAS;MACpD;MAEQ,MAAM,cAAc,WAA4B;AACtD,YAAI,UAAU,mBAAmB,MAAM;AACrC,gBAAM,IAAI,MAAM,gDAAgD;;AAGlE,cAAM,YAAY,MAAM,oBACtB,UAAU,gBAAe,GAAI,UAAU,WAAW;AAEpD,eAAO,KAAK,kBAAkB,WAAW,SAAS;MACpD;MAEQ,kBAAkB,WACA,WAAyB;AACjD,aAAK,YAAY;AACjB,cAAM,QAAQ,KAAK,UAAU;AAE7B,YAAI,YAAY,KAAK,UAAU;AAC/B,YAAI,KAAK,UAAU,uBAAuB,MAAM;AAC9C,gBAAM,WAAW,KAAK,UAAU;AAChC,cAAI,SAAS,aAAa,MAAM;AAC9B,wBAAY,SAAS;;AAGvB,cAAI,SAAS,wBAAwB,MAAM;AACzC,iBAAK,uBAAuB,SAAS;;;AAGzC,aAAK,YAAY;AAEjB,aAAK,UAAU,GAAG,MAAM,SAAS,QAAQ,IAAI,MAAM,SAAS,WAAW;AACvE,aAAK,WAAW,IAAI,cAChB,gBAAgB,SAAS,eAAe,OAAO,KAAK,SAAS,CAAC;AAClE,aAAK,SAAS,YAAY,KAAK,6BAA6B,SAAS;AAGrE,aAAK,SAAS,kBAAkB,KAAK;AAErC,YAAI,UAAU,oBAAoB,QAC7B,UAAU,iBAA0C,QAAQ,MAAM;AACrE,gBAAM,cACF,gBAAgB,SAAS,eAAe,UAAU,gBAAgB;AACtE,eAAK,cAAc,IAAI,cAAc,WAAW;AAChD,eAAK,YAAY,YAAY,KAAK,SAAS;AAI3C,eAAK,YAAY,kBAAkB,KAAK;AACxC,eAAK,uBAAuB,UAAU;;AAGxC,eAAO;MACT;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MA8CA,MAAM,KAAK,cAAmC,QAAsB;AAElE,YAAI,OAAO,iBAAiB,UAAU;AACpC,gBAAM,WAAW,KAAK,GAAG,gBAAgB,YAAY;AACrD,cAAI,SAAS,WAAW,GAAG;AACzB,kBAAM,IAAI,MACN,0CAA0C,YAAY,GAAG;qBACpD,SAAS,SAAS,GAAG;AAC9B,kBAAM,IAAI,MACN,wBAAwB,SAAS,MAAM,4BAC/B,YAAY,GAAG;;AAE7B,yBAAe,SAAS,CAAC;;AAE3B,YAAI,aAAa,QAAQ,MAAM;AAC7B,gBAAM,IAAI,MACN,6GACsD;;AAG5D,eAAO,aAAa,KAAK,KAAK,SAAS;MACzC;MAEQ,yBAAyB,eAA8B;AAC7D,YAAI,KAAK,sBAAsB;AAC7B,gBAAM,qBACF,yBAAyB,SAAS,CAAC,aAAa,IAAI;AACxD,gBAAM,kBAAkC,CAAA;AAExC,6BAAmB,QACf,CAAC,cAAc,MAAM,gBAAgB,KAAK,qBAAqB,CAAC,CAAC,IAC7D,YAAY;AAEpB,iBAAO;;AAET,eAAO;MACT;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MAyCA,QAAQ,QAAwC,QAA2B;AAEzE,cAAM,gBAAgB,KAAK,QAAQ,QAAQ,KAAK,WAAW;AAC3D,eAAO,KAAK,yBAAyB,aAAa;MACpD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MA0CA,MAAM,aACF,QACA,QAA2B;AAC7B,cAAM,gBAAgB,MAAM,KAAK,aAAa,QAAQ,KAAK,WAAW;AACtE,eAAO,KAAK,yBAAyB,aAAa;MACpD;MAEQ,gBAAgB,QACc;;AACpC,YAAI,EAAE,kBAAkB,WAAW,CAAC,MAAM,QAAQ,MAAM,GAAG;AAEzD,gBAAM,mBAAkB,KAAA,KAAK,eAAS,QAAA,OAAA,SAAA,SAAA,GAAE;AACxC,cAAI,mBAAmB,MAAM;AAC3B,uBAAW,SAAS,iBAAiB;AACnC,oBAAMC,UAAS,gBAAgB,KAAK;AACpC,kBAAIA,QAAO,cAAc,MAAM;AAC7B,uBAAO,KAAK,IAAI,KAAK,0BAA0BA,QAAO,UAAU;;;;AAItE,iBAAO;;AAET,iBAAS,MAAM,QAAQ,MAAM,IAAI,SAAS,CAAC,MAAM;AAEjD,cAAM,oBACF,OAAO,KAAK,KAAK,yBAAyB,EAAE;AAChD,YAAI,OAAO,SAAS,sBAAsB,KAAK,WAAW,QAAQ;AAChE,gBAAM,IAAI,MAAM,oDACZ,KAAK,WAAW,SAChB,iBAAiB,+CACjB,OAAO,MAAM,0BAA0B;;AAG7C,YAAI,aAAa;AACjB,eAAO,KAAK,WAAW,OAAO,CAAC,KAAK,cAAa;;AAC/C,gBAAM,cAAa,MAAA,MAAAC,MAAA,KAAK,eAAS,QAAAA,QAAA,SAAA,SAAAA,IAAE,YAAM,QAAA,OAAA,SAAA,SAAA,GAAG,SAAS,OAAC,QAAA,OAAA,SAAA,SAAA,GAAE;AACxD,cAAI,cAAc,MAAM;AACtB,gBAAI,SAAS,IAAI,KAAK,0BAA0B,UAAU;iBACrD;AACL,gBAAI,SAAS,IAAK,OAAoB,YAAY;;AAEpD,iBAAO;QACT,GAAG,CAAA,CAAoB;MACzB;MAEQ,iBAAiB,SAAwB;AAC/C,kBAAU,WAAW,KAAK;AAC1B,eAAO,CAAC,MAAM,QAAQ,OAAO,IAAI,CAAC,OAAO,IAAI;MAC/C;MAEQ,0BAAuB;AAC7B,YAAI,KAAK,eAAe,MAAM;AAC5B,iBAAO,CAAA;;AAET,YAAI,KAAK,wBAAwB,MAAM;AACrC,iBAAO,KAAK,YAAY,QAAQ,CAAA,GAAI,CAAA,CAAE;eACjC;AACL,iBAAO,KAAK,YAAY,QACpB,CAAA,GAAI,OAAO,KAAK,KAAK,qBAAqB,OAAO,CAAC;;MAE1D;MAEQ,MAAM,+BAA4B;AACxC,YAAI,KAAK,eAAe,MAAM;AAC5B,iBAAO,CAAA;;AAET,YAAI,KAAK,wBAAwB,MAAM;AACrC,iBAAO,KAAK,YAAY,aAAa,CAAA,GAAI,CAAA,CAAE;eACtC;AACL,iBAAO,KAAK,YAAY,aACpB,CAAA,GAAI,OAAO,KAAK,KAAK,qBAAqB,OAAO,CAAC;;MAE1D;MAEQ,6BAA6B,SAAiB;AACpD,aAAK,4BAA4B,CAAA;AAEjC,YAAI,KAAK,sBAAsB;AAC7B,gBAAM,mBAAmB,KAAK,qBAAqB;AACnD,gBAAM,cAAc,OAAO,KAAK,gBAAgB;AAChD,mBAAS,IAAI,GAAG,IAAI,YAAY,QAAQ,KAAK;AAC3C,kBAAM,aAAa,YAAY,CAAC;AAChC,kBAAM,aAAa,iBAAiB,UAAU;AAC9C,iBAAK,0BAA0B,WAAW,UAAU,IAAI,QAAQ,CAAC;;;MAGvE;;;;;;;;;;;;;;;;;MAkBA,QAAQ,QAAwC,SAAyB;AAEvE,YAAI,KAAK,6BAA6B,MAAM;AAC1C,eAAK,6BAA6B,KAAK,wBAAuB,CAAE;;AAElE,iBAAS,KAAK,gBAAgB,MAAM;AACpC,kBAAU,KAAK,iBAAiB,OAAO;AACvC,cAAM,SAAS,KAAK,SAAS,QAAQ,QAAQ,OAAO;AACpD,eAAO,OAAO,SAAS,IAAI,SAAS,OAAO,CAAC;MAC9C;;;;;;;;;;;;;;;;;MAkBA,MAAM,aACF,QACA,SAAyB;AAC3B,YAAI,KAAK,6BAA6B,MAAM;AAC1C,eAAK,6BACD,MAAM,KAAK,6BAA4B,CAAE;;AAE/C,iBAAS,KAAK,gBAAgB,MAAM;AACpC,kBAAU,KAAK,iBAAiB,OAAO;AACvC,cAAM,SAAS,MAAM,KAAK,SAAS,aAAa,QAAQ,OAAO;AAC/D,eAAO,OAAO,SAAS,IAAI,SAAS,OAAO,CAAC;MAC9C;;;;;;;MAQA,yBAAsB;AACpB,eAAO,KAAK,SAAS,uBAAsB;MAC7C;;;;;;;MAQA,6BAA0B;AACxB,aAAK,SAAS,2BAA0B;MAC1C;MAEQ,6BAA6B,KAAmB;AACtD,eAAO,OAAO,KAAK,GAAG,EAAE,OAAO,CAAC,QAAyB,QAAO;AAC9D,iBAAO,GAAG,IAAI,CAAC,IAAI,GAAG,CAAC;AACvB,iBAAO;QACT,GAAG,CAAA,CAAE;MACP;;;;;;MAOA,UAAO;AACL,aAAK,SAAS,QAAO;AAErB,YAAI,KAAK,aAAa;AACpB,eAAK,YAAY,QAAO;AACxB,cAAI,KAAK,2BAA2B;AAClC,oBAAQ,KAAK,yBAAyB;;;AAI1C,aAAK,gBAAgB,QAAO;MAC9B;;;;;;AC7kBF,IAGM;AAHN;;AAGA,IAAM,UAAU;;;;;ACHhB,IAmBM;AAnBN;;AAiBA;AAEA,IAAM,MAAM,IAAG;AAGf,QAAI,aAAa,6BAA6B,MAAM,OAAO,gBAAa;AACtE,UAAI,YAAY;AACd,gBAAQ,KACJ,+OAG0D;;IAElE,CAAC;;;;;AC9BD,IAAAC,gBAAA;SAAAA,eAAA;;;;;;;;IAAAC,aAAA;;AAgBA;AAGA;AACA;AAEA;;;",
  "names": ["DataType", "SaverDef", "CheckpointFormatVersion", "tensor", "contextId", "pad", "json", "json", "json", "json", "json", "json", "json", "json", "json", "json", "json", "json", "json", "json", "json", "json", "json", "json", "op", "functions", "executeOp", "tensor", "tensor", "indices", "tensor", "split", "tensors", "executeOp", "tensor", "condResult", "split", "pad", "executeOp", "executeOp", "step", "mean", "executeOp", "executeOp", "executeOp", "data", "init_hash_table", "executeOp", "init_hash_table", "executeOp", "image", "executeOp", "executeOp", "executeOp", "executeOp", "executeOp", "reverse", "x", "weights", "size", "executeOp", "tensor", "executeOp", "executeOp", "executeOp", "executeOp", "executeOp", "tidy", "node", "tensorMap", "context", "unique", "stack", "init_graph_executor", "tensor", "clone", "executeOp", "node", "stack", "init_graph_executor", "tensor", "_a", "dist_exports", "init_dist"]
}
